{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.02133651958692498,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0002133651958692498,
      "grad_norm": 0.03869746997952461,
      "learning_rate": 1e-05,
      "loss": 0.3248,
      "step": 5
    },
    {
      "epoch": 0.0004267303917384996,
      "grad_norm": 0.02739635854959488,
      "learning_rate": 2e-05,
      "loss": 0.3953,
      "step": 10
    },
    {
      "epoch": 0.0006400955876077494,
      "grad_norm": 0.019273385405540466,
      "learning_rate": 3e-05,
      "loss": 0.3951,
      "step": 15
    },
    {
      "epoch": 0.0008534607834769992,
      "grad_norm": 0.04957350343465805,
      "learning_rate": 4e-05,
      "loss": 0.3954,
      "step": 20
    },
    {
      "epoch": 0.001066825979346249,
      "grad_norm": 0.04382278770208359,
      "learning_rate": 5e-05,
      "loss": 0.388,
      "step": 25
    },
    {
      "epoch": 0.0012801911752154988,
      "grad_norm": 0.030294347554445267,
      "learning_rate": 6e-05,
      "loss": 0.3584,
      "step": 30
    },
    {
      "epoch": 0.0014935563710847487,
      "grad_norm": 0.024038711562752724,
      "learning_rate": 7e-05,
      "loss": 0.4352,
      "step": 35
    },
    {
      "epoch": 0.0017069215669539984,
      "grad_norm": 0.02722998335957527,
      "learning_rate": 8e-05,
      "loss": 0.3966,
      "step": 40
    },
    {
      "epoch": 0.0019202867628232484,
      "grad_norm": 0.0432308204472065,
      "learning_rate": 9e-05,
      "loss": 0.3614,
      "step": 45
    },
    {
      "epoch": 0.002133651958692498,
      "grad_norm": 0.022680964320898056,
      "learning_rate": 0.0001,
      "loss": 0.3402,
      "step": 50
    },
    {
      "epoch": 0.002347017154561748,
      "grad_norm": 0.02603471651673317,
      "learning_rate": 9.999974825027756e-05,
      "loss": 0.3873,
      "step": 55
    },
    {
      "epoch": 0.0025603823504309975,
      "grad_norm": 0.017965203151106834,
      "learning_rate": 9.999899300364532e-05,
      "loss": 0.3068,
      "step": 60
    },
    {
      "epoch": 0.0027737475463002477,
      "grad_norm": 0.024919070303440094,
      "learning_rate": 9.999773426770865e-05,
      "loss": 0.3714,
      "step": 65
    },
    {
      "epoch": 0.0029871127421694974,
      "grad_norm": 0.03676893934607506,
      "learning_rate": 9.999597205514297e-05,
      "loss": 0.3834,
      "step": 70
    },
    {
      "epoch": 0.003200477938038747,
      "grad_norm": 0.026584310457110405,
      "learning_rate": 9.999370638369377e-05,
      "loss": 0.3203,
      "step": 75
    },
    {
      "epoch": 0.003413843133907997,
      "grad_norm": 0.028050128370523453,
      "learning_rate": 9.99909372761763e-05,
      "loss": 0.3786,
      "step": 80
    },
    {
      "epoch": 0.0036272083297772466,
      "grad_norm": 0.0348004475235939,
      "learning_rate": 9.998766476047547e-05,
      "loss": 0.3346,
      "step": 85
    },
    {
      "epoch": 0.0038405735256464967,
      "grad_norm": 0.016999248415231705,
      "learning_rate": 9.998388886954547e-05,
      "loss": 0.3259,
      "step": 90
    },
    {
      "epoch": 0.0040539387215157464,
      "grad_norm": 0.02837252803146839,
      "learning_rate": 9.997960964140947e-05,
      "loss": 0.3621,
      "step": 95
    },
    {
      "epoch": 0.004267303917384996,
      "grad_norm": 0.026871170848608017,
      "learning_rate": 9.997482711915927e-05,
      "loss": 0.3697,
      "step": 100
    },
    {
      "epoch": 0.004480669113254246,
      "grad_norm": 0.029482675716280937,
      "learning_rate": 9.99695413509548e-05,
      "loss": 0.3568,
      "step": 105
    },
    {
      "epoch": 0.004694034309123496,
      "grad_norm": 0.02930273301899433,
      "learning_rate": 9.996375239002369e-05,
      "loss": 0.3434,
      "step": 110
    },
    {
      "epoch": 0.004907399504992745,
      "grad_norm": 0.03681829199194908,
      "learning_rate": 9.995746029466071e-05,
      "loss": 0.3316,
      "step": 115
    },
    {
      "epoch": 0.005120764700861995,
      "grad_norm": 0.04959462955594063,
      "learning_rate": 9.99506651282272e-05,
      "loss": 0.3334,
      "step": 120
    },
    {
      "epoch": 0.005334129896731245,
      "grad_norm": 0.025351479649543762,
      "learning_rate": 9.99433669591504e-05,
      "loss": 0.2926,
      "step": 125
    },
    {
      "epoch": 0.005547495092600495,
      "grad_norm": 0.032123204320669174,
      "learning_rate": 9.993556586092281e-05,
      "loss": 0.3775,
      "step": 130
    },
    {
      "epoch": 0.005760860288469745,
      "grad_norm": 0.0235612615942955,
      "learning_rate": 9.992726191210138e-05,
      "loss": 0.284,
      "step": 135
    },
    {
      "epoch": 0.005974225484338995,
      "grad_norm": 0.027285289019346237,
      "learning_rate": 9.991845519630678e-05,
      "loss": 0.3134,
      "step": 140
    },
    {
      "epoch": 0.0061875906802082445,
      "grad_norm": 0.02710113674402237,
      "learning_rate": 9.990914580222257e-05,
      "loss": 0.3194,
      "step": 145
    },
    {
      "epoch": 0.006400955876077494,
      "grad_norm": 0.03646542876958847,
      "learning_rate": 9.989933382359422e-05,
      "loss": 0.3205,
      "step": 150
    },
    {
      "epoch": 0.006614321071946744,
      "grad_norm": 0.036253318190574646,
      "learning_rate": 9.988901935922826e-05,
      "loss": 0.2972,
      "step": 155
    },
    {
      "epoch": 0.006827686267815994,
      "grad_norm": 0.056111834943294525,
      "learning_rate": 9.987820251299122e-05,
      "loss": 0.3093,
      "step": 160
    },
    {
      "epoch": 0.007041051463685243,
      "grad_norm": 0.035737186670303345,
      "learning_rate": 9.986688339380862e-05,
      "loss": 0.2782,
      "step": 165
    },
    {
      "epoch": 0.007254416659554493,
      "grad_norm": 0.03300263360142708,
      "learning_rate": 9.985506211566388e-05,
      "loss": 0.3389,
      "step": 170
    },
    {
      "epoch": 0.007467781855423743,
      "grad_norm": 0.028414659202098846,
      "learning_rate": 9.984273879759713e-05,
      "loss": 0.2875,
      "step": 175
    },
    {
      "epoch": 0.0076811470512929934,
      "grad_norm": 0.03488699719309807,
      "learning_rate": 9.982991356370404e-05,
      "loss": 0.3146,
      "step": 180
    },
    {
      "epoch": 0.007894512247162243,
      "grad_norm": 0.02304576151072979,
      "learning_rate": 9.981658654313457e-05,
      "loss": 0.3334,
      "step": 185
    },
    {
      "epoch": 0.008107877443031493,
      "grad_norm": 0.024964524433016777,
      "learning_rate": 9.98027578700917e-05,
      "loss": 0.3466,
      "step": 190
    },
    {
      "epoch": 0.008321242638900743,
      "grad_norm": 0.03501828387379646,
      "learning_rate": 9.978842768382998e-05,
      "loss": 0.3441,
      "step": 195
    },
    {
      "epoch": 0.008534607834769992,
      "grad_norm": 0.038075726479291916,
      "learning_rate": 9.977359612865423e-05,
      "loss": 0.3015,
      "step": 200
    },
    {
      "epoch": 0.008747973030639242,
      "grad_norm": 0.050676748156547546,
      "learning_rate": 9.975826335391808e-05,
      "loss": 0.3553,
      "step": 205
    },
    {
      "epoch": 0.008961338226508492,
      "grad_norm": 0.033146731555461884,
      "learning_rate": 9.974242951402235e-05,
      "loss": 0.3076,
      "step": 210
    },
    {
      "epoch": 0.009174703422377741,
      "grad_norm": 0.04014997556805611,
      "learning_rate": 9.972609476841367e-05,
      "loss": 0.3208,
      "step": 215
    },
    {
      "epoch": 0.009388068618246991,
      "grad_norm": 0.032781995832920074,
      "learning_rate": 9.970925928158274e-05,
      "loss": 0.3197,
      "step": 220
    },
    {
      "epoch": 0.009601433814116241,
      "grad_norm": 0.030503202229738235,
      "learning_rate": 9.969192322306271e-05,
      "loss": 0.3061,
      "step": 225
    },
    {
      "epoch": 0.00981479900998549,
      "grad_norm": 0.045481644570827484,
      "learning_rate": 9.967408676742751e-05,
      "loss": 0.3385,
      "step": 230
    },
    {
      "epoch": 0.01002816420585474,
      "grad_norm": 0.02612905204296112,
      "learning_rate": 9.965575009429006e-05,
      "loss": 0.3218,
      "step": 235
    },
    {
      "epoch": 0.01024152940172399,
      "grad_norm": 0.02986380271613598,
      "learning_rate": 9.963691338830044e-05,
      "loss": 0.335,
      "step": 240
    },
    {
      "epoch": 0.01045489459759324,
      "grad_norm": 0.041255317628383636,
      "learning_rate": 9.961757683914406e-05,
      "loss": 0.3375,
      "step": 245
    },
    {
      "epoch": 0.01066825979346249,
      "grad_norm": 0.03265068680047989,
      "learning_rate": 9.959774064153977e-05,
      "loss": 0.3121,
      "step": 250
    },
    {
      "epoch": 0.010881624989331741,
      "grad_norm": 0.036994025111198425,
      "learning_rate": 9.957740499523787e-05,
      "loss": 0.3193,
      "step": 255
    },
    {
      "epoch": 0.01109499018520099,
      "grad_norm": 0.038589030504226685,
      "learning_rate": 9.955657010501806e-05,
      "loss": 0.3373,
      "step": 260
    },
    {
      "epoch": 0.01130835538107024,
      "grad_norm": 0.03312426060438156,
      "learning_rate": 9.953523618068749e-05,
      "loss": 0.2991,
      "step": 265
    },
    {
      "epoch": 0.01152172057693949,
      "grad_norm": 0.04065118357539177,
      "learning_rate": 9.951340343707852e-05,
      "loss": 0.2788,
      "step": 270
    },
    {
      "epoch": 0.01173508577280874,
      "grad_norm": 0.03685835376381874,
      "learning_rate": 9.949107209404665e-05,
      "loss": 0.3527,
      "step": 275
    },
    {
      "epoch": 0.01194845096867799,
      "grad_norm": 0.024746570736169815,
      "learning_rate": 9.946824237646824e-05,
      "loss": 0.3311,
      "step": 280
    },
    {
      "epoch": 0.01216181616454724,
      "grad_norm": 0.050961077213287354,
      "learning_rate": 9.944491451423828e-05,
      "loss": 0.3068,
      "step": 285
    },
    {
      "epoch": 0.012375181360416489,
      "grad_norm": 0.03330977261066437,
      "learning_rate": 9.942108874226811e-05,
      "loss": 0.3046,
      "step": 290
    },
    {
      "epoch": 0.012588546556285739,
      "grad_norm": 0.041634589433670044,
      "learning_rate": 9.939676530048301e-05,
      "loss": 0.3638,
      "step": 295
    },
    {
      "epoch": 0.012801911752154988,
      "grad_norm": 0.04857579991221428,
      "learning_rate": 9.937194443381972e-05,
      "loss": 0.3359,
      "step": 300
    },
    {
      "epoch": 0.013015276948024238,
      "grad_norm": 0.033971674740314484,
      "learning_rate": 9.934662639222412e-05,
      "loss": 0.3343,
      "step": 305
    },
    {
      "epoch": 0.013228642143893488,
      "grad_norm": 0.04807056114077568,
      "learning_rate": 9.93208114306486e-05,
      "loss": 0.2885,
      "step": 310
    },
    {
      "epoch": 0.013442007339762738,
      "grad_norm": 0.032758694142103195,
      "learning_rate": 9.929449980904952e-05,
      "loss": 0.2978,
      "step": 315
    },
    {
      "epoch": 0.013655372535631987,
      "grad_norm": 0.0615675263106823,
      "learning_rate": 9.926769179238466e-05,
      "loss": 0.3362,
      "step": 320
    },
    {
      "epoch": 0.013868737731501237,
      "grad_norm": 0.03430687263607979,
      "learning_rate": 9.924038765061042e-05,
      "loss": 0.3064,
      "step": 325
    },
    {
      "epoch": 0.014082102927370487,
      "grad_norm": 0.04423543065786362,
      "learning_rate": 9.921258765867919e-05,
      "loss": 0.3385,
      "step": 330
    },
    {
      "epoch": 0.014295468123239737,
      "grad_norm": 0.050316158682107925,
      "learning_rate": 9.918429209653662e-05,
      "loss": 0.2862,
      "step": 335
    },
    {
      "epoch": 0.014508833319108986,
      "grad_norm": 0.03375300019979477,
      "learning_rate": 9.915550124911866e-05,
      "loss": 0.3395,
      "step": 340
    },
    {
      "epoch": 0.014722198514978236,
      "grad_norm": 0.0314343124628067,
      "learning_rate": 9.912621540634887e-05,
      "loss": 0.2859,
      "step": 345
    },
    {
      "epoch": 0.014935563710847486,
      "grad_norm": 0.05071764439344406,
      "learning_rate": 9.909643486313533e-05,
      "loss": 0.3474,
      "step": 350
    },
    {
      "epoch": 0.015148928906716737,
      "grad_norm": 0.06137031689286232,
      "learning_rate": 9.90661599193678e-05,
      "loss": 0.3758,
      "step": 355
    },
    {
      "epoch": 0.015362294102585987,
      "grad_norm": 0.030769577249884605,
      "learning_rate": 9.903539087991462e-05,
      "loss": 0.3186,
      "step": 360
    },
    {
      "epoch": 0.015575659298455237,
      "grad_norm": 0.0395379476249218,
      "learning_rate": 9.900412805461967e-05,
      "loss": 0.3311,
      "step": 365
    },
    {
      "epoch": 0.015789024494324486,
      "grad_norm": 0.031456802040338516,
      "learning_rate": 9.897237175829926e-05,
      "loss": 0.2988,
      "step": 370
    },
    {
      "epoch": 0.016002389690193734,
      "grad_norm": 0.03804735839366913,
      "learning_rate": 9.894012231073894e-05,
      "loss": 0.2572,
      "step": 375
    },
    {
      "epoch": 0.016215754886062986,
      "grad_norm": 0.05333496257662773,
      "learning_rate": 9.890738003669029e-05,
      "loss": 0.3299,
      "step": 380
    },
    {
      "epoch": 0.016429120081932234,
      "grad_norm": 0.04284248128533363,
      "learning_rate": 9.887414526586763e-05,
      "loss": 0.3057,
      "step": 385
    },
    {
      "epoch": 0.016642485277801485,
      "grad_norm": 0.06497358530759811,
      "learning_rate": 9.884041833294476e-05,
      "loss": 0.2854,
      "step": 390
    },
    {
      "epoch": 0.016855850473670733,
      "grad_norm": 0.030042508617043495,
      "learning_rate": 9.880619957755151e-05,
      "loss": 0.3066,
      "step": 395
    },
    {
      "epoch": 0.017069215669539985,
      "grad_norm": 0.037049245089292526,
      "learning_rate": 9.877148934427037e-05,
      "loss": 0.2994,
      "step": 400
    },
    {
      "epoch": 0.017282580865409236,
      "grad_norm": 0.04202405735850334,
      "learning_rate": 9.873628798263296e-05,
      "loss": 0.3333,
      "step": 405
    },
    {
      "epoch": 0.017495946061278484,
      "grad_norm": 0.02314177341759205,
      "learning_rate": 9.870059584711668e-05,
      "loss": 0.3097,
      "step": 410
    },
    {
      "epoch": 0.017709311257147736,
      "grad_norm": 0.03363711014389992,
      "learning_rate": 9.866441329714088e-05,
      "loss": 0.3114,
      "step": 415
    },
    {
      "epoch": 0.017922676453016984,
      "grad_norm": 0.03179682046175003,
      "learning_rate": 9.862774069706346e-05,
      "loss": 0.2858,
      "step": 420
    },
    {
      "epoch": 0.018136041648886235,
      "grad_norm": 0.031132983043789864,
      "learning_rate": 9.859057841617709e-05,
      "loss": 0.3659,
      "step": 425
    },
    {
      "epoch": 0.018349406844755483,
      "grad_norm": 0.03776048123836517,
      "learning_rate": 9.855292682870551e-05,
      "loss": 0.3391,
      "step": 430
    },
    {
      "epoch": 0.018562772040624734,
      "grad_norm": 0.0370539166033268,
      "learning_rate": 9.851478631379982e-05,
      "loss": 0.3285,
      "step": 435
    },
    {
      "epoch": 0.018776137236493982,
      "grad_norm": 0.05034906417131424,
      "learning_rate": 9.847615725553456e-05,
      "loss": 0.2996,
      "step": 440
    },
    {
      "epoch": 0.018989502432363234,
      "grad_norm": 0.03803911432623863,
      "learning_rate": 9.843704004290392e-05,
      "loss": 0.3311,
      "step": 445
    },
    {
      "epoch": 0.019202867628232482,
      "grad_norm": 0.026636559516191483,
      "learning_rate": 9.839743506981782e-05,
      "loss": 0.3264,
      "step": 450
    },
    {
      "epoch": 0.019416232824101733,
      "grad_norm": 0.03475625067949295,
      "learning_rate": 9.835734273509786e-05,
      "loss": 0.3127,
      "step": 455
    },
    {
      "epoch": 0.01962959801997098,
      "grad_norm": 0.034204330295324326,
      "learning_rate": 9.831676344247342e-05,
      "loss": 0.269,
      "step": 460
    },
    {
      "epoch": 0.019842963215840233,
      "grad_norm": 0.035325467586517334,
      "learning_rate": 9.827569760057755e-05,
      "loss": 0.2725,
      "step": 465
    },
    {
      "epoch": 0.02005632841170948,
      "grad_norm": 0.02739345096051693,
      "learning_rate": 9.82341456229428e-05,
      "loss": 0.2961,
      "step": 470
    },
    {
      "epoch": 0.020269693607578732,
      "grad_norm": 0.07521704584360123,
      "learning_rate": 9.819210792799712e-05,
      "loss": 0.3308,
      "step": 475
    },
    {
      "epoch": 0.02048305880344798,
      "grad_norm": 0.11195027828216553,
      "learning_rate": 9.814958493905963e-05,
      "loss": 0.3328,
      "step": 480
    },
    {
      "epoch": 0.02069642399931723,
      "grad_norm": 0.030925286933779716,
      "learning_rate": 9.810657708433637e-05,
      "loss": 0.3128,
      "step": 485
    },
    {
      "epoch": 0.02090978919518648,
      "grad_norm": 0.035490475594997406,
      "learning_rate": 9.806308479691595e-05,
      "loss": 0.279,
      "step": 490
    },
    {
      "epoch": 0.02112315439105573,
      "grad_norm": 0.0735531598329544,
      "learning_rate": 9.801910851476523e-05,
      "loss": 0.3455,
      "step": 495
    },
    {
      "epoch": 0.02133651958692498,
      "grad_norm": 0.029140891507267952,
      "learning_rate": 9.797464868072488e-05,
      "loss": 0.3824,
      "step": 500
    }
  ],
  "logging_steps": 5,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.33340823502848e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
