{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.04267303917384996,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0002133651958692498,
      "grad_norm": 0.03869746997952461,
      "learning_rate": 1e-05,
      "loss": 0.3248,
      "step": 5
    },
    {
      "epoch": 0.0004267303917384996,
      "grad_norm": 0.02739635854959488,
      "learning_rate": 2e-05,
      "loss": 0.3953,
      "step": 10
    },
    {
      "epoch": 0.0006400955876077494,
      "grad_norm": 0.019273385405540466,
      "learning_rate": 3e-05,
      "loss": 0.3951,
      "step": 15
    },
    {
      "epoch": 0.0008534607834769992,
      "grad_norm": 0.04957350343465805,
      "learning_rate": 4e-05,
      "loss": 0.3954,
      "step": 20
    },
    {
      "epoch": 0.001066825979346249,
      "grad_norm": 0.04382278770208359,
      "learning_rate": 5e-05,
      "loss": 0.388,
      "step": 25
    },
    {
      "epoch": 0.0012801911752154988,
      "grad_norm": 0.030294347554445267,
      "learning_rate": 6e-05,
      "loss": 0.3584,
      "step": 30
    },
    {
      "epoch": 0.0014935563710847487,
      "grad_norm": 0.024038711562752724,
      "learning_rate": 7e-05,
      "loss": 0.4352,
      "step": 35
    },
    {
      "epoch": 0.0017069215669539984,
      "grad_norm": 0.02722998335957527,
      "learning_rate": 8e-05,
      "loss": 0.3966,
      "step": 40
    },
    {
      "epoch": 0.0019202867628232484,
      "grad_norm": 0.0432308204472065,
      "learning_rate": 9e-05,
      "loss": 0.3614,
      "step": 45
    },
    {
      "epoch": 0.002133651958692498,
      "grad_norm": 0.022680964320898056,
      "learning_rate": 0.0001,
      "loss": 0.3402,
      "step": 50
    },
    {
      "epoch": 0.002347017154561748,
      "grad_norm": 0.02603471651673317,
      "learning_rate": 9.999974825027756e-05,
      "loss": 0.3873,
      "step": 55
    },
    {
      "epoch": 0.0025603823504309975,
      "grad_norm": 0.017965203151106834,
      "learning_rate": 9.999899300364532e-05,
      "loss": 0.3068,
      "step": 60
    },
    {
      "epoch": 0.0027737475463002477,
      "grad_norm": 0.024919070303440094,
      "learning_rate": 9.999773426770865e-05,
      "loss": 0.3714,
      "step": 65
    },
    {
      "epoch": 0.0029871127421694974,
      "grad_norm": 0.03676893934607506,
      "learning_rate": 9.999597205514297e-05,
      "loss": 0.3834,
      "step": 70
    },
    {
      "epoch": 0.003200477938038747,
      "grad_norm": 0.026584310457110405,
      "learning_rate": 9.999370638369377e-05,
      "loss": 0.3203,
      "step": 75
    },
    {
      "epoch": 0.003413843133907997,
      "grad_norm": 0.028050128370523453,
      "learning_rate": 9.99909372761763e-05,
      "loss": 0.3786,
      "step": 80
    },
    {
      "epoch": 0.0036272083297772466,
      "grad_norm": 0.0348004475235939,
      "learning_rate": 9.998766476047547e-05,
      "loss": 0.3346,
      "step": 85
    },
    {
      "epoch": 0.0038405735256464967,
      "grad_norm": 0.016999248415231705,
      "learning_rate": 9.998388886954547e-05,
      "loss": 0.3259,
      "step": 90
    },
    {
      "epoch": 0.0040539387215157464,
      "grad_norm": 0.02837252803146839,
      "learning_rate": 9.997960964140947e-05,
      "loss": 0.3621,
      "step": 95
    },
    {
      "epoch": 0.004267303917384996,
      "grad_norm": 0.026871170848608017,
      "learning_rate": 9.997482711915927e-05,
      "loss": 0.3697,
      "step": 100
    },
    {
      "epoch": 0.004480669113254246,
      "grad_norm": 0.029482675716280937,
      "learning_rate": 9.99695413509548e-05,
      "loss": 0.3568,
      "step": 105
    },
    {
      "epoch": 0.004694034309123496,
      "grad_norm": 0.02930273301899433,
      "learning_rate": 9.996375239002369e-05,
      "loss": 0.3434,
      "step": 110
    },
    {
      "epoch": 0.004907399504992745,
      "grad_norm": 0.03681829199194908,
      "learning_rate": 9.995746029466071e-05,
      "loss": 0.3316,
      "step": 115
    },
    {
      "epoch": 0.005120764700861995,
      "grad_norm": 0.04959462955594063,
      "learning_rate": 9.99506651282272e-05,
      "loss": 0.3334,
      "step": 120
    },
    {
      "epoch": 0.005334129896731245,
      "grad_norm": 0.025351479649543762,
      "learning_rate": 9.99433669591504e-05,
      "loss": 0.2926,
      "step": 125
    },
    {
      "epoch": 0.005547495092600495,
      "grad_norm": 0.032123204320669174,
      "learning_rate": 9.993556586092281e-05,
      "loss": 0.3775,
      "step": 130
    },
    {
      "epoch": 0.005760860288469745,
      "grad_norm": 0.0235612615942955,
      "learning_rate": 9.992726191210138e-05,
      "loss": 0.284,
      "step": 135
    },
    {
      "epoch": 0.005974225484338995,
      "grad_norm": 0.027285289019346237,
      "learning_rate": 9.991845519630678e-05,
      "loss": 0.3134,
      "step": 140
    },
    {
      "epoch": 0.0061875906802082445,
      "grad_norm": 0.02710113674402237,
      "learning_rate": 9.990914580222257e-05,
      "loss": 0.3194,
      "step": 145
    },
    {
      "epoch": 0.006400955876077494,
      "grad_norm": 0.03646542876958847,
      "learning_rate": 9.989933382359422e-05,
      "loss": 0.3205,
      "step": 150
    },
    {
      "epoch": 0.006614321071946744,
      "grad_norm": 0.036253318190574646,
      "learning_rate": 9.988901935922826e-05,
      "loss": 0.2972,
      "step": 155
    },
    {
      "epoch": 0.006827686267815994,
      "grad_norm": 0.056111834943294525,
      "learning_rate": 9.987820251299122e-05,
      "loss": 0.3093,
      "step": 160
    },
    {
      "epoch": 0.007041051463685243,
      "grad_norm": 0.035737186670303345,
      "learning_rate": 9.986688339380862e-05,
      "loss": 0.2782,
      "step": 165
    },
    {
      "epoch": 0.007254416659554493,
      "grad_norm": 0.03300263360142708,
      "learning_rate": 9.985506211566388e-05,
      "loss": 0.3389,
      "step": 170
    },
    {
      "epoch": 0.007467781855423743,
      "grad_norm": 0.028414659202098846,
      "learning_rate": 9.984273879759713e-05,
      "loss": 0.2875,
      "step": 175
    },
    {
      "epoch": 0.0076811470512929934,
      "grad_norm": 0.03488699719309807,
      "learning_rate": 9.982991356370404e-05,
      "loss": 0.3146,
      "step": 180
    },
    {
      "epoch": 0.007894512247162243,
      "grad_norm": 0.02304576151072979,
      "learning_rate": 9.981658654313457e-05,
      "loss": 0.3334,
      "step": 185
    },
    {
      "epoch": 0.008107877443031493,
      "grad_norm": 0.024964524433016777,
      "learning_rate": 9.98027578700917e-05,
      "loss": 0.3466,
      "step": 190
    },
    {
      "epoch": 0.008321242638900743,
      "grad_norm": 0.03501828387379646,
      "learning_rate": 9.978842768382998e-05,
      "loss": 0.3441,
      "step": 195
    },
    {
      "epoch": 0.008534607834769992,
      "grad_norm": 0.038075726479291916,
      "learning_rate": 9.977359612865423e-05,
      "loss": 0.3015,
      "step": 200
    },
    {
      "epoch": 0.008747973030639242,
      "grad_norm": 0.050676748156547546,
      "learning_rate": 9.975826335391808e-05,
      "loss": 0.3553,
      "step": 205
    },
    {
      "epoch": 0.008961338226508492,
      "grad_norm": 0.033146731555461884,
      "learning_rate": 9.974242951402235e-05,
      "loss": 0.3076,
      "step": 210
    },
    {
      "epoch": 0.009174703422377741,
      "grad_norm": 0.04014997556805611,
      "learning_rate": 9.972609476841367e-05,
      "loss": 0.3208,
      "step": 215
    },
    {
      "epoch": 0.009388068618246991,
      "grad_norm": 0.032781995832920074,
      "learning_rate": 9.970925928158274e-05,
      "loss": 0.3197,
      "step": 220
    },
    {
      "epoch": 0.009601433814116241,
      "grad_norm": 0.030503202229738235,
      "learning_rate": 9.969192322306271e-05,
      "loss": 0.3061,
      "step": 225
    },
    {
      "epoch": 0.00981479900998549,
      "grad_norm": 0.045481644570827484,
      "learning_rate": 9.967408676742751e-05,
      "loss": 0.3385,
      "step": 230
    },
    {
      "epoch": 0.01002816420585474,
      "grad_norm": 0.02612905204296112,
      "learning_rate": 9.965575009429006e-05,
      "loss": 0.3218,
      "step": 235
    },
    {
      "epoch": 0.01024152940172399,
      "grad_norm": 0.02986380271613598,
      "learning_rate": 9.963691338830044e-05,
      "loss": 0.335,
      "step": 240
    },
    {
      "epoch": 0.01045489459759324,
      "grad_norm": 0.041255317628383636,
      "learning_rate": 9.961757683914406e-05,
      "loss": 0.3375,
      "step": 245
    },
    {
      "epoch": 0.01066825979346249,
      "grad_norm": 0.03265068680047989,
      "learning_rate": 9.959774064153977e-05,
      "loss": 0.3121,
      "step": 250
    },
    {
      "epoch": 0.010881624989331741,
      "grad_norm": 0.036994025111198425,
      "learning_rate": 9.957740499523787e-05,
      "loss": 0.3193,
      "step": 255
    },
    {
      "epoch": 0.01109499018520099,
      "grad_norm": 0.038589030504226685,
      "learning_rate": 9.955657010501806e-05,
      "loss": 0.3373,
      "step": 260
    },
    {
      "epoch": 0.01130835538107024,
      "grad_norm": 0.03312426060438156,
      "learning_rate": 9.953523618068749e-05,
      "loss": 0.2991,
      "step": 265
    },
    {
      "epoch": 0.01152172057693949,
      "grad_norm": 0.04065118357539177,
      "learning_rate": 9.951340343707852e-05,
      "loss": 0.2788,
      "step": 270
    },
    {
      "epoch": 0.01173508577280874,
      "grad_norm": 0.03685835376381874,
      "learning_rate": 9.949107209404665e-05,
      "loss": 0.3527,
      "step": 275
    },
    {
      "epoch": 0.01194845096867799,
      "grad_norm": 0.024746570736169815,
      "learning_rate": 9.946824237646824e-05,
      "loss": 0.3311,
      "step": 280
    },
    {
      "epoch": 0.01216181616454724,
      "grad_norm": 0.050961077213287354,
      "learning_rate": 9.944491451423828e-05,
      "loss": 0.3068,
      "step": 285
    },
    {
      "epoch": 0.012375181360416489,
      "grad_norm": 0.03330977261066437,
      "learning_rate": 9.942108874226811e-05,
      "loss": 0.3046,
      "step": 290
    },
    {
      "epoch": 0.012588546556285739,
      "grad_norm": 0.041634589433670044,
      "learning_rate": 9.939676530048301e-05,
      "loss": 0.3638,
      "step": 295
    },
    {
      "epoch": 0.012801911752154988,
      "grad_norm": 0.04857579991221428,
      "learning_rate": 9.937194443381972e-05,
      "loss": 0.3359,
      "step": 300
    },
    {
      "epoch": 0.013015276948024238,
      "grad_norm": 0.033971674740314484,
      "learning_rate": 9.934662639222412e-05,
      "loss": 0.3343,
      "step": 305
    },
    {
      "epoch": 0.013228642143893488,
      "grad_norm": 0.04807056114077568,
      "learning_rate": 9.93208114306486e-05,
      "loss": 0.2885,
      "step": 310
    },
    {
      "epoch": 0.013442007339762738,
      "grad_norm": 0.032758694142103195,
      "learning_rate": 9.929449980904952e-05,
      "loss": 0.2978,
      "step": 315
    },
    {
      "epoch": 0.013655372535631987,
      "grad_norm": 0.0615675263106823,
      "learning_rate": 9.926769179238466e-05,
      "loss": 0.3362,
      "step": 320
    },
    {
      "epoch": 0.013868737731501237,
      "grad_norm": 0.03430687263607979,
      "learning_rate": 9.924038765061042e-05,
      "loss": 0.3064,
      "step": 325
    },
    {
      "epoch": 0.014082102927370487,
      "grad_norm": 0.04423543065786362,
      "learning_rate": 9.921258765867919e-05,
      "loss": 0.3385,
      "step": 330
    },
    {
      "epoch": 0.014295468123239737,
      "grad_norm": 0.050316158682107925,
      "learning_rate": 9.918429209653662e-05,
      "loss": 0.2862,
      "step": 335
    },
    {
      "epoch": 0.014508833319108986,
      "grad_norm": 0.03375300019979477,
      "learning_rate": 9.915550124911866e-05,
      "loss": 0.3395,
      "step": 340
    },
    {
      "epoch": 0.014722198514978236,
      "grad_norm": 0.0314343124628067,
      "learning_rate": 9.912621540634887e-05,
      "loss": 0.2859,
      "step": 345
    },
    {
      "epoch": 0.014935563710847486,
      "grad_norm": 0.05071764439344406,
      "learning_rate": 9.909643486313533e-05,
      "loss": 0.3474,
      "step": 350
    },
    {
      "epoch": 0.015148928906716737,
      "grad_norm": 0.06137031689286232,
      "learning_rate": 9.90661599193678e-05,
      "loss": 0.3758,
      "step": 355
    },
    {
      "epoch": 0.015362294102585987,
      "grad_norm": 0.030769577249884605,
      "learning_rate": 9.903539087991462e-05,
      "loss": 0.3186,
      "step": 360
    },
    {
      "epoch": 0.015575659298455237,
      "grad_norm": 0.0395379476249218,
      "learning_rate": 9.900412805461967e-05,
      "loss": 0.3311,
      "step": 365
    },
    {
      "epoch": 0.015789024494324486,
      "grad_norm": 0.031456802040338516,
      "learning_rate": 9.897237175829926e-05,
      "loss": 0.2988,
      "step": 370
    },
    {
      "epoch": 0.016002389690193734,
      "grad_norm": 0.03804735839366913,
      "learning_rate": 9.894012231073894e-05,
      "loss": 0.2572,
      "step": 375
    },
    {
      "epoch": 0.016215754886062986,
      "grad_norm": 0.05333496257662773,
      "learning_rate": 9.890738003669029e-05,
      "loss": 0.3299,
      "step": 380
    },
    {
      "epoch": 0.016429120081932234,
      "grad_norm": 0.04284248128533363,
      "learning_rate": 9.887414526586763e-05,
      "loss": 0.3057,
      "step": 385
    },
    {
      "epoch": 0.016642485277801485,
      "grad_norm": 0.06497358530759811,
      "learning_rate": 9.884041833294476e-05,
      "loss": 0.2854,
      "step": 390
    },
    {
      "epoch": 0.016855850473670733,
      "grad_norm": 0.030042508617043495,
      "learning_rate": 9.880619957755151e-05,
      "loss": 0.3066,
      "step": 395
    },
    {
      "epoch": 0.017069215669539985,
      "grad_norm": 0.037049245089292526,
      "learning_rate": 9.877148934427037e-05,
      "loss": 0.2994,
      "step": 400
    },
    {
      "epoch": 0.017282580865409236,
      "grad_norm": 0.04202405735850334,
      "learning_rate": 9.873628798263296e-05,
      "loss": 0.3333,
      "step": 405
    },
    {
      "epoch": 0.017495946061278484,
      "grad_norm": 0.02314177341759205,
      "learning_rate": 9.870059584711668e-05,
      "loss": 0.3097,
      "step": 410
    },
    {
      "epoch": 0.017709311257147736,
      "grad_norm": 0.03363711014389992,
      "learning_rate": 9.866441329714088e-05,
      "loss": 0.3114,
      "step": 415
    },
    {
      "epoch": 0.017922676453016984,
      "grad_norm": 0.03179682046175003,
      "learning_rate": 9.862774069706346e-05,
      "loss": 0.2858,
      "step": 420
    },
    {
      "epoch": 0.018136041648886235,
      "grad_norm": 0.031132983043789864,
      "learning_rate": 9.859057841617709e-05,
      "loss": 0.3659,
      "step": 425
    },
    {
      "epoch": 0.018349406844755483,
      "grad_norm": 0.03776048123836517,
      "learning_rate": 9.855292682870551e-05,
      "loss": 0.3391,
      "step": 430
    },
    {
      "epoch": 0.018562772040624734,
      "grad_norm": 0.0370539166033268,
      "learning_rate": 9.851478631379982e-05,
      "loss": 0.3285,
      "step": 435
    },
    {
      "epoch": 0.018776137236493982,
      "grad_norm": 0.05034906417131424,
      "learning_rate": 9.847615725553456e-05,
      "loss": 0.2996,
      "step": 440
    },
    {
      "epoch": 0.018989502432363234,
      "grad_norm": 0.03803911432623863,
      "learning_rate": 9.843704004290392e-05,
      "loss": 0.3311,
      "step": 445
    },
    {
      "epoch": 0.019202867628232482,
      "grad_norm": 0.026636559516191483,
      "learning_rate": 9.839743506981782e-05,
      "loss": 0.3264,
      "step": 450
    },
    {
      "epoch": 0.019416232824101733,
      "grad_norm": 0.03475625067949295,
      "learning_rate": 9.835734273509786e-05,
      "loss": 0.3127,
      "step": 455
    },
    {
      "epoch": 0.01962959801997098,
      "grad_norm": 0.034204330295324326,
      "learning_rate": 9.831676344247342e-05,
      "loss": 0.269,
      "step": 460
    },
    {
      "epoch": 0.019842963215840233,
      "grad_norm": 0.035325467586517334,
      "learning_rate": 9.827569760057755e-05,
      "loss": 0.2725,
      "step": 465
    },
    {
      "epoch": 0.02005632841170948,
      "grad_norm": 0.02739345096051693,
      "learning_rate": 9.82341456229428e-05,
      "loss": 0.2961,
      "step": 470
    },
    {
      "epoch": 0.020269693607578732,
      "grad_norm": 0.07521704584360123,
      "learning_rate": 9.819210792799712e-05,
      "loss": 0.3308,
      "step": 475
    },
    {
      "epoch": 0.02048305880344798,
      "grad_norm": 0.11195027828216553,
      "learning_rate": 9.814958493905963e-05,
      "loss": 0.3328,
      "step": 480
    },
    {
      "epoch": 0.02069642399931723,
      "grad_norm": 0.030925286933779716,
      "learning_rate": 9.810657708433637e-05,
      "loss": 0.3128,
      "step": 485
    },
    {
      "epoch": 0.02090978919518648,
      "grad_norm": 0.035490475594997406,
      "learning_rate": 9.806308479691595e-05,
      "loss": 0.279,
      "step": 490
    },
    {
      "epoch": 0.02112315439105573,
      "grad_norm": 0.0735531598329544,
      "learning_rate": 9.801910851476523e-05,
      "loss": 0.3455,
      "step": 495
    },
    {
      "epoch": 0.02133651958692498,
      "grad_norm": 0.029140891507267952,
      "learning_rate": 9.797464868072488e-05,
      "loss": 0.3824,
      "step": 500
    },
    {
      "epoch": 0.02154988478279423,
      "grad_norm": 0.040087923407554626,
      "learning_rate": 9.792970574250493e-05,
      "loss": 0.3149,
      "step": 505
    },
    {
      "epoch": 0.021763249978663482,
      "grad_norm": 0.04935041069984436,
      "learning_rate": 9.788428015268027e-05,
      "loss": 0.3153,
      "step": 510
    },
    {
      "epoch": 0.02197661517453273,
      "grad_norm": 0.03310387581586838,
      "learning_rate": 9.783837236868609e-05,
      "loss": 0.2722,
      "step": 515
    },
    {
      "epoch": 0.02218998037040198,
      "grad_norm": 0.02964087948203087,
      "learning_rate": 9.779198285281325e-05,
      "loss": 0.3128,
      "step": 520
    },
    {
      "epoch": 0.02240334556627123,
      "grad_norm": 0.06069183722138405,
      "learning_rate": 9.77451120722037e-05,
      "loss": 0.3058,
      "step": 525
    },
    {
      "epoch": 0.02261671076214048,
      "grad_norm": 0.06223162263631821,
      "learning_rate": 9.769776049884563e-05,
      "loss": 0.312,
      "step": 530
    },
    {
      "epoch": 0.02283007595800973,
      "grad_norm": 0.044999465346336365,
      "learning_rate": 9.764992860956889e-05,
      "loss": 0.3001,
      "step": 535
    },
    {
      "epoch": 0.02304344115387898,
      "grad_norm": 0.04808852821588516,
      "learning_rate": 9.760161688604008e-05,
      "loss": 0.273,
      "step": 540
    },
    {
      "epoch": 0.02325680634974823,
      "grad_norm": 0.018572229892015457,
      "learning_rate": 9.755282581475769e-05,
      "loss": 0.2526,
      "step": 545
    },
    {
      "epoch": 0.02347017154561748,
      "grad_norm": 0.03439535200595856,
      "learning_rate": 9.750355588704727e-05,
      "loss": 0.3184,
      "step": 550
    },
    {
      "epoch": 0.023683536741486728,
      "grad_norm": 0.05634547024965286,
      "learning_rate": 9.745380759905647e-05,
      "loss": 0.3584,
      "step": 555
    },
    {
      "epoch": 0.02389690193735598,
      "grad_norm": 0.0630321204662323,
      "learning_rate": 9.740358145174998e-05,
      "loss": 0.2518,
      "step": 560
    },
    {
      "epoch": 0.024110267133225227,
      "grad_norm": 0.026363343000411987,
      "learning_rate": 9.735287795090455e-05,
      "loss": 0.2977,
      "step": 565
    },
    {
      "epoch": 0.02432363232909448,
      "grad_norm": 0.040619298815727234,
      "learning_rate": 9.730169760710386e-05,
      "loss": 0.2847,
      "step": 570
    },
    {
      "epoch": 0.024536997524963727,
      "grad_norm": 0.01808500662446022,
      "learning_rate": 9.725004093573342e-05,
      "loss": 0.2921,
      "step": 575
    },
    {
      "epoch": 0.024750362720832978,
      "grad_norm": 0.046795934438705444,
      "learning_rate": 9.719790845697533e-05,
      "loss": 0.2694,
      "step": 580
    },
    {
      "epoch": 0.024963727916702226,
      "grad_norm": 0.036702100187540054,
      "learning_rate": 9.714530069580309e-05,
      "loss": 0.3257,
      "step": 585
    },
    {
      "epoch": 0.025177093112571478,
      "grad_norm": 0.050856996327638626,
      "learning_rate": 9.709221818197624e-05,
      "loss": 0.3452,
      "step": 590
    },
    {
      "epoch": 0.025390458308440726,
      "grad_norm": 0.048253726214170456,
      "learning_rate": 9.703866145003511e-05,
      "loss": 0.3845,
      "step": 595
    },
    {
      "epoch": 0.025603823504309977,
      "grad_norm": 0.03832037001848221,
      "learning_rate": 9.698463103929542e-05,
      "loss": 0.3196,
      "step": 600
    },
    {
      "epoch": 0.02581718870017923,
      "grad_norm": 0.03219674900174141,
      "learning_rate": 9.693012749384279e-05,
      "loss": 0.2777,
      "step": 605
    },
    {
      "epoch": 0.026030553896048476,
      "grad_norm": 0.03412896394729614,
      "learning_rate": 9.687515136252731e-05,
      "loss": 0.3041,
      "step": 610
    },
    {
      "epoch": 0.026243919091917728,
      "grad_norm": 0.04074668884277344,
      "learning_rate": 9.681970319895803e-05,
      "loss": 0.3104,
      "step": 615
    },
    {
      "epoch": 0.026457284287786976,
      "grad_norm": 0.062356870621442795,
      "learning_rate": 9.676378356149734e-05,
      "loss": 0.3352,
      "step": 620
    },
    {
      "epoch": 0.026670649483656227,
      "grad_norm": 0.027655797079205513,
      "learning_rate": 9.670739301325534e-05,
      "loss": 0.2813,
      "step": 625
    },
    {
      "epoch": 0.026884014679525475,
      "grad_norm": 0.04658840224146843,
      "learning_rate": 9.665053212208426e-05,
      "loss": 0.2847,
      "step": 630
    },
    {
      "epoch": 0.027097379875394727,
      "grad_norm": 0.09305604547262192,
      "learning_rate": 9.659320146057262e-05,
      "loss": 0.3345,
      "step": 635
    },
    {
      "epoch": 0.027310745071263975,
      "grad_norm": 0.10578807443380356,
      "learning_rate": 9.653540160603956e-05,
      "loss": 0.3111,
      "step": 640
    },
    {
      "epoch": 0.027524110267133226,
      "grad_norm": 0.02678944170475006,
      "learning_rate": 9.647713314052896e-05,
      "loss": 0.2757,
      "step": 645
    },
    {
      "epoch": 0.027737475463002474,
      "grad_norm": 0.03380942717194557,
      "learning_rate": 9.641839665080363e-05,
      "loss": 0.2598,
      "step": 650
    },
    {
      "epoch": 0.027950840658871726,
      "grad_norm": 0.04207558184862137,
      "learning_rate": 9.635919272833938e-05,
      "loss": 0.2646,
      "step": 655
    },
    {
      "epoch": 0.028164205854740974,
      "grad_norm": 0.047386348247528076,
      "learning_rate": 9.629952196931901e-05,
      "loss": 0.3282,
      "step": 660
    },
    {
      "epoch": 0.028377571050610225,
      "grad_norm": 0.02409733086824417,
      "learning_rate": 9.623938497462646e-05,
      "loss": 0.2972,
      "step": 665
    },
    {
      "epoch": 0.028590936246479473,
      "grad_norm": 0.029774650931358337,
      "learning_rate": 9.617878234984055e-05,
      "loss": 0.3025,
      "step": 670
    },
    {
      "epoch": 0.028804301442348725,
      "grad_norm": 0.03071901574730873,
      "learning_rate": 9.611771470522908e-05,
      "loss": 0.3262,
      "step": 675
    },
    {
      "epoch": 0.029017666638217973,
      "grad_norm": 0.03461213409900665,
      "learning_rate": 9.60561826557425e-05,
      "loss": 0.3209,
      "step": 680
    },
    {
      "epoch": 0.029231031834087224,
      "grad_norm": 0.027064334601163864,
      "learning_rate": 9.599418682100793e-05,
      "loss": 0.2786,
      "step": 685
    },
    {
      "epoch": 0.029444397029956472,
      "grad_norm": 0.031094921752810478,
      "learning_rate": 9.593172782532268e-05,
      "loss": 0.2697,
      "step": 690
    },
    {
      "epoch": 0.029657762225825723,
      "grad_norm": 0.028905808925628662,
      "learning_rate": 9.586880629764817e-05,
      "loss": 0.2967,
      "step": 695
    },
    {
      "epoch": 0.02987112742169497,
      "grad_norm": 0.03242633864283562,
      "learning_rate": 9.580542287160348e-05,
      "loss": 0.3165,
      "step": 700
    },
    {
      "epoch": 0.030084492617564223,
      "grad_norm": 0.03664035350084305,
      "learning_rate": 9.574157818545901e-05,
      "loss": 0.324,
      "step": 705
    },
    {
      "epoch": 0.030297857813433474,
      "grad_norm": 0.03862154856324196,
      "learning_rate": 9.567727288213005e-05,
      "loss": 0.3218,
      "step": 710
    },
    {
      "epoch": 0.030511223009302722,
      "grad_norm": 0.029502928256988525,
      "learning_rate": 9.561250760917027e-05,
      "loss": 0.2832,
      "step": 715
    },
    {
      "epoch": 0.030724588205171974,
      "grad_norm": 0.04643407091498375,
      "learning_rate": 9.554728301876526e-05,
      "loss": 0.2624,
      "step": 720
    },
    {
      "epoch": 0.030937953401041222,
      "grad_norm": 0.03219695761799812,
      "learning_rate": 9.548159976772592e-05,
      "loss": 0.2889,
      "step": 725
    },
    {
      "epoch": 0.031151318596910473,
      "grad_norm": 0.044360432773828506,
      "learning_rate": 9.541545851748186e-05,
      "loss": 0.3103,
      "step": 730
    },
    {
      "epoch": 0.03136468379277972,
      "grad_norm": 0.02901867777109146,
      "learning_rate": 9.534885993407474e-05,
      "loss": 0.3068,
      "step": 735
    },
    {
      "epoch": 0.03157804898864897,
      "grad_norm": 0.03267716243863106,
      "learning_rate": 9.528180468815155e-05,
      "loss": 0.2765,
      "step": 740
    },
    {
      "epoch": 0.031791414184518224,
      "grad_norm": 0.046168915927410126,
      "learning_rate": 9.521429345495787e-05,
      "loss": 0.3334,
      "step": 745
    },
    {
      "epoch": 0.03200477938038747,
      "grad_norm": 0.048181407153606415,
      "learning_rate": 9.514632691433107e-05,
      "loss": 0.3146,
      "step": 750
    },
    {
      "epoch": 0.03221814457625672,
      "grad_norm": 0.02444417215883732,
      "learning_rate": 9.507790575069347e-05,
      "loss": 0.2972,
      "step": 755
    },
    {
      "epoch": 0.03243150977212597,
      "grad_norm": 0.04914536699652672,
      "learning_rate": 9.50090306530454e-05,
      "loss": 0.3135,
      "step": 760
    },
    {
      "epoch": 0.03264487496799522,
      "grad_norm": 0.035306770354509354,
      "learning_rate": 9.493970231495835e-05,
      "loss": 0.3298,
      "step": 765
    },
    {
      "epoch": 0.03285824016386447,
      "grad_norm": 0.06596852093935013,
      "learning_rate": 9.486992143456792e-05,
      "loss": 0.3253,
      "step": 770
    },
    {
      "epoch": 0.03307160535973372,
      "grad_norm": 0.03253694251179695,
      "learning_rate": 9.479968871456679e-05,
      "loss": 0.2654,
      "step": 775
    },
    {
      "epoch": 0.03328497055560297,
      "grad_norm": 0.05699998512864113,
      "learning_rate": 9.472900486219769e-05,
      "loss": 0.3685,
      "step": 780
    },
    {
      "epoch": 0.03349833575147222,
      "grad_norm": 0.05977329984307289,
      "learning_rate": 9.46578705892462e-05,
      "loss": 0.3123,
      "step": 785
    },
    {
      "epoch": 0.033711700947341466,
      "grad_norm": 0.03356384113430977,
      "learning_rate": 9.458628661203367e-05,
      "loss": 0.3225,
      "step": 790
    },
    {
      "epoch": 0.03392506614321072,
      "grad_norm": 0.06818829476833344,
      "learning_rate": 9.451425365140996e-05,
      "loss": 0.3291,
      "step": 795
    },
    {
      "epoch": 0.03413843133907997,
      "grad_norm": 0.03218923509120941,
      "learning_rate": 9.444177243274618e-05,
      "loss": 0.2989,
      "step": 800
    },
    {
      "epoch": 0.03435179653494922,
      "grad_norm": 0.02792300656437874,
      "learning_rate": 9.43688436859274e-05,
      "loss": 0.3214,
      "step": 805
    },
    {
      "epoch": 0.03456516173081847,
      "grad_norm": 0.026786861941218376,
      "learning_rate": 9.429546814534529e-05,
      "loss": 0.2758,
      "step": 810
    },
    {
      "epoch": 0.03477852692668772,
      "grad_norm": 0.03266213834285736,
      "learning_rate": 9.422164654989072e-05,
      "loss": 0.291,
      "step": 815
    },
    {
      "epoch": 0.03499189212255697,
      "grad_norm": 0.04392775893211365,
      "learning_rate": 9.414737964294636e-05,
      "loss": 0.3133,
      "step": 820
    },
    {
      "epoch": 0.03520525731842622,
      "grad_norm": 0.06800848990678787,
      "learning_rate": 9.407266817237911e-05,
      "loss": 0.2698,
      "step": 825
    },
    {
      "epoch": 0.03541862251429547,
      "grad_norm": 0.0510174036026001,
      "learning_rate": 9.399751289053267e-05,
      "loss": 0.285,
      "step": 830
    },
    {
      "epoch": 0.035631987710164716,
      "grad_norm": 0.03984105587005615,
      "learning_rate": 9.392191455421988e-05,
      "loss": 0.2985,
      "step": 835
    },
    {
      "epoch": 0.03584535290603397,
      "grad_norm": 0.03444138541817665,
      "learning_rate": 9.384587392471515e-05,
      "loss": 0.2674,
      "step": 840
    },
    {
      "epoch": 0.03605871810190322,
      "grad_norm": 0.049355775117874146,
      "learning_rate": 9.376939176774679e-05,
      "loss": 0.2976,
      "step": 845
    },
    {
      "epoch": 0.03627208329777247,
      "grad_norm": 0.03635568916797638,
      "learning_rate": 9.369246885348926e-05,
      "loss": 0.2956,
      "step": 850
    },
    {
      "epoch": 0.036485448493641714,
      "grad_norm": 0.04686814919114113,
      "learning_rate": 9.361510595655545e-05,
      "loss": 0.3187,
      "step": 855
    },
    {
      "epoch": 0.036698813689510966,
      "grad_norm": 0.044731322675943375,
      "learning_rate": 9.353730385598887e-05,
      "loss": 0.2419,
      "step": 860
    },
    {
      "epoch": 0.03691217888538022,
      "grad_norm": 0.039150986820459366,
      "learning_rate": 9.345906333525581e-05,
      "loss": 0.3214,
      "step": 865
    },
    {
      "epoch": 0.03712554408124947,
      "grad_norm": 0.025934845209121704,
      "learning_rate": 9.338038518223747e-05,
      "loss": 0.2451,
      "step": 870
    },
    {
      "epoch": 0.03733890927711871,
      "grad_norm": 0.04700668156147003,
      "learning_rate": 9.330127018922194e-05,
      "loss": 0.2999,
      "step": 875
    },
    {
      "epoch": 0.037552274472987965,
      "grad_norm": 0.037765342742204666,
      "learning_rate": 9.322171915289635e-05,
      "loss": 0.2838,
      "step": 880
    },
    {
      "epoch": 0.037765639668857216,
      "grad_norm": 0.025620363652706146,
      "learning_rate": 9.314173287433873e-05,
      "loss": 0.2976,
      "step": 885
    },
    {
      "epoch": 0.03797900486472647,
      "grad_norm": 0.04109512269496918,
      "learning_rate": 9.306131215901003e-05,
      "loss": 0.3003,
      "step": 890
    },
    {
      "epoch": 0.03819237006059571,
      "grad_norm": 0.02608657069504261,
      "learning_rate": 9.298045781674596e-05,
      "loss": 0.2887,
      "step": 895
    },
    {
      "epoch": 0.038405735256464964,
      "grad_norm": 0.02382752299308777,
      "learning_rate": 9.289917066174886e-05,
      "loss": 0.3295,
      "step": 900
    },
    {
      "epoch": 0.038619100452334215,
      "grad_norm": 0.040469031780958176,
      "learning_rate": 9.281745151257946e-05,
      "loss": 0.341,
      "step": 905
    },
    {
      "epoch": 0.03883246564820347,
      "grad_norm": 0.046035751700401306,
      "learning_rate": 9.273530119214868e-05,
      "loss": 0.2912,
      "step": 910
    },
    {
      "epoch": 0.03904583084407272,
      "grad_norm": 0.025035373866558075,
      "learning_rate": 9.265272052770936e-05,
      "loss": 0.2892,
      "step": 915
    },
    {
      "epoch": 0.03925919603994196,
      "grad_norm": 0.060057301074266434,
      "learning_rate": 9.256971035084785e-05,
      "loss": 0.3036,
      "step": 920
    },
    {
      "epoch": 0.039472561235811214,
      "grad_norm": 0.030372150242328644,
      "learning_rate": 9.248627149747573e-05,
      "loss": 0.2765,
      "step": 925
    },
    {
      "epoch": 0.039685926431680466,
      "grad_norm": 0.041626475751399994,
      "learning_rate": 9.24024048078213e-05,
      "loss": 0.3225,
      "step": 930
    },
    {
      "epoch": 0.03989929162754972,
      "grad_norm": 0.04169540852308273,
      "learning_rate": 9.231811112642121e-05,
      "loss": 0.3089,
      "step": 935
    },
    {
      "epoch": 0.04011265682341896,
      "grad_norm": 0.035264741629362106,
      "learning_rate": 9.223339130211192e-05,
      "loss": 0.3602,
      "step": 940
    },
    {
      "epoch": 0.04032602201928821,
      "grad_norm": 0.017377423122525215,
      "learning_rate": 9.214824618802109e-05,
      "loss": 0.3194,
      "step": 945
    },
    {
      "epoch": 0.040539387215157464,
      "grad_norm": 0.04722890257835388,
      "learning_rate": 9.206267664155907e-05,
      "loss": 0.2701,
      "step": 950
    },
    {
      "epoch": 0.040752752411026716,
      "grad_norm": 0.04383736848831177,
      "learning_rate": 9.197668352441025e-05,
      "loss": 0.3633,
      "step": 955
    },
    {
      "epoch": 0.04096611760689596,
      "grad_norm": 0.03514501452445984,
      "learning_rate": 9.189026770252436e-05,
      "loss": 0.2526,
      "step": 960
    },
    {
      "epoch": 0.04117948280276521,
      "grad_norm": 0.04011779651045799,
      "learning_rate": 9.18034300461078e-05,
      "loss": 0.2568,
      "step": 965
    },
    {
      "epoch": 0.04139284799863446,
      "grad_norm": 0.04268975183367729,
      "learning_rate": 9.171617142961477e-05,
      "loss": 0.3358,
      "step": 970
    },
    {
      "epoch": 0.041606213194503715,
      "grad_norm": 0.056539736688137054,
      "learning_rate": 9.162849273173857e-05,
      "loss": 0.2417,
      "step": 975
    },
    {
      "epoch": 0.04181957839037296,
      "grad_norm": 0.05925797298550606,
      "learning_rate": 9.154039483540273e-05,
      "loss": 0.3116,
      "step": 980
    },
    {
      "epoch": 0.04203294358624221,
      "grad_norm": 0.02750694751739502,
      "learning_rate": 9.145187862775209e-05,
      "loss": 0.2386,
      "step": 985
    },
    {
      "epoch": 0.04224630878211146,
      "grad_norm": 0.06588881462812424,
      "learning_rate": 9.136294500014386e-05,
      "loss": 0.3231,
      "step": 990
    },
    {
      "epoch": 0.042459673977980714,
      "grad_norm": 0.06240357831120491,
      "learning_rate": 9.12735948481387e-05,
      "loss": 0.3082,
      "step": 995
    },
    {
      "epoch": 0.04267303917384996,
      "grad_norm": 0.065621517598629,
      "learning_rate": 9.118382907149165e-05,
      "loss": 0.3256,
      "step": 1000
    }
  ],
  "logging_steps": 5,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.712744975930163e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
