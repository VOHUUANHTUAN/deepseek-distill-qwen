{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.21336519586924982,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0002133651958692498,
      "grad_norm": 0.03956512361764908,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.2912,
      "step": 5
    },
    {
      "epoch": 0.0004267303917384996,
      "grad_norm": 0.026892080903053284,
      "learning_rate": 1.8e-05,
      "loss": 0.3556,
      "step": 10
    },
    {
      "epoch": 0.0006400955876077494,
      "grad_norm": 0.019087420776486397,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.3441,
      "step": 15
    },
    {
      "epoch": 0.0008534607834769992,
      "grad_norm": 0.049927301704883575,
      "learning_rate": 3.8e-05,
      "loss": 0.3541,
      "step": 20
    },
    {
      "epoch": 0.001066825979346249,
      "grad_norm": 0.044411927461624146,
      "learning_rate": 4.8e-05,
      "loss": 0.3493,
      "step": 25
    },
    {
      "epoch": 0.0012801911752154988,
      "grad_norm": 0.030033458024263382,
      "learning_rate": 5.8e-05,
      "loss": 0.3193,
      "step": 30
    },
    {
      "epoch": 0.0014935563710847487,
      "grad_norm": 0.022057926282286644,
      "learning_rate": 6.800000000000001e-05,
      "loss": 0.3917,
      "step": 35
    },
    {
      "epoch": 0.0017069215669539984,
      "grad_norm": 0.027298463508486748,
      "learning_rate": 7.800000000000001e-05,
      "loss": 0.3546,
      "step": 40
    },
    {
      "epoch": 0.0019202867628232484,
      "grad_norm": 0.042551398277282715,
      "learning_rate": 8.800000000000001e-05,
      "loss": 0.3263,
      "step": 45
    },
    {
      "epoch": 0.002133651958692498,
      "grad_norm": 0.022645611315965652,
      "learning_rate": 9.8e-05,
      "loss": 0.2995,
      "step": 50
    },
    {
      "epoch": 0.002347017154561748,
      "grad_norm": 0.026563460007309914,
      "learning_rate": 9.999983888012897e-05,
      "loss": 0.3502,
      "step": 55
    },
    {
      "epoch": 0.0025603823504309975,
      "grad_norm": 0.01827406883239746,
      "learning_rate": 9.999918433243251e-05,
      "loss": 0.2708,
      "step": 60
    },
    {
      "epoch": 0.0027737475463002477,
      "grad_norm": 0.024904195219278336,
      "learning_rate": 9.999802629350492e-05,
      "loss": 0.3382,
      "step": 65
    },
    {
      "epoch": 0.0029871127421694974,
      "grad_norm": 0.036995697766542435,
      "learning_rate": 9.999636477500764e-05,
      "loss": 0.3457,
      "step": 70
    },
    {
      "epoch": 0.003200477938038747,
      "grad_norm": 0.026742354035377502,
      "learning_rate": 9.999419979367214e-05,
      "loss": 0.2769,
      "step": 75
    },
    {
      "epoch": 0.003413843133907997,
      "grad_norm": 0.02795397862792015,
      "learning_rate": 9.999153137129977e-05,
      "loss": 0.3408,
      "step": 80
    },
    {
      "epoch": 0.0036272083297772466,
      "grad_norm": 0.035124994814395905,
      "learning_rate": 9.998835953476149e-05,
      "loss": 0.2974,
      "step": 85
    },
    {
      "epoch": 0.0038405735256464967,
      "grad_norm": 0.017137659713625908,
      "learning_rate": 9.998468431599768e-05,
      "loss": 0.2847,
      "step": 90
    },
    {
      "epoch": 0.0040539387215157464,
      "grad_norm": 0.029370715841650963,
      "learning_rate": 9.998050575201771e-05,
      "loss": 0.3222,
      "step": 95
    },
    {
      "epoch": 0.004267303917384996,
      "grad_norm": 0.025762202218174934,
      "learning_rate": 9.997582388489975e-05,
      "loss": 0.333,
      "step": 100
    },
    {
      "epoch": 0.004480669113254246,
      "grad_norm": 0.0271734781563282,
      "learning_rate": 9.997063876179006e-05,
      "loss": 0.3193,
      "step": 105
    },
    {
      "epoch": 0.004694034309123496,
      "grad_norm": 0.030140260234475136,
      "learning_rate": 9.996495043490285e-05,
      "loss": 0.3117,
      "step": 110
    },
    {
      "epoch": 0.004907399504992745,
      "grad_norm": 0.036636028438806534,
      "learning_rate": 9.995875896151947e-05,
      "loss": 0.2947,
      "step": 115
    },
    {
      "epoch": 0.005120764700861995,
      "grad_norm": 0.0498843677341938,
      "learning_rate": 9.995206440398798e-05,
      "loss": 0.2985,
      "step": 120
    },
    {
      "epoch": 0.005334129896731245,
      "grad_norm": 0.025191377848386765,
      "learning_rate": 9.994486682972253e-05,
      "loss": 0.2562,
      "step": 125
    },
    {
      "epoch": 0.005547495092600495,
      "grad_norm": 0.029922764748334885,
      "learning_rate": 9.993716631120258e-05,
      "loss": 0.3397,
      "step": 130
    },
    {
      "epoch": 0.005760860288469745,
      "grad_norm": 0.020917952060699463,
      "learning_rate": 9.992896292597229e-05,
      "loss": 0.243,
      "step": 135
    },
    {
      "epoch": 0.005974225484338995,
      "grad_norm": 0.02735038846731186,
      "learning_rate": 9.992025675663965e-05,
      "loss": 0.278,
      "step": 140
    },
    {
      "epoch": 0.0061875906802082445,
      "grad_norm": 0.025983858853578568,
      "learning_rate": 9.991104789087569e-05,
      "loss": 0.2887,
      "step": 145
    },
    {
      "epoch": 0.006400955876077494,
      "grad_norm": 0.03666191175580025,
      "learning_rate": 9.990133642141359e-05,
      "loss": 0.286,
      "step": 150
    },
    {
      "epoch": 0.006614321071946744,
      "grad_norm": 0.03475484624505043,
      "learning_rate": 9.989112244604772e-05,
      "loss": 0.2599,
      "step": 155
    },
    {
      "epoch": 0.006827686267815994,
      "grad_norm": 0.05559298396110535,
      "learning_rate": 9.988040606763272e-05,
      "loss": 0.2761,
      "step": 160
    },
    {
      "epoch": 0.007041051463685243,
      "grad_norm": 0.035263437777757645,
      "learning_rate": 9.98691873940824e-05,
      "loss": 0.2475,
      "step": 165
    },
    {
      "epoch": 0.007254416659554493,
      "grad_norm": 0.033193107694387436,
      "learning_rate": 9.985746653836868e-05,
      "loss": 0.3035,
      "step": 170
    },
    {
      "epoch": 0.007467781855423743,
      "grad_norm": 0.028311358764767647,
      "learning_rate": 9.984524361852043e-05,
      "loss": 0.2552,
      "step": 175
    },
    {
      "epoch": 0.0076811470512929934,
      "grad_norm": 0.03438667953014374,
      "learning_rate": 9.983251875762232e-05,
      "loss": 0.2799,
      "step": 180
    },
    {
      "epoch": 0.007894512247162243,
      "grad_norm": 0.02185436338186264,
      "learning_rate": 9.981929208381358e-05,
      "loss": 0.2991,
      "step": 185
    },
    {
      "epoch": 0.008107877443031493,
      "grad_norm": 0.02376946620643139,
      "learning_rate": 9.980556373028665e-05,
      "loss": 0.3105,
      "step": 190
    },
    {
      "epoch": 0.008321242638900743,
      "grad_norm": 0.029226215556263924,
      "learning_rate": 9.97913338352859e-05,
      "loss": 0.3108,
      "step": 195
    },
    {
      "epoch": 0.008534607834769992,
      "grad_norm": 0.038026366382837296,
      "learning_rate": 9.977660254210622e-05,
      "loss": 0.2667,
      "step": 200
    },
    {
      "epoch": 0.008747973030639242,
      "grad_norm": 0.04829779267311096,
      "learning_rate": 9.976136999909156e-05,
      "loss": 0.3241,
      "step": 205
    },
    {
      "epoch": 0.008961338226508492,
      "grad_norm": 0.029476888477802277,
      "learning_rate": 9.974563635963347e-05,
      "loss": 0.2823,
      "step": 210
    },
    {
      "epoch": 0.009174703422377741,
      "grad_norm": 0.039745256304740906,
      "learning_rate": 9.972940178216951e-05,
      "loss": 0.289,
      "step": 215
    },
    {
      "epoch": 0.009388068618246991,
      "grad_norm": 0.03090384230017662,
      "learning_rate": 9.97126664301817e-05,
      "loss": 0.2866,
      "step": 220
    },
    {
      "epoch": 0.009601433814116241,
      "grad_norm": 0.030000466853380203,
      "learning_rate": 9.969543047219488e-05,
      "loss": 0.2715,
      "step": 225
    },
    {
      "epoch": 0.00981479900998549,
      "grad_norm": 0.043920259922742844,
      "learning_rate": 9.96776940817749e-05,
      "loss": 0.304,
      "step": 230
    },
    {
      "epoch": 0.01002816420585474,
      "grad_norm": 0.02307508885860443,
      "learning_rate": 9.965945743752706e-05,
      "loss": 0.2816,
      "step": 235
    },
    {
      "epoch": 0.01024152940172399,
      "grad_norm": 0.02746823988854885,
      "learning_rate": 9.964072072309412e-05,
      "loss": 0.3025,
      "step": 240
    },
    {
      "epoch": 0.01045489459759324,
      "grad_norm": 0.039521701633930206,
      "learning_rate": 9.962148412715463e-05,
      "loss": 0.3056,
      "step": 245
    },
    {
      "epoch": 0.01066825979346249,
      "grad_norm": 0.031297482550144196,
      "learning_rate": 9.96017478434209e-05,
      "loss": 0.2829,
      "step": 250
    },
    {
      "epoch": 0.010881624989331741,
      "grad_norm": 0.035057831555604935,
      "learning_rate": 9.958151207063704e-05,
      "loss": 0.2939,
      "step": 255
    },
    {
      "epoch": 0.01109499018520099,
      "grad_norm": 0.03763855993747711,
      "learning_rate": 9.956077701257709e-05,
      "loss": 0.3064,
      "step": 260
    },
    {
      "epoch": 0.01130835538107024,
      "grad_norm": 0.0317029133439064,
      "learning_rate": 9.953954287804286e-05,
      "loss": 0.2673,
      "step": 265
    },
    {
      "epoch": 0.01152172057693949,
      "grad_norm": 0.03794080391526222,
      "learning_rate": 9.951780988086184e-05,
      "loss": 0.2456,
      "step": 270
    },
    {
      "epoch": 0.01173508577280874,
      "grad_norm": 0.036909155547618866,
      "learning_rate": 9.949557823988507e-05,
      "loss": 0.3187,
      "step": 275
    },
    {
      "epoch": 0.01194845096867799,
      "grad_norm": 0.019808480516076088,
      "learning_rate": 9.947284817898492e-05,
      "loss": 0.2997,
      "step": 280
    },
    {
      "epoch": 0.01216181616454724,
      "grad_norm": 0.04877963662147522,
      "learning_rate": 9.944961992705288e-05,
      "loss": 0.274,
      "step": 285
    },
    {
      "epoch": 0.012375181360416489,
      "grad_norm": 0.03313374146819115,
      "learning_rate": 9.942589371799714e-05,
      "loss": 0.2744,
      "step": 290
    },
    {
      "epoch": 0.012588546556285739,
      "grad_norm": 0.039932895451784134,
      "learning_rate": 9.940166979074041e-05,
      "loss": 0.3311,
      "step": 295
    },
    {
      "epoch": 0.012801911752154988,
      "grad_norm": 0.0462551973760128,
      "learning_rate": 9.937694838921734e-05,
      "loss": 0.3019,
      "step": 300
    },
    {
      "epoch": 0.013015276948024238,
      "grad_norm": 0.03281445801258087,
      "learning_rate": 9.935172976237219e-05,
      "loss": 0.296,
      "step": 305
    },
    {
      "epoch": 0.013228642143893488,
      "grad_norm": 0.04639114439487457,
      "learning_rate": 9.932601416415622e-05,
      "loss": 0.251,
      "step": 310
    },
    {
      "epoch": 0.013442007339762738,
      "grad_norm": 0.033200785517692566,
      "learning_rate": 9.929980185352526e-05,
      "loss": 0.2643,
      "step": 315
    },
    {
      "epoch": 0.013655372535631987,
      "grad_norm": 0.059455133974552155,
      "learning_rate": 9.927309309443695e-05,
      "loss": 0.3027,
      "step": 320
    },
    {
      "epoch": 0.013868737731501237,
      "grad_norm": 0.03329530358314514,
      "learning_rate": 9.924588815584821e-05,
      "loss": 0.2748,
      "step": 325
    },
    {
      "epoch": 0.014082102927370487,
      "grad_norm": 0.04291178286075592,
      "learning_rate": 9.921818731171248e-05,
      "loss": 0.3053,
      "step": 330
    },
    {
      "epoch": 0.014295468123239737,
      "grad_norm": 0.04888489842414856,
      "learning_rate": 9.918999084097695e-05,
      "loss": 0.2547,
      "step": 335
    },
    {
      "epoch": 0.014508833319108986,
      "grad_norm": 0.032774556428194046,
      "learning_rate": 9.916129902757975e-05,
      "loss": 0.304,
      "step": 340
    },
    {
      "epoch": 0.014722198514978236,
      "grad_norm": 0.0315607488155365,
      "learning_rate": 9.913211216044715e-05,
      "loss": 0.2548,
      "step": 345
    },
    {
      "epoch": 0.014935563710847486,
      "grad_norm": 0.0493784137070179,
      "learning_rate": 9.910243053349056e-05,
      "loss": 0.3135,
      "step": 350
    },
    {
      "epoch": 0.015148928906716737,
      "grad_norm": 0.05833929032087326,
      "learning_rate": 9.907225444560361e-05,
      "loss": 0.3478,
      "step": 355
    },
    {
      "epoch": 0.015362294102585987,
      "grad_norm": 0.029205884784460068,
      "learning_rate": 9.904158420065923e-05,
      "loss": 0.2843,
      "step": 360
    },
    {
      "epoch": 0.015575659298455237,
      "grad_norm": 0.0377034917473793,
      "learning_rate": 9.90104201075064e-05,
      "loss": 0.2964,
      "step": 365
    },
    {
      "epoch": 0.015789024494324486,
      "grad_norm": 0.030159292742609978,
      "learning_rate": 9.89787624799672e-05,
      "loss": 0.2685,
      "step": 370
    },
    {
      "epoch": 0.016002389690193734,
      "grad_norm": 0.036340050399303436,
      "learning_rate": 9.894661163683361e-05,
      "loss": 0.2268,
      "step": 375
    },
    {
      "epoch": 0.016215754886062986,
      "grad_norm": 0.05141959339380264,
      "learning_rate": 9.891396790186424e-05,
      "loss": 0.3012,
      "step": 380
    },
    {
      "epoch": 0.016429120081932234,
      "grad_norm": 0.04116874560713768,
      "learning_rate": 9.888083160378113e-05,
      "loss": 0.2771,
      "step": 385
    },
    {
      "epoch": 0.016642485277801485,
      "grad_norm": 0.058151938021183014,
      "learning_rate": 9.884720307626647e-05,
      "loss": 0.2545,
      "step": 390
    },
    {
      "epoch": 0.016855850473670733,
      "grad_norm": 0.02843770571053028,
      "learning_rate": 9.881308265795912e-05,
      "loss": 0.2771,
      "step": 395
    },
    {
      "epoch": 0.017069215669539985,
      "grad_norm": 0.03583540767431259,
      "learning_rate": 9.877847069245135e-05,
      "loss": 0.2641,
      "step": 400
    },
    {
      "epoch": 0.017282580865409236,
      "grad_norm": 0.040088776499032974,
      "learning_rate": 9.874336752828523e-05,
      "loss": 0.2966,
      "step": 405
    },
    {
      "epoch": 0.017495946061278484,
      "grad_norm": 0.021249419078230858,
      "learning_rate": 9.870777351894927e-05,
      "loss": 0.2784,
      "step": 410
    },
    {
      "epoch": 0.017709311257147736,
      "grad_norm": 0.03012305125594139,
      "learning_rate": 9.867168902287472e-05,
      "loss": 0.2781,
      "step": 415
    },
    {
      "epoch": 0.017922676453016984,
      "grad_norm": 0.03120175004005432,
      "learning_rate": 9.863511440343206e-05,
      "loss": 0.2494,
      "step": 420
    },
    {
      "epoch": 0.018136041648886235,
      "grad_norm": 0.028612149879336357,
      "learning_rate": 9.859805002892732e-05,
      "loss": 0.3296,
      "step": 425
    },
    {
      "epoch": 0.018349406844755483,
      "grad_norm": 0.036236971616744995,
      "learning_rate": 9.856049627259832e-05,
      "loss": 0.3047,
      "step": 430
    },
    {
      "epoch": 0.018562772040624734,
      "grad_norm": 0.03210485726594925,
      "learning_rate": 9.852245351261099e-05,
      "loss": 0.2968,
      "step": 435
    },
    {
      "epoch": 0.018776137236493982,
      "grad_norm": 0.04646575450897217,
      "learning_rate": 9.848392213205549e-05,
      "loss": 0.2641,
      "step": 440
    },
    {
      "epoch": 0.018989502432363234,
      "grad_norm": 0.03748751059174538,
      "learning_rate": 9.844490251894237e-05,
      "loss": 0.3013,
      "step": 445
    },
    {
      "epoch": 0.019202867628232482,
      "grad_norm": 0.024934103712439537,
      "learning_rate": 9.840539506619874e-05,
      "loss": 0.2977,
      "step": 450
    },
    {
      "epoch": 0.019416232824101733,
      "grad_norm": 0.033847201615571976,
      "learning_rate": 9.83654001716642e-05,
      "loss": 0.2806,
      "step": 455
    },
    {
      "epoch": 0.01962959801997098,
      "grad_norm": 0.025195877999067307,
      "learning_rate": 9.832491823808687e-05,
      "loss": 0.233,
      "step": 460
    },
    {
      "epoch": 0.019842963215840233,
      "grad_norm": 0.033992983400821686,
      "learning_rate": 9.828394967311941e-05,
      "loss": 0.2392,
      "step": 465
    },
    {
      "epoch": 0.02005632841170948,
      "grad_norm": 0.0265718512237072,
      "learning_rate": 9.824249488931476e-05,
      "loss": 0.2589,
      "step": 470
    },
    {
      "epoch": 0.020269693607578732,
      "grad_norm": 0.06975604593753815,
      "learning_rate": 9.82005543041222e-05,
      "loss": 0.2991,
      "step": 475
    },
    {
      "epoch": 0.02048305880344798,
      "grad_norm": 0.13323792815208435,
      "learning_rate": 9.815812833988291e-05,
      "loss": 0.308,
      "step": 480
    },
    {
      "epoch": 0.02069642399931723,
      "grad_norm": 0.030268529430031776,
      "learning_rate": 9.81152174238259e-05,
      "loss": 0.2791,
      "step": 485
    },
    {
      "epoch": 0.02090978919518648,
      "grad_norm": 0.033020928502082825,
      "learning_rate": 9.807182198806361e-05,
      "loss": 0.2459,
      "step": 490
    },
    {
      "epoch": 0.02112315439105573,
      "grad_norm": 0.07309115678071976,
      "learning_rate": 9.802794246958759e-05,
      "loss": 0.311,
      "step": 495
    },
    {
      "epoch": 0.02133651958692498,
      "grad_norm": 0.029171453788876534,
      "learning_rate": 9.798357931026412e-05,
      "loss": 0.3479,
      "step": 500
    },
    {
      "epoch": 0.02154988478279423,
      "grad_norm": 0.03804120793938637,
      "learning_rate": 9.793873295682971e-05,
      "loss": 0.2841,
      "step": 505
    },
    {
      "epoch": 0.021763249978663482,
      "grad_norm": 0.05005984008312225,
      "learning_rate": 9.789340386088663e-05,
      "loss": 0.2851,
      "step": 510
    },
    {
      "epoch": 0.02197661517453273,
      "grad_norm": 0.031944312155246735,
      "learning_rate": 9.784759247889841e-05,
      "loss": 0.2398,
      "step": 515
    },
    {
      "epoch": 0.02218998037040198,
      "grad_norm": 0.029352325946092606,
      "learning_rate": 9.780129927218513e-05,
      "loss": 0.2828,
      "step": 520
    },
    {
      "epoch": 0.02240334556627123,
      "grad_norm": 0.05619465559720993,
      "learning_rate": 9.775452470691886e-05,
      "loss": 0.2689,
      "step": 525
    },
    {
      "epoch": 0.02261671076214048,
      "grad_norm": 0.058790065348148346,
      "learning_rate": 9.770726925411897e-05,
      "loss": 0.2801,
      "step": 530
    },
    {
      "epoch": 0.02283007595800973,
      "grad_norm": 0.04221794009208679,
      "learning_rate": 9.765953338964735e-05,
      "loss": 0.2687,
      "step": 535
    },
    {
      "epoch": 0.02304344115387898,
      "grad_norm": 0.047739092260599136,
      "learning_rate": 9.76113175942036e-05,
      "loss": 0.2424,
      "step": 540
    },
    {
      "epoch": 0.02325680634974823,
      "grad_norm": 0.017963066697120667,
      "learning_rate": 9.756262235332029e-05,
      "loss": 0.2238,
      "step": 545
    },
    {
      "epoch": 0.02347017154561748,
      "grad_norm": 0.033997923135757446,
      "learning_rate": 9.751344815735792e-05,
      "loss": 0.2967,
      "step": 550
    },
    {
      "epoch": 0.023683536741486728,
      "grad_norm": 0.05463733524084091,
      "learning_rate": 9.746379550150009e-05,
      "loss": 0.3264,
      "step": 555
    },
    {
      "epoch": 0.02389690193735598,
      "grad_norm": 0.060959797352552414,
      "learning_rate": 9.74136648857485e-05,
      "loss": 0.2205,
      "step": 560
    },
    {
      "epoch": 0.024110267133225227,
      "grad_norm": 0.024205481633543968,
      "learning_rate": 9.73630568149179e-05,
      "loss": 0.2685,
      "step": 565
    },
    {
      "epoch": 0.02432363232909448,
      "grad_norm": 0.03931494429707527,
      "learning_rate": 9.731197179863103e-05,
      "loss": 0.2476,
      "step": 570
    },
    {
      "epoch": 0.024536997524963727,
      "grad_norm": 0.01846333034336567,
      "learning_rate": 9.72604103513134e-05,
      "loss": 0.2633,
      "step": 575
    },
    {
      "epoch": 0.024750362720832978,
      "grad_norm": 0.04539819806814194,
      "learning_rate": 9.72083729921882e-05,
      "loss": 0.242,
      "step": 580
    },
    {
      "epoch": 0.024963727916702226,
      "grad_norm": 0.035399679094552994,
      "learning_rate": 9.71558602452711e-05,
      "loss": 0.2946,
      "step": 585
    },
    {
      "epoch": 0.025177093112571478,
      "grad_norm": 0.04938485473394394,
      "learning_rate": 9.710287263936484e-05,
      "loss": 0.3104,
      "step": 590
    },
    {
      "epoch": 0.025390458308440726,
      "grad_norm": 0.04690195620059967,
      "learning_rate": 9.704941070805406e-05,
      "loss": 0.3534,
      "step": 595
    },
    {
      "epoch": 0.025603823504309977,
      "grad_norm": 0.0331694670021534,
      "learning_rate": 9.699547498969978e-05,
      "loss": 0.2822,
      "step": 600
    },
    {
      "epoch": 0.02581718870017923,
      "grad_norm": 0.03175467625260353,
      "learning_rate": 9.694106602743411e-05,
      "loss": 0.2459,
      "step": 605
    },
    {
      "epoch": 0.026030553896048476,
      "grad_norm": 0.03311099857091904,
      "learning_rate": 9.688618436915469e-05,
      "loss": 0.2742,
      "step": 610
    },
    {
      "epoch": 0.026243919091917728,
      "grad_norm": 0.0403532013297081,
      "learning_rate": 9.68308305675192e-05,
      "loss": 0.2798,
      "step": 615
    },
    {
      "epoch": 0.026457284287786976,
      "grad_norm": 0.06178947538137436,
      "learning_rate": 9.677500517993983e-05,
      "loss": 0.3079,
      "step": 620
    },
    {
      "epoch": 0.026670649483656227,
      "grad_norm": 0.02588691934943199,
      "learning_rate": 9.671870876857758e-05,
      "loss": 0.247,
      "step": 625
    },
    {
      "epoch": 0.026884014679525475,
      "grad_norm": 0.03683735430240631,
      "learning_rate": 9.66619419003367e-05,
      "loss": 0.249,
      "step": 630
    },
    {
      "epoch": 0.027097379875394727,
      "grad_norm": 0.09524267166852951,
      "learning_rate": 9.660470514685895e-05,
      "loss": 0.2971,
      "step": 635
    },
    {
      "epoch": 0.027310745071263975,
      "grad_norm": 0.09355056285858154,
      "learning_rate": 9.654699908451776e-05,
      "loss": 0.283,
      "step": 640
    },
    {
      "epoch": 0.027524110267133226,
      "grad_norm": 0.02253079228103161,
      "learning_rate": 9.648882429441257e-05,
      "loss": 0.2424,
      "step": 645
    },
    {
      "epoch": 0.027737475463002474,
      "grad_norm": 0.03182954341173172,
      "learning_rate": 9.643018136236285e-05,
      "loss": 0.2272,
      "step": 650
    },
    {
      "epoch": 0.027950840658871726,
      "grad_norm": 0.0411505363881588,
      "learning_rate": 9.637107087890229e-05,
      "loss": 0.2313,
      "step": 655
    },
    {
      "epoch": 0.028164205854740974,
      "grad_norm": 0.04611441493034363,
      "learning_rate": 9.63114934392728e-05,
      "loss": 0.2978,
      "step": 660
    },
    {
      "epoch": 0.028377571050610225,
      "grad_norm": 0.0233082827180624,
      "learning_rate": 9.625144964341852e-05,
      "loss": 0.2669,
      "step": 665
    },
    {
      "epoch": 0.028590936246479473,
      "grad_norm": 0.030269712209701538,
      "learning_rate": 9.619094009597982e-05,
      "loss": 0.275,
      "step": 670
    },
    {
      "epoch": 0.028804301442348725,
      "grad_norm": 0.029854916036128998,
      "learning_rate": 9.612996540628718e-05,
      "loss": 0.2974,
      "step": 675
    },
    {
      "epoch": 0.029017666638217973,
      "grad_norm": 0.03410609811544418,
      "learning_rate": 9.606852618835503e-05,
      "loss": 0.291,
      "step": 680
    },
    {
      "epoch": 0.029231031834087224,
      "grad_norm": 0.026049025356769562,
      "learning_rate": 9.600662306087561e-05,
      "loss": 0.2504,
      "step": 685
    },
    {
      "epoch": 0.029444397029956472,
      "grad_norm": 0.02961144782602787,
      "learning_rate": 9.594425664721273e-05,
      "loss": 0.2381,
      "step": 690
    },
    {
      "epoch": 0.029657762225825723,
      "grad_norm": 0.031786564737558365,
      "learning_rate": 9.588142757539551e-05,
      "loss": 0.2675,
      "step": 695
    },
    {
      "epoch": 0.02987112742169497,
      "grad_norm": 0.028311412781476974,
      "learning_rate": 9.581813647811198e-05,
      "loss": 0.2831,
      "step": 700
    },
    {
      "epoch": 0.030084492617564223,
      "grad_norm": 0.036188870668411255,
      "learning_rate": 9.57543839927028e-05,
      "loss": 0.2912,
      "step": 705
    },
    {
      "epoch": 0.030297857813433474,
      "grad_norm": 0.037650976330041885,
      "learning_rate": 9.569017076115477e-05,
      "loss": 0.2916,
      "step": 710
    },
    {
      "epoch": 0.030511223009302722,
      "grad_norm": 0.027713395655155182,
      "learning_rate": 9.562549743009444e-05,
      "loss": 0.2519,
      "step": 715
    },
    {
      "epoch": 0.030724588205171974,
      "grad_norm": 0.0437273234128952,
      "learning_rate": 9.556036465078151e-05,
      "loss": 0.233,
      "step": 720
    },
    {
      "epoch": 0.030937953401041222,
      "grad_norm": 0.02644345723092556,
      "learning_rate": 9.549477307910238e-05,
      "loss": 0.2663,
      "step": 725
    },
    {
      "epoch": 0.031151318596910473,
      "grad_norm": 0.044137876480817795,
      "learning_rate": 9.542872337556341e-05,
      "loss": 0.2786,
      "step": 730
    },
    {
      "epoch": 0.03136468379277972,
      "grad_norm": 0.027183713391423225,
      "learning_rate": 9.536221620528442e-05,
      "loss": 0.2825,
      "step": 735
    },
    {
      "epoch": 0.03157804898864897,
      "grad_norm": 0.03091796301305294,
      "learning_rate": 9.529525223799185e-05,
      "loss": 0.2441,
      "step": 740
    },
    {
      "epoch": 0.031791414184518224,
      "grad_norm": 0.046071771532297134,
      "learning_rate": 9.522783214801212e-05,
      "loss": 0.3033,
      "step": 745
    },
    {
      "epoch": 0.03200477938038747,
      "grad_norm": 0.046894434839487076,
      "learning_rate": 9.515995661426477e-05,
      "loss": 0.2833,
      "step": 750
    },
    {
      "epoch": 0.03221814457625672,
      "grad_norm": 0.023569930344820023,
      "learning_rate": 9.50916263202557e-05,
      "loss": 0.2717,
      "step": 755
    },
    {
      "epoch": 0.03243150977212597,
      "grad_norm": 0.046441223472356796,
      "learning_rate": 9.502284195407018e-05,
      "loss": 0.2873,
      "step": 760
    },
    {
      "epoch": 0.03264487496799522,
      "grad_norm": 0.03211268410086632,
      "learning_rate": 9.495360420836604e-05,
      "loss": 0.2996,
      "step": 765
    },
    {
      "epoch": 0.03285824016386447,
      "grad_norm": 0.06250066310167313,
      "learning_rate": 9.48839137803666e-05,
      "loss": 0.2914,
      "step": 770
    },
    {
      "epoch": 0.03307160535973372,
      "grad_norm": 0.02906959503889084,
      "learning_rate": 9.48137713718537e-05,
      "loss": 0.2334,
      "step": 775
    },
    {
      "epoch": 0.03328497055560297,
      "grad_norm": 0.054249998182058334,
      "learning_rate": 9.47431776891606e-05,
      "loss": 0.3377,
      "step": 780
    },
    {
      "epoch": 0.03349833575147222,
      "grad_norm": 0.0590582937002182,
      "learning_rate": 9.467213344316493e-05,
      "loss": 0.2843,
      "step": 785
    },
    {
      "epoch": 0.033711700947341466,
      "grad_norm": 0.031787481158971786,
      "learning_rate": 9.460063934928141e-05,
      "loss": 0.2946,
      "step": 790
    },
    {
      "epoch": 0.03392506614321072,
      "grad_norm": 0.06562652438879013,
      "learning_rate": 9.452869612745483e-05,
      "loss": 0.2984,
      "step": 795
    },
    {
      "epoch": 0.03413843133907997,
      "grad_norm": 0.030938204377889633,
      "learning_rate": 9.44563045021526e-05,
      "loss": 0.267,
      "step": 800
    },
    {
      "epoch": 0.03435179653494922,
      "grad_norm": 0.02579217590391636,
      "learning_rate": 9.438346520235759e-05,
      "loss": 0.291,
      "step": 805
    },
    {
      "epoch": 0.03456516173081847,
      "grad_norm": 0.025543898344039917,
      "learning_rate": 9.431017896156074e-05,
      "loss": 0.2498,
      "step": 810
    },
    {
      "epoch": 0.03477852692668772,
      "grad_norm": 0.0316057913005352,
      "learning_rate": 9.423644651775369e-05,
      "loss": 0.2612,
      "step": 815
    },
    {
      "epoch": 0.03499189212255697,
      "grad_norm": 0.04319724440574646,
      "learning_rate": 9.416226861342131e-05,
      "loss": 0.2834,
      "step": 820
    },
    {
      "epoch": 0.03520525731842622,
      "grad_norm": 0.06887686252593994,
      "learning_rate": 9.40876459955343e-05,
      "loss": 0.2383,
      "step": 825
    },
    {
      "epoch": 0.03541862251429547,
      "grad_norm": 0.050858091562986374,
      "learning_rate": 9.401257941554157e-05,
      "loss": 0.2495,
      "step": 830
    },
    {
      "epoch": 0.035631987710164716,
      "grad_norm": 0.03954673185944557,
      "learning_rate": 9.393706962936275e-05,
      "loss": 0.2699,
      "step": 835
    },
    {
      "epoch": 0.03584535290603397,
      "grad_norm": 0.029054228216409683,
      "learning_rate": 9.386111739738057e-05,
      "loss": 0.2378,
      "step": 840
    },
    {
      "epoch": 0.03605871810190322,
      "grad_norm": 0.047654591500759125,
      "learning_rate": 9.378472348443315e-05,
      "loss": 0.2704,
      "step": 845
    },
    {
      "epoch": 0.03627208329777247,
      "grad_norm": 0.03542691096663475,
      "learning_rate": 9.370788865980633e-05,
      "loss": 0.2662,
      "step": 850
    },
    {
      "epoch": 0.036485448493641714,
      "grad_norm": 0.04613197594881058,
      "learning_rate": 9.363061369722595e-05,
      "loss": 0.2841,
      "step": 855
    },
    {
      "epoch": 0.036698813689510966,
      "grad_norm": 0.0447966568171978,
      "learning_rate": 9.355289937485004e-05,
      "loss": 0.2093,
      "step": 860
    },
    {
      "epoch": 0.03691217888538022,
      "grad_norm": 0.03745049610733986,
      "learning_rate": 9.347474647526095e-05,
      "loss": 0.2897,
      "step": 865
    },
    {
      "epoch": 0.03712554408124947,
      "grad_norm": 0.023103633895516396,
      "learning_rate": 9.339615578545753e-05,
      "loss": 0.2127,
      "step": 870
    },
    {
      "epoch": 0.03733890927711871,
      "grad_norm": 0.04574818164110184,
      "learning_rate": 9.331712809684712e-05,
      "loss": 0.2697,
      "step": 875
    },
    {
      "epoch": 0.037552274472987965,
      "grad_norm": 0.03625917062163353,
      "learning_rate": 9.323766420523769e-05,
      "loss": 0.2545,
      "step": 880
    },
    {
      "epoch": 0.037765639668857216,
      "grad_norm": 0.024954993277788162,
      "learning_rate": 9.315776491082972e-05,
      "loss": 0.2639,
      "step": 885
    },
    {
      "epoch": 0.03797900486472647,
      "grad_norm": 0.040726833045482635,
      "learning_rate": 9.307743101820827e-05,
      "loss": 0.2663,
      "step": 890
    },
    {
      "epoch": 0.03819237006059571,
      "grad_norm": 0.024317122995853424,
      "learning_rate": 9.299666333633472e-05,
      "loss": 0.2548,
      "step": 895
    },
    {
      "epoch": 0.038405735256464964,
      "grad_norm": 0.02196457050740719,
      "learning_rate": 9.29154626785387e-05,
      "loss": 0.2966,
      "step": 900
    },
    {
      "epoch": 0.038619100452334215,
      "grad_norm": 0.03682681545615196,
      "learning_rate": 9.283382986250997e-05,
      "loss": 0.3153,
      "step": 905
    },
    {
      "epoch": 0.03883246564820347,
      "grad_norm": 0.043909136205911636,
      "learning_rate": 9.275176571029008e-05,
      "loss": 0.2626,
      "step": 910
    },
    {
      "epoch": 0.03904583084407272,
      "grad_norm": 0.023810015991330147,
      "learning_rate": 9.266927104826409e-05,
      "loss": 0.2584,
      "step": 915
    },
    {
      "epoch": 0.03925919603994196,
      "grad_norm": 0.059404801577329636,
      "learning_rate": 9.258634670715238e-05,
      "loss": 0.2641,
      "step": 920
    },
    {
      "epoch": 0.039472561235811214,
      "grad_norm": 0.028522497043013573,
      "learning_rate": 9.250299352200214e-05,
      "loss": 0.2456,
      "step": 925
    },
    {
      "epoch": 0.039685926431680466,
      "grad_norm": 0.040745701640844345,
      "learning_rate": 9.241921233217899e-05,
      "loss": 0.2966,
      "step": 930
    },
    {
      "epoch": 0.03989929162754972,
      "grad_norm": 0.03946399688720703,
      "learning_rate": 9.23350039813586e-05,
      "loss": 0.2782,
      "step": 935
    },
    {
      "epoch": 0.04011265682341896,
      "grad_norm": 0.03440142795443535,
      "learning_rate": 9.225036931751812e-05,
      "loss": 0.3322,
      "step": 940
    },
    {
      "epoch": 0.04032602201928821,
      "grad_norm": 0.016199935227632523,
      "learning_rate": 9.216530919292767e-05,
      "loss": 0.2898,
      "step": 945
    },
    {
      "epoch": 0.040539387215157464,
      "grad_norm": 0.04205959662795067,
      "learning_rate": 9.207982446414178e-05,
      "loss": 0.2375,
      "step": 950
    },
    {
      "epoch": 0.040752752411026716,
      "grad_norm": 0.04946102201938629,
      "learning_rate": 9.199391599199072e-05,
      "loss": 0.3327,
      "step": 955
    },
    {
      "epoch": 0.04096611760689596,
      "grad_norm": 0.034303370863199234,
      "learning_rate": 9.190758464157183e-05,
      "loss": 0.2214,
      "step": 960
    },
    {
      "epoch": 0.04117948280276521,
      "grad_norm": 0.03868279233574867,
      "learning_rate": 9.182083128224086e-05,
      "loss": 0.2291,
      "step": 965
    },
    {
      "epoch": 0.04139284799863446,
      "grad_norm": 0.04136692360043526,
      "learning_rate": 9.173365678760318e-05,
      "loss": 0.3056,
      "step": 970
    },
    {
      "epoch": 0.041606213194503715,
      "grad_norm": 0.05572578310966492,
      "learning_rate": 9.164606203550497e-05,
      "loss": 0.2113,
      "step": 975
    },
    {
      "epoch": 0.04181957839037296,
      "grad_norm": 0.052576541900634766,
      "learning_rate": 9.155804790802444e-05,
      "loss": 0.2828,
      "step": 980
    },
    {
      "epoch": 0.04203294358624221,
      "grad_norm": 0.027290984988212585,
      "learning_rate": 9.146961529146285e-05,
      "loss": 0.2072,
      "step": 985
    },
    {
      "epoch": 0.04224630878211146,
      "grad_norm": 0.06300253421068192,
      "learning_rate": 9.138076507633567e-05,
      "loss": 0.2906,
      "step": 990
    },
    {
      "epoch": 0.042459673977980714,
      "grad_norm": 0.06324904412031174,
      "learning_rate": 9.129149815736358e-05,
      "loss": 0.2722,
      "step": 995
    },
    {
      "epoch": 0.04267303917384996,
      "grad_norm": 0.06388256698846817,
      "learning_rate": 9.120181543346347e-05,
      "loss": 0.2931,
      "step": 1000
    },
    {
      "epoch": 0.04288640436971921,
      "grad_norm": 0.06965386867523193,
      "learning_rate": 9.111171780773937e-05,
      "loss": 0.2738,
      "step": 1005
    },
    {
      "epoch": 0.04309976956558846,
      "grad_norm": 0.061207544058561325,
      "learning_rate": 9.102120618747337e-05,
      "loss": 0.3248,
      "step": 1010
    },
    {
      "epoch": 0.04331313476145771,
      "grad_norm": 0.03414316102862358,
      "learning_rate": 9.093028148411649e-05,
      "loss": 0.3174,
      "step": 1015
    },
    {
      "epoch": 0.043526499957326964,
      "grad_norm": 0.03916358947753906,
      "learning_rate": 9.083894461327947e-05,
      "loss": 0.2707,
      "step": 1020
    },
    {
      "epoch": 0.04373986515319621,
      "grad_norm": 0.030022209510207176,
      "learning_rate": 9.074719649472359e-05,
      "loss": 0.258,
      "step": 1025
    },
    {
      "epoch": 0.04395323034906546,
      "grad_norm": 0.0692969411611557,
      "learning_rate": 9.065503805235138e-05,
      "loss": 0.2756,
      "step": 1030
    },
    {
      "epoch": 0.04416659554493471,
      "grad_norm": 0.0557040274143219,
      "learning_rate": 9.056247021419735e-05,
      "loss": 0.2661,
      "step": 1035
    },
    {
      "epoch": 0.04437996074080396,
      "grad_norm": 0.0371689572930336,
      "learning_rate": 9.046949391241859e-05,
      "loss": 0.2492,
      "step": 1040
    },
    {
      "epoch": 0.04459332593667321,
      "grad_norm": 0.02759876288473606,
      "learning_rate": 9.037611008328544e-05,
      "loss": 0.2463,
      "step": 1045
    },
    {
      "epoch": 0.04480669113254246,
      "grad_norm": 0.028433620929718018,
      "learning_rate": 9.028231966717199e-05,
      "loss": 0.2689,
      "step": 1050
    },
    {
      "epoch": 0.04502005632841171,
      "grad_norm": 0.06207912787795067,
      "learning_rate": 9.018812360854671e-05,
      "loss": 0.2909,
      "step": 1055
    },
    {
      "epoch": 0.04523342152428096,
      "grad_norm": 0.023970024660229683,
      "learning_rate": 9.009352285596286e-05,
      "loss": 0.26,
      "step": 1060
    },
    {
      "epoch": 0.045446786720150206,
      "grad_norm": 0.0322456993162632,
      "learning_rate": 8.9998518362049e-05,
      "loss": 0.2556,
      "step": 1065
    },
    {
      "epoch": 0.04566015191601946,
      "grad_norm": 0.03758605197072029,
      "learning_rate": 8.990311108349927e-05,
      "loss": 0.2787,
      "step": 1070
    },
    {
      "epoch": 0.04587351711188871,
      "grad_norm": 0.0282424483448267,
      "learning_rate": 8.980730198106395e-05,
      "loss": 0.2428,
      "step": 1075
    },
    {
      "epoch": 0.04608688230775796,
      "grad_norm": 0.03697577491402626,
      "learning_rate": 8.971109201953962e-05,
      "loss": 0.2965,
      "step": 1080
    },
    {
      "epoch": 0.046300247503627205,
      "grad_norm": 0.04555972293019295,
      "learning_rate": 8.961448216775954e-05,
      "loss": 0.2357,
      "step": 1085
    },
    {
      "epoch": 0.04651361269949646,
      "grad_norm": 0.059265684336423874,
      "learning_rate": 8.951747339858383e-05,
      "loss": 0.3145,
      "step": 1090
    },
    {
      "epoch": 0.04672697789536571,
      "grad_norm": 0.02921934425830841,
      "learning_rate": 8.942006668888972e-05,
      "loss": 0.2304,
      "step": 1095
    },
    {
      "epoch": 0.04694034309123496,
      "grad_norm": 0.03985913470387459,
      "learning_rate": 8.932226301956169e-05,
      "loss": 0.2328,
      "step": 1100
    },
    {
      "epoch": 0.04715370828710421,
      "grad_norm": 0.03644593060016632,
      "learning_rate": 8.922406337548162e-05,
      "loss": 0.3003,
      "step": 1105
    },
    {
      "epoch": 0.047367073482973455,
      "grad_norm": 0.03278481587767601,
      "learning_rate": 8.912546874551882e-05,
      "loss": 0.243,
      "step": 1110
    },
    {
      "epoch": 0.04758043867884271,
      "grad_norm": 0.03012063167989254,
      "learning_rate": 8.902648012252012e-05,
      "loss": 0.279,
      "step": 1115
    },
    {
      "epoch": 0.04779380387471196,
      "grad_norm": 0.029487384483218193,
      "learning_rate": 8.89270985032999e-05,
      "loss": 0.251,
      "step": 1120
    },
    {
      "epoch": 0.04800716907058121,
      "grad_norm": 0.04262380301952362,
      "learning_rate": 8.882732488862988e-05,
      "loss": 0.247,
      "step": 1125
    },
    {
      "epoch": 0.048220534266450454,
      "grad_norm": 0.026352474465966225,
      "learning_rate": 8.872716028322932e-05,
      "loss": 0.2344,
      "step": 1130
    },
    {
      "epoch": 0.048433899462319706,
      "grad_norm": 0.049734603613615036,
      "learning_rate": 8.862660569575465e-05,
      "loss": 0.2544,
      "step": 1135
    },
    {
      "epoch": 0.04864726465818896,
      "grad_norm": 0.03433588519692421,
      "learning_rate": 8.852566213878947e-05,
      "loss": 0.263,
      "step": 1140
    },
    {
      "epoch": 0.04886062985405821,
      "grad_norm": 0.04362286254763603,
      "learning_rate": 8.842433062883427e-05,
      "loss": 0.3252,
      "step": 1145
    },
    {
      "epoch": 0.04907399504992745,
      "grad_norm": 0.03138258680701256,
      "learning_rate": 8.83226121862962e-05,
      "loss": 0.2815,
      "step": 1150
    },
    {
      "epoch": 0.049287360245796705,
      "grad_norm": 0.04098518565297127,
      "learning_rate": 8.822050783547889e-05,
      "loss": 0.2968,
      "step": 1155
    },
    {
      "epoch": 0.049500725441665956,
      "grad_norm": 0.05700204148888588,
      "learning_rate": 8.811801860457201e-05,
      "loss": 0.3166,
      "step": 1160
    },
    {
      "epoch": 0.04971409063753521,
      "grad_norm": 0.04811840504407883,
      "learning_rate": 8.801514552564097e-05,
      "loss": 0.2326,
      "step": 1165
    },
    {
      "epoch": 0.04992745583340445,
      "grad_norm": 0.03698478639125824,
      "learning_rate": 8.791188963461652e-05,
      "loss": 0.3081,
      "step": 1170
    },
    {
      "epoch": 0.050140821029273704,
      "grad_norm": 0.04285129904747009,
      "learning_rate": 8.780825197128437e-05,
      "loss": 0.2942,
      "step": 1175
    },
    {
      "epoch": 0.050354186225142955,
      "grad_norm": 0.040595877915620804,
      "learning_rate": 8.770423357927461e-05,
      "loss": 0.2566,
      "step": 1180
    },
    {
      "epoch": 0.050567551421012207,
      "grad_norm": 0.03924380615353584,
      "learning_rate": 8.75998355060513e-05,
      "loss": 0.2768,
      "step": 1185
    },
    {
      "epoch": 0.05078091661688145,
      "grad_norm": 0.04953142628073692,
      "learning_rate": 8.749505880290188e-05,
      "loss": 0.2927,
      "step": 1190
    },
    {
      "epoch": 0.0509942818127507,
      "grad_norm": 0.04521257057785988,
      "learning_rate": 8.73899045249266e-05,
      "loss": 0.2582,
      "step": 1195
    },
    {
      "epoch": 0.051207647008619954,
      "grad_norm": 0.05603989213705063,
      "learning_rate": 8.728437373102784e-05,
      "loss": 0.2737,
      "step": 1200
    },
    {
      "epoch": 0.051421012204489205,
      "grad_norm": 0.06176679953932762,
      "learning_rate": 8.717846748389956e-05,
      "loss": 0.2895,
      "step": 1205
    },
    {
      "epoch": 0.05163437740035846,
      "grad_norm": 0.038099490106105804,
      "learning_rate": 8.707218685001647e-05,
      "loss": 0.2455,
      "step": 1210
    },
    {
      "epoch": 0.0518477425962277,
      "grad_norm": 0.027822667732834816,
      "learning_rate": 8.696553289962339e-05,
      "loss": 0.2784,
      "step": 1215
    },
    {
      "epoch": 0.05206110779209695,
      "grad_norm": 0.060905542224645615,
      "learning_rate": 8.685850670672439e-05,
      "loss": 0.229,
      "step": 1220
    },
    {
      "epoch": 0.052274472987966204,
      "grad_norm": 0.03755621984601021,
      "learning_rate": 8.675110934907206e-05,
      "loss": 0.2511,
      "step": 1225
    },
    {
      "epoch": 0.052487838183835456,
      "grad_norm": 0.03154146298766136,
      "learning_rate": 8.664334190815659e-05,
      "loss": 0.3162,
      "step": 1230
    },
    {
      "epoch": 0.0527012033797047,
      "grad_norm": 0.0800115168094635,
      "learning_rate": 8.653520546919493e-05,
      "loss": 0.2913,
      "step": 1235
    },
    {
      "epoch": 0.05291456857557395,
      "grad_norm": 0.04612227529287338,
      "learning_rate": 8.642670112111982e-05,
      "loss": 0.3375,
      "step": 1240
    },
    {
      "epoch": 0.0531279337714432,
      "grad_norm": 0.05655276030302048,
      "learning_rate": 8.631782995656882e-05,
      "loss": 0.284,
      "step": 1245
    },
    {
      "epoch": 0.053341298967312455,
      "grad_norm": 0.018315743654966354,
      "learning_rate": 8.620859307187339e-05,
      "loss": 0.1967,
      "step": 1250
    },
    {
      "epoch": 0.0535546641631817,
      "grad_norm": 0.04112517833709717,
      "learning_rate": 8.609899156704768e-05,
      "loss": 0.2113,
      "step": 1255
    },
    {
      "epoch": 0.05376802935905095,
      "grad_norm": 0.05302157625555992,
      "learning_rate": 8.598902654577768e-05,
      "loss": 0.3028,
      "step": 1260
    },
    {
      "epoch": 0.0539813945549202,
      "grad_norm": 0.028352195397019386,
      "learning_rate": 8.587869911540993e-05,
      "loss": 0.2154,
      "step": 1265
    },
    {
      "epoch": 0.054194759750789454,
      "grad_norm": 0.0362103208899498,
      "learning_rate": 8.57680103869404e-05,
      "loss": 0.3032,
      "step": 1270
    },
    {
      "epoch": 0.0544081249466587,
      "grad_norm": 0.03478872403502464,
      "learning_rate": 8.565696147500337e-05,
      "loss": 0.2482,
      "step": 1275
    },
    {
      "epoch": 0.05462149014252795,
      "grad_norm": 0.02771204523742199,
      "learning_rate": 8.554555349786016e-05,
      "loss": 0.2414,
      "step": 1280
    },
    {
      "epoch": 0.0548348553383972,
      "grad_norm": 0.041167695075273514,
      "learning_rate": 8.543378757738785e-05,
      "loss": 0.2579,
      "step": 1285
    },
    {
      "epoch": 0.05504822053426645,
      "grad_norm": 0.03489971533417702,
      "learning_rate": 8.532166483906803e-05,
      "loss": 0.2936,
      "step": 1290
    },
    {
      "epoch": 0.0552615857301357,
      "grad_norm": 0.04199797660112381,
      "learning_rate": 8.520918641197542e-05,
      "loss": 0.2818,
      "step": 1295
    },
    {
      "epoch": 0.05547495092600495,
      "grad_norm": 0.040457602590322495,
      "learning_rate": 8.509635342876655e-05,
      "loss": 0.2596,
      "step": 1300
    },
    {
      "epoch": 0.0556883161218742,
      "grad_norm": 0.032357096672058105,
      "learning_rate": 8.498316702566828e-05,
      "loss": 0.2972,
      "step": 1305
    },
    {
      "epoch": 0.05590168131774345,
      "grad_norm": 0.0315093994140625,
      "learning_rate": 8.486962834246645e-05,
      "loss": 0.2791,
      "step": 1310
    },
    {
      "epoch": 0.0561150465136127,
      "grad_norm": 0.02981637418270111,
      "learning_rate": 8.475573852249435e-05,
      "loss": 0.2863,
      "step": 1315
    },
    {
      "epoch": 0.05632841170948195,
      "grad_norm": 0.03184719383716583,
      "learning_rate": 8.464149871262117e-05,
      "loss": 0.2225,
      "step": 1320
    },
    {
      "epoch": 0.0565417769053512,
      "grad_norm": 0.07248327136039734,
      "learning_rate": 8.452691006324054e-05,
      "loss": 0.2437,
      "step": 1325
    },
    {
      "epoch": 0.05675514210122045,
      "grad_norm": 0.0382407009601593,
      "learning_rate": 8.441197372825891e-05,
      "loss": 0.258,
      "step": 1330
    },
    {
      "epoch": 0.0569685072970897,
      "grad_norm": 0.042298175394535065,
      "learning_rate": 8.42966908650839e-05,
      "loss": 0.2853,
      "step": 1335
    },
    {
      "epoch": 0.057181872492958946,
      "grad_norm": 0.03249141201376915,
      "learning_rate": 8.418106263461261e-05,
      "loss": 0.2508,
      "step": 1340
    },
    {
      "epoch": 0.0573952376888282,
      "grad_norm": 0.03515800088644028,
      "learning_rate": 8.406509020122008e-05,
      "loss": 0.2814,
      "step": 1345
    },
    {
      "epoch": 0.05760860288469745,
      "grad_norm": 0.034991905093193054,
      "learning_rate": 8.394877473274743e-05,
      "loss": 0.2652,
      "step": 1350
    },
    {
      "epoch": 0.0578219680805667,
      "grad_norm": 0.04050406813621521,
      "learning_rate": 8.38321174004901e-05,
      "loss": 0.2393,
      "step": 1355
    },
    {
      "epoch": 0.058035333276435945,
      "grad_norm": 0.03801000118255615,
      "learning_rate": 8.371511937918616e-05,
      "loss": 0.2557,
      "step": 1360
    },
    {
      "epoch": 0.058248698472305196,
      "grad_norm": 0.03803227096796036,
      "learning_rate": 8.35977818470044e-05,
      "loss": 0.2608,
      "step": 1365
    },
    {
      "epoch": 0.05846206366817445,
      "grad_norm": 0.035335030406713486,
      "learning_rate": 8.348010598553244e-05,
      "loss": 0.2768,
      "step": 1370
    },
    {
      "epoch": 0.0586754288640437,
      "grad_norm": 0.031461793929338455,
      "learning_rate": 8.33620929797649e-05,
      "loss": 0.2694,
      "step": 1375
    },
    {
      "epoch": 0.058888794059912944,
      "grad_norm": 0.03284905478358269,
      "learning_rate": 8.324374401809143e-05,
      "loss": 0.2275,
      "step": 1380
    },
    {
      "epoch": 0.059102159255782195,
      "grad_norm": 0.03649332746863365,
      "learning_rate": 8.312506029228478e-05,
      "loss": 0.2461,
      "step": 1385
    },
    {
      "epoch": 0.05931552445165145,
      "grad_norm": 0.03680724650621414,
      "learning_rate": 8.300604299748876e-05,
      "loss": 0.2715,
      "step": 1390
    },
    {
      "epoch": 0.0595288896475207,
      "grad_norm": 0.06462039053440094,
      "learning_rate": 8.288669333220616e-05,
      "loss": 0.303,
      "step": 1395
    },
    {
      "epoch": 0.05974225484338994,
      "grad_norm": 0.05677239969372749,
      "learning_rate": 8.276701249828685e-05,
      "loss": 0.2699,
      "step": 1400
    },
    {
      "epoch": 0.059955620039259194,
      "grad_norm": 0.030757322907447815,
      "learning_rate": 8.264700170091543e-05,
      "loss": 0.3067,
      "step": 1405
    },
    {
      "epoch": 0.060168985235128446,
      "grad_norm": 0.05634153634309769,
      "learning_rate": 8.252666214859935e-05,
      "loss": 0.2572,
      "step": 1410
    },
    {
      "epoch": 0.0603823504309977,
      "grad_norm": 0.036859892308712006,
      "learning_rate": 8.240599505315655e-05,
      "loss": 0.2426,
      "step": 1415
    },
    {
      "epoch": 0.06059571562686695,
      "grad_norm": 0.043805841356515884,
      "learning_rate": 8.228500162970333e-05,
      "loss": 0.2681,
      "step": 1420
    },
    {
      "epoch": 0.06080908082273619,
      "grad_norm": 0.040093958377838135,
      "learning_rate": 8.216368309664212e-05,
      "loss": 0.2922,
      "step": 1425
    },
    {
      "epoch": 0.061022446018605445,
      "grad_norm": 0.042460571974515915,
      "learning_rate": 8.204204067564925e-05,
      "loss": 0.2443,
      "step": 1430
    },
    {
      "epoch": 0.061235811214474696,
      "grad_norm": 0.030517883598804474,
      "learning_rate": 8.192007559166247e-05,
      "loss": 0.2352,
      "step": 1435
    },
    {
      "epoch": 0.06144917641034395,
      "grad_norm": 0.03784123435616493,
      "learning_rate": 8.179778907286888e-05,
      "loss": 0.2467,
      "step": 1440
    },
    {
      "epoch": 0.06166254160621319,
      "grad_norm": 0.028742872178554535,
      "learning_rate": 8.167518235069235e-05,
      "loss": 0.2512,
      "step": 1445
    },
    {
      "epoch": 0.061875906802082443,
      "grad_norm": 0.030150553211569786,
      "learning_rate": 8.155225665978119e-05,
      "loss": 0.2356,
      "step": 1450
    },
    {
      "epoch": 0.062089271997951695,
      "grad_norm": 0.038011129945516586,
      "learning_rate": 8.142901323799578e-05,
      "loss": 0.2286,
      "step": 1455
    },
    {
      "epoch": 0.062302637193820946,
      "grad_norm": 0.0414518266916275,
      "learning_rate": 8.130545332639599e-05,
      "loss": 0.3136,
      "step": 1460
    },
    {
      "epoch": 0.0625160023896902,
      "grad_norm": 0.0297387782484293,
      "learning_rate": 8.118157816922874e-05,
      "loss": 0.241,
      "step": 1465
    },
    {
      "epoch": 0.06272936758555944,
      "grad_norm": 0.05473915860056877,
      "learning_rate": 8.105738901391552e-05,
      "loss": 0.2507,
      "step": 1470
    },
    {
      "epoch": 0.06294273278142869,
      "grad_norm": 0.04644512012600899,
      "learning_rate": 8.093288711103973e-05,
      "loss": 0.3056,
      "step": 1475
    },
    {
      "epoch": 0.06315609797729795,
      "grad_norm": 0.029344705864787102,
      "learning_rate": 8.080807371433416e-05,
      "loss": 0.2648,
      "step": 1480
    },
    {
      "epoch": 0.06336946317316719,
      "grad_norm": 0.06217552721500397,
      "learning_rate": 8.068295008066831e-05,
      "loss": 0.2249,
      "step": 1485
    },
    {
      "epoch": 0.06358282836903645,
      "grad_norm": 0.051597051322460175,
      "learning_rate": 8.05575174700358e-05,
      "loss": 0.2314,
      "step": 1490
    },
    {
      "epoch": 0.06379619356490569,
      "grad_norm": 0.04054702818393707,
      "learning_rate": 8.04317771455416e-05,
      "loss": 0.2234,
      "step": 1495
    },
    {
      "epoch": 0.06400955876077494,
      "grad_norm": 0.0432317778468132,
      "learning_rate": 8.030573037338942e-05,
      "loss": 0.276,
      "step": 1500
    },
    {
      "epoch": 0.0642229239566442,
      "grad_norm": 0.04206065088510513,
      "learning_rate": 8.017937842286883e-05,
      "loss": 0.2724,
      "step": 1505
    },
    {
      "epoch": 0.06443628915251344,
      "grad_norm": 0.033305875957012177,
      "learning_rate": 8.005272256634257e-05,
      "loss": 0.2637,
      "step": 1510
    },
    {
      "epoch": 0.0646496543483827,
      "grad_norm": 0.04426507651805878,
      "learning_rate": 7.992576407923373e-05,
      "loss": 0.2385,
      "step": 1515
    },
    {
      "epoch": 0.06486301954425194,
      "grad_norm": 0.04925144836306572,
      "learning_rate": 7.979850424001283e-05,
      "loss": 0.2032,
      "step": 1520
    },
    {
      "epoch": 0.06507638474012119,
      "grad_norm": 0.0709012970328331,
      "learning_rate": 7.967094433018508e-05,
      "loss": 0.2714,
      "step": 1525
    },
    {
      "epoch": 0.06528974993599045,
      "grad_norm": 0.05535994842648506,
      "learning_rate": 7.954308563427733e-05,
      "loss": 0.257,
      "step": 1530
    },
    {
      "epoch": 0.06550311513185969,
      "grad_norm": 0.0598006471991539,
      "learning_rate": 7.941492943982522e-05,
      "loss": 0.2736,
      "step": 1535
    },
    {
      "epoch": 0.06571648032772893,
      "grad_norm": 0.03838341310620308,
      "learning_rate": 7.928647703736023e-05,
      "loss": 0.2812,
      "step": 1540
    },
    {
      "epoch": 0.0659298455235982,
      "grad_norm": 0.03836604580283165,
      "learning_rate": 7.91577297203966e-05,
      "loss": 0.3167,
      "step": 1545
    },
    {
      "epoch": 0.06614321071946744,
      "grad_norm": 0.03951882943511009,
      "learning_rate": 7.902868878541841e-05,
      "loss": 0.2946,
      "step": 1550
    },
    {
      "epoch": 0.0663565759153367,
      "grad_norm": 0.03273544833064079,
      "learning_rate": 7.889935553186642e-05,
      "loss": 0.3148,
      "step": 1555
    },
    {
      "epoch": 0.06656994111120594,
      "grad_norm": 0.06854616105556488,
      "learning_rate": 7.876973126212506e-05,
      "loss": 0.2863,
      "step": 1560
    },
    {
      "epoch": 0.06678330630707519,
      "grad_norm": 0.061365433037281036,
      "learning_rate": 7.86398172815093e-05,
      "loss": 0.3176,
      "step": 1565
    },
    {
      "epoch": 0.06699667150294444,
      "grad_norm": 0.0659542977809906,
      "learning_rate": 7.85096148982515e-05,
      "loss": 0.2646,
      "step": 1570
    },
    {
      "epoch": 0.06721003669881369,
      "grad_norm": 0.06526146084070206,
      "learning_rate": 7.837912542348818e-05,
      "loss": 0.2727,
      "step": 1575
    },
    {
      "epoch": 0.06742340189468293,
      "grad_norm": 0.058708470314741135,
      "learning_rate": 7.82483501712469e-05,
      "loss": 0.2535,
      "step": 1580
    },
    {
      "epoch": 0.06763676709055219,
      "grad_norm": 0.03860969841480255,
      "learning_rate": 7.811729045843302e-05,
      "loss": 0.257,
      "step": 1585
    },
    {
      "epoch": 0.06785013228642144,
      "grad_norm": 0.04359191283583641,
      "learning_rate": 7.798594760481638e-05,
      "loss": 0.2959,
      "step": 1590
    },
    {
      "epoch": 0.0680634974822907,
      "grad_norm": 0.04573407396674156,
      "learning_rate": 7.785432293301806e-05,
      "loss": 0.2705,
      "step": 1595
    },
    {
      "epoch": 0.06827686267815994,
      "grad_norm": 0.06335180997848511,
      "learning_rate": 7.772241776849704e-05,
      "loss": 0.2604,
      "step": 1600
    },
    {
      "epoch": 0.06849022787402918,
      "grad_norm": 0.04331490397453308,
      "learning_rate": 7.759023343953689e-05,
      "loss": 0.282,
      "step": 1605
    },
    {
      "epoch": 0.06870359306989844,
      "grad_norm": 0.03213268145918846,
      "learning_rate": 7.745777127723231e-05,
      "loss": 0.2759,
      "step": 1610
    },
    {
      "epoch": 0.06891695826576769,
      "grad_norm": 0.02890622615814209,
      "learning_rate": 7.732503261547579e-05,
      "loss": 0.2123,
      "step": 1615
    },
    {
      "epoch": 0.06913032346163694,
      "grad_norm": 0.02919544279575348,
      "learning_rate": 7.71920187909442e-05,
      "loss": 0.2378,
      "step": 1620
    },
    {
      "epoch": 0.06934368865750619,
      "grad_norm": 0.08839218318462372,
      "learning_rate": 7.705873114308528e-05,
      "loss": 0.329,
      "step": 1625
    },
    {
      "epoch": 0.06955705385337543,
      "grad_norm": 0.04515694081783295,
      "learning_rate": 7.692517101410415e-05,
      "loss": 0.3101,
      "step": 1630
    },
    {
      "epoch": 0.06977041904924469,
      "grad_norm": 0.04956479370594025,
      "learning_rate": 7.679133974894983e-05,
      "loss": 0.2236,
      "step": 1635
    },
    {
      "epoch": 0.06998378424511394,
      "grad_norm": 0.02876509167253971,
      "learning_rate": 7.665723869530169e-05,
      "loss": 0.3325,
      "step": 1640
    },
    {
      "epoch": 0.07019714944098318,
      "grad_norm": 0.02242579683661461,
      "learning_rate": 7.652286920355583e-05,
      "loss": 0.25,
      "step": 1645
    },
    {
      "epoch": 0.07041051463685244,
      "grad_norm": 0.05168885365128517,
      "learning_rate": 7.638823262681155e-05,
      "loss": 0.2834,
      "step": 1650
    },
    {
      "epoch": 0.07062387983272168,
      "grad_norm": 0.04744305461645126,
      "learning_rate": 7.625333032085769e-05,
      "loss": 0.2767,
      "step": 1655
    },
    {
      "epoch": 0.07083724502859094,
      "grad_norm": 0.03482934460043907,
      "learning_rate": 7.611816364415895e-05,
      "loss": 0.2692,
      "step": 1660
    },
    {
      "epoch": 0.07105061022446019,
      "grad_norm": 0.040283385664224625,
      "learning_rate": 7.59827339578423e-05,
      "loss": 0.2544,
      "step": 1665
    },
    {
      "epoch": 0.07126397542032943,
      "grad_norm": 0.028353312984108925,
      "learning_rate": 7.584704262568316e-05,
      "loss": 0.2814,
      "step": 1670
    },
    {
      "epoch": 0.07147734061619869,
      "grad_norm": 0.04649852588772774,
      "learning_rate": 7.571109101409171e-05,
      "loss": 0.2551,
      "step": 1675
    },
    {
      "epoch": 0.07169070581206793,
      "grad_norm": 0.05383424833416939,
      "learning_rate": 7.557488049209921e-05,
      "loss": 0.2738,
      "step": 1680
    },
    {
      "epoch": 0.07190407100793718,
      "grad_norm": 0.05910378322005272,
      "learning_rate": 7.543841243134409e-05,
      "loss": 0.2733,
      "step": 1685
    },
    {
      "epoch": 0.07211743620380644,
      "grad_norm": 0.03916218876838684,
      "learning_rate": 7.530168820605818e-05,
      "loss": 0.2915,
      "step": 1690
    },
    {
      "epoch": 0.07233080139967568,
      "grad_norm": 0.034289658069610596,
      "learning_rate": 7.516470919305298e-05,
      "loss": 0.2851,
      "step": 1695
    },
    {
      "epoch": 0.07254416659554494,
      "grad_norm": 0.023408006876707077,
      "learning_rate": 7.502747677170557e-05,
      "loss": 0.2203,
      "step": 1700
    },
    {
      "epoch": 0.07275753179141418,
      "grad_norm": 0.04985402897000313,
      "learning_rate": 7.488999232394492e-05,
      "loss": 0.3305,
      "step": 1705
    },
    {
      "epoch": 0.07297089698728343,
      "grad_norm": 0.05100056901574135,
      "learning_rate": 7.475225723423789e-05,
      "loss": 0.2597,
      "step": 1710
    },
    {
      "epoch": 0.07318426218315269,
      "grad_norm": 0.04057559370994568,
      "learning_rate": 7.461427288957532e-05,
      "loss": 0.2944,
      "step": 1715
    },
    {
      "epoch": 0.07339762737902193,
      "grad_norm": 0.041732434183359146,
      "learning_rate": 7.447604067945802e-05,
      "loss": 0.2743,
      "step": 1720
    },
    {
      "epoch": 0.07361099257489119,
      "grad_norm": 0.03119041956961155,
      "learning_rate": 7.433756199588282e-05,
      "loss": 0.2581,
      "step": 1725
    },
    {
      "epoch": 0.07382435777076043,
      "grad_norm": 0.035854071378707886,
      "learning_rate": 7.41988382333285e-05,
      "loss": 0.215,
      "step": 1730
    },
    {
      "epoch": 0.07403772296662968,
      "grad_norm": 0.05135173350572586,
      "learning_rate": 7.405987078874186e-05,
      "loss": 0.2544,
      "step": 1735
    },
    {
      "epoch": 0.07425108816249894,
      "grad_norm": 0.04098614305257797,
      "learning_rate": 7.392066106152347e-05,
      "loss": 0.2865,
      "step": 1740
    },
    {
      "epoch": 0.07446445335836818,
      "grad_norm": 0.056381240487098694,
      "learning_rate": 7.378121045351378e-05,
      "loss": 0.2604,
      "step": 1745
    },
    {
      "epoch": 0.07467781855423743,
      "grad_norm": 0.03319316729903221,
      "learning_rate": 7.364152036897882e-05,
      "loss": 0.2407,
      "step": 1750
    },
    {
      "epoch": 0.07489118375010669,
      "grad_norm": 0.03739717975258827,
      "learning_rate": 7.350159221459621e-05,
      "loss": 0.2195,
      "step": 1755
    },
    {
      "epoch": 0.07510454894597593,
      "grad_norm": 0.0708521381020546,
      "learning_rate": 7.336142739944094e-05,
      "loss": 0.2991,
      "step": 1760
    },
    {
      "epoch": 0.07531791414184519,
      "grad_norm": 0.055864688009023666,
      "learning_rate": 7.32210273349711e-05,
      "loss": 0.285,
      "step": 1765
    },
    {
      "epoch": 0.07553127933771443,
      "grad_norm": 0.05874878540635109,
      "learning_rate": 7.30803934350138e-05,
      "loss": 0.3133,
      "step": 1770
    },
    {
      "epoch": 0.07574464453358368,
      "grad_norm": 0.05106037110090256,
      "learning_rate": 7.293952711575086e-05,
      "loss": 0.2694,
      "step": 1775
    },
    {
      "epoch": 0.07595800972945294,
      "grad_norm": 0.04524580016732216,
      "learning_rate": 7.279842979570454e-05,
      "loss": 0.2586,
      "step": 1780
    },
    {
      "epoch": 0.07617137492532218,
      "grad_norm": 0.057806625962257385,
      "learning_rate": 7.265710289572328e-05,
      "loss": 0.2679,
      "step": 1785
    },
    {
      "epoch": 0.07638474012119142,
      "grad_norm": 0.049935974180698395,
      "learning_rate": 7.251554783896741e-05,
      "loss": 0.2714,
      "step": 1790
    },
    {
      "epoch": 0.07659810531706068,
      "grad_norm": 0.051934149116277695,
      "learning_rate": 7.237376605089476e-05,
      "loss": 0.2412,
      "step": 1795
    },
    {
      "epoch": 0.07681147051292993,
      "grad_norm": 0.07878798246383667,
      "learning_rate": 7.223175895924638e-05,
      "loss": 0.2681,
      "step": 1800
    },
    {
      "epoch": 0.07702483570879919,
      "grad_norm": 0.05866424739360809,
      "learning_rate": 7.20895279940321e-05,
      "loss": 0.3082,
      "step": 1805
    },
    {
      "epoch": 0.07723820090466843,
      "grad_norm": 0.038881100714206696,
      "learning_rate": 7.194707458751614e-05,
      "loss": 0.2665,
      "step": 1810
    },
    {
      "epoch": 0.07745156610053767,
      "grad_norm": 0.07077103853225708,
      "learning_rate": 7.180440017420277e-05,
      "loss": 0.2766,
      "step": 1815
    },
    {
      "epoch": 0.07766493129640693,
      "grad_norm": 0.03149977698922157,
      "learning_rate": 7.166150619082171e-05,
      "loss": 0.2552,
      "step": 1820
    },
    {
      "epoch": 0.07787829649227618,
      "grad_norm": 0.04241208732128143,
      "learning_rate": 7.15183940763138e-05,
      "loss": 0.2298,
      "step": 1825
    },
    {
      "epoch": 0.07809166168814544,
      "grad_norm": 0.04383200779557228,
      "learning_rate": 7.137506527181644e-05,
      "loss": 0.279,
      "step": 1830
    },
    {
      "epoch": 0.07830502688401468,
      "grad_norm": 0.03244629129767418,
      "learning_rate": 7.123152122064909e-05,
      "loss": 0.3213,
      "step": 1835
    },
    {
      "epoch": 0.07851839207988393,
      "grad_norm": 0.030112652108073235,
      "learning_rate": 7.108776336829877e-05,
      "loss": 0.3037,
      "step": 1840
    },
    {
      "epoch": 0.07873175727575318,
      "grad_norm": 0.04880126938223839,
      "learning_rate": 7.094379316240545e-05,
      "loss": 0.2907,
      "step": 1845
    },
    {
      "epoch": 0.07894512247162243,
      "grad_norm": 0.039399437606334686,
      "learning_rate": 7.079961205274748e-05,
      "loss": 0.294,
      "step": 1850
    },
    {
      "epoch": 0.07915848766749167,
      "grad_norm": 0.031951893121004105,
      "learning_rate": 7.06552214912271e-05,
      "loss": 0.2701,
      "step": 1855
    },
    {
      "epoch": 0.07937185286336093,
      "grad_norm": 0.03194039687514305,
      "learning_rate": 7.05106229318556e-05,
      "loss": 0.2458,
      "step": 1860
    },
    {
      "epoch": 0.07958521805923018,
      "grad_norm": 0.04526529833674431,
      "learning_rate": 7.036581783073888e-05,
      "loss": 0.2565,
      "step": 1865
    },
    {
      "epoch": 0.07979858325509943,
      "grad_norm": 0.03675670921802521,
      "learning_rate": 7.022080764606271e-05,
      "loss": 0.2447,
      "step": 1870
    },
    {
      "epoch": 0.08001194845096868,
      "grad_norm": 0.029494166374206543,
      "learning_rate": 7.007559383807803e-05,
      "loss": 0.2591,
      "step": 1875
    },
    {
      "epoch": 0.08022531364683792,
      "grad_norm": 0.041366107761859894,
      "learning_rate": 6.99301778690863e-05,
      "loss": 0.2419,
      "step": 1880
    },
    {
      "epoch": 0.08043867884270718,
      "grad_norm": 0.037852026522159576,
      "learning_rate": 6.97845612034247e-05,
      "loss": 0.2566,
      "step": 1885
    },
    {
      "epoch": 0.08065204403857643,
      "grad_norm": 0.045591387897729874,
      "learning_rate": 6.96387453074514e-05,
      "loss": 0.294,
      "step": 1890
    },
    {
      "epoch": 0.08086540923444567,
      "grad_norm": 0.05231069028377533,
      "learning_rate": 6.949273164953091e-05,
      "loss": 0.1956,
      "step": 1895
    },
    {
      "epoch": 0.08107877443031493,
      "grad_norm": 0.056985098868608475,
      "learning_rate": 6.93465217000191e-05,
      "loss": 0.2285,
      "step": 1900
    },
    {
      "epoch": 0.08129213962618417,
      "grad_norm": 0.04742848128080368,
      "learning_rate": 6.920011693124857e-05,
      "loss": 0.2261,
      "step": 1905
    },
    {
      "epoch": 0.08150550482205343,
      "grad_norm": 0.04500420019030571,
      "learning_rate": 6.905351881751372e-05,
      "loss": 0.2495,
      "step": 1910
    },
    {
      "epoch": 0.08171887001792268,
      "grad_norm": 0.046806707978248596,
      "learning_rate": 6.890672883505589e-05,
      "loss": 0.2651,
      "step": 1915
    },
    {
      "epoch": 0.08193223521379192,
      "grad_norm": 0.04837993532419205,
      "learning_rate": 6.875974846204859e-05,
      "loss": 0.2651,
      "step": 1920
    },
    {
      "epoch": 0.08214560040966118,
      "grad_norm": 0.024299215525388718,
      "learning_rate": 6.861257917858258e-05,
      "loss": 0.2394,
      "step": 1925
    },
    {
      "epoch": 0.08235896560553042,
      "grad_norm": 0.04087216034531593,
      "learning_rate": 6.846522246665083e-05,
      "loss": 0.3013,
      "step": 1930
    },
    {
      "epoch": 0.08257233080139968,
      "grad_norm": 0.030068401247262955,
      "learning_rate": 6.831767981013389e-05,
      "loss": 0.325,
      "step": 1935
    },
    {
      "epoch": 0.08278569599726893,
      "grad_norm": 0.03252981975674629,
      "learning_rate": 6.81699526947846e-05,
      "loss": 0.2342,
      "step": 1940
    },
    {
      "epoch": 0.08299906119313817,
      "grad_norm": 0.03407016769051552,
      "learning_rate": 6.80220426082134e-05,
      "loss": 0.26,
      "step": 1945
    },
    {
      "epoch": 0.08321242638900743,
      "grad_norm": 0.03799741342663765,
      "learning_rate": 6.787395103987323e-05,
      "loss": 0.3205,
      "step": 1950
    },
    {
      "epoch": 0.08342579158487667,
      "grad_norm": 0.03146937116980553,
      "learning_rate": 6.772567948104453e-05,
      "loss": 0.2648,
      "step": 1955
    },
    {
      "epoch": 0.08363915678074592,
      "grad_norm": 0.050101589411497116,
      "learning_rate": 6.757722942482023e-05,
      "loss": 0.249,
      "step": 1960
    },
    {
      "epoch": 0.08385252197661518,
      "grad_norm": 0.05255359411239624,
      "learning_rate": 6.742860236609077e-05,
      "loss": 0.2628,
      "step": 1965
    },
    {
      "epoch": 0.08406588717248442,
      "grad_norm": 0.034856874495744705,
      "learning_rate": 6.727979980152899e-05,
      "loss": 0.2317,
      "step": 1970
    },
    {
      "epoch": 0.08427925236835368,
      "grad_norm": 0.056640610098838806,
      "learning_rate": 6.713082322957502e-05,
      "loss": 0.277,
      "step": 1975
    },
    {
      "epoch": 0.08449261756422292,
      "grad_norm": 0.04408236965537071,
      "learning_rate": 6.698167415042135e-05,
      "loss": 0.2388,
      "step": 1980
    },
    {
      "epoch": 0.08470598276009217,
      "grad_norm": 0.040742501616477966,
      "learning_rate": 6.68323540659975e-05,
      "loss": 0.2729,
      "step": 1985
    },
    {
      "epoch": 0.08491934795596143,
      "grad_norm": 0.033966075628995895,
      "learning_rate": 6.668286447995508e-05,
      "loss": 0.2734,
      "step": 1990
    },
    {
      "epoch": 0.08513271315183067,
      "grad_norm": 0.030447501689195633,
      "learning_rate": 6.653320689765257e-05,
      "loss": 0.2759,
      "step": 1995
    },
    {
      "epoch": 0.08534607834769992,
      "grad_norm": 0.08190026134252548,
      "learning_rate": 6.638338282614014e-05,
      "loss": 0.2907,
      "step": 2000
    },
    {
      "epoch": 0.08555944354356917,
      "grad_norm": 0.02388741448521614,
      "learning_rate": 6.623339377414456e-05,
      "loss": 0.2254,
      "step": 2005
    },
    {
      "epoch": 0.08577280873943842,
      "grad_norm": 0.03164907917380333,
      "learning_rate": 6.608324125205388e-05,
      "loss": 0.2337,
      "step": 2010
    },
    {
      "epoch": 0.08598617393530768,
      "grad_norm": 0.047048695385456085,
      "learning_rate": 6.593292677190235e-05,
      "loss": 0.3061,
      "step": 2015
    },
    {
      "epoch": 0.08619953913117692,
      "grad_norm": 0.0645923987030983,
      "learning_rate": 6.578245184735513e-05,
      "loss": 0.2427,
      "step": 2020
    },
    {
      "epoch": 0.08641290432704617,
      "grad_norm": 0.025534668937325478,
      "learning_rate": 6.563181799369301e-05,
      "loss": 0.2838,
      "step": 2025
    },
    {
      "epoch": 0.08662626952291543,
      "grad_norm": 0.029163893312215805,
      "learning_rate": 6.548102672779724e-05,
      "loss": 0.2681,
      "step": 2030
    },
    {
      "epoch": 0.08683963471878467,
      "grad_norm": 0.07058608531951904,
      "learning_rate": 6.533007956813421e-05,
      "loss": 0.3099,
      "step": 2035
    },
    {
      "epoch": 0.08705299991465393,
      "grad_norm": 0.04340500384569168,
      "learning_rate": 6.517897803474011e-05,
      "loss": 0.235,
      "step": 2040
    },
    {
      "epoch": 0.08726636511052317,
      "grad_norm": 0.040255095809698105,
      "learning_rate": 6.502772364920573e-05,
      "loss": 0.2516,
      "step": 2045
    },
    {
      "epoch": 0.08747973030639242,
      "grad_norm": 0.04492196813225746,
      "learning_rate": 6.487631793466104e-05,
      "loss": 0.3079,
      "step": 2050
    },
    {
      "epoch": 0.08769309550226168,
      "grad_norm": 0.03649269789457321,
      "learning_rate": 6.472476241575989e-05,
      "loss": 0.2489,
      "step": 2055
    },
    {
      "epoch": 0.08790646069813092,
      "grad_norm": 0.042938895523548126,
      "learning_rate": 6.457305861866471e-05,
      "loss": 0.202,
      "step": 2060
    },
    {
      "epoch": 0.08811982589400016,
      "grad_norm": 0.022924307733774185,
      "learning_rate": 6.442120807103101e-05,
      "loss": 0.2816,
      "step": 2065
    },
    {
      "epoch": 0.08833319108986942,
      "grad_norm": 0.03915401175618172,
      "learning_rate": 6.426921230199214e-05,
      "loss": 0.2539,
      "step": 2070
    },
    {
      "epoch": 0.08854655628573867,
      "grad_norm": 0.038005322217941284,
      "learning_rate": 6.411707284214384e-05,
      "loss": 0.2739,
      "step": 2075
    },
    {
      "epoch": 0.08875992148160793,
      "grad_norm": 0.024789581075310707,
      "learning_rate": 6.396479122352873e-05,
      "loss": 0.2854,
      "step": 2080
    },
    {
      "epoch": 0.08897328667747717,
      "grad_norm": 0.04293755441904068,
      "learning_rate": 6.381236897962102e-05,
      "loss": 0.2906,
      "step": 2085
    },
    {
      "epoch": 0.08918665187334641,
      "grad_norm": 0.07479886710643768,
      "learning_rate": 6.365980764531106e-05,
      "loss": 0.2565,
      "step": 2090
    },
    {
      "epoch": 0.08940001706921567,
      "grad_norm": 0.034313835203647614,
      "learning_rate": 6.350710875688972e-05,
      "loss": 0.2985,
      "step": 2095
    },
    {
      "epoch": 0.08961338226508492,
      "grad_norm": 0.050408486276865005,
      "learning_rate": 6.33542738520332e-05,
      "loss": 0.3161,
      "step": 2100
    },
    {
      "epoch": 0.08982674746095418,
      "grad_norm": 0.06110876053571701,
      "learning_rate": 6.320130446978723e-05,
      "loss": 0.2535,
      "step": 2105
    },
    {
      "epoch": 0.09004011265682342,
      "grad_norm": 0.03833309933543205,
      "learning_rate": 6.30482021505518e-05,
      "loss": 0.2277,
      "step": 2110
    },
    {
      "epoch": 0.09025347785269267,
      "grad_norm": 0.07273266464471817,
      "learning_rate": 6.289496843606559e-05,
      "loss": 0.2896,
      "step": 2115
    },
    {
      "epoch": 0.09046684304856192,
      "grad_norm": 0.046822745352983475,
      "learning_rate": 6.27416048693904e-05,
      "loss": 0.288,
      "step": 2120
    },
    {
      "epoch": 0.09068020824443117,
      "grad_norm": 0.03319999575614929,
      "learning_rate": 6.258811299489563e-05,
      "loss": 0.2332,
      "step": 2125
    },
    {
      "epoch": 0.09089357344030041,
      "grad_norm": 0.040677960962057114,
      "learning_rate": 6.243449435824276e-05,
      "loss": 0.2268,
      "step": 2130
    },
    {
      "epoch": 0.09110693863616967,
      "grad_norm": 0.0314982570707798,
      "learning_rate": 6.228075050636972e-05,
      "loss": 0.2239,
      "step": 2135
    },
    {
      "epoch": 0.09132030383203892,
      "grad_norm": 0.07740900665521622,
      "learning_rate": 6.212688298747545e-05,
      "loss": 0.2692,
      "step": 2140
    },
    {
      "epoch": 0.09153366902790817,
      "grad_norm": 0.045600373297929764,
      "learning_rate": 6.197289335100413e-05,
      "loss": 0.2935,
      "step": 2145
    },
    {
      "epoch": 0.09174703422377742,
      "grad_norm": 0.042281970381736755,
      "learning_rate": 6.181878314762968e-05,
      "loss": 0.2754,
      "step": 2150
    },
    {
      "epoch": 0.09196039941964666,
      "grad_norm": 0.052572544664144516,
      "learning_rate": 6.166455392924015e-05,
      "loss": 0.2387,
      "step": 2155
    },
    {
      "epoch": 0.09217376461551592,
      "grad_norm": 0.03985495865345001,
      "learning_rate": 6.151020724892204e-05,
      "loss": 0.2466,
      "step": 2160
    },
    {
      "epoch": 0.09238712981138517,
      "grad_norm": 0.04332344979047775,
      "learning_rate": 6.135574466094475e-05,
      "loss": 0.2828,
      "step": 2165
    },
    {
      "epoch": 0.09260049500725441,
      "grad_norm": 0.07385674118995667,
      "learning_rate": 6.120116772074478e-05,
      "loss": 0.2873,
      "step": 2170
    },
    {
      "epoch": 0.09281386020312367,
      "grad_norm": 0.03396092355251312,
      "learning_rate": 6.104647798491021e-05,
      "loss": 0.2777,
      "step": 2175
    },
    {
      "epoch": 0.09302722539899291,
      "grad_norm": 0.05595475435256958,
      "learning_rate": 6.089167701116498e-05,
      "loss": 0.2985,
      "step": 2180
    },
    {
      "epoch": 0.09324059059486217,
      "grad_norm": 0.0753965824842453,
      "learning_rate": 6.073676635835317e-05,
      "loss": 0.3032,
      "step": 2185
    },
    {
      "epoch": 0.09345395579073142,
      "grad_norm": 0.0423317551612854,
      "learning_rate": 6.0581747586423324e-05,
      "loss": 0.3092,
      "step": 2190
    },
    {
      "epoch": 0.09366732098660066,
      "grad_norm": 0.10067365318536758,
      "learning_rate": 6.0426622256412765e-05,
      "loss": 0.2791,
      "step": 2195
    },
    {
      "epoch": 0.09388068618246992,
      "grad_norm": 0.04766010120511055,
      "learning_rate": 6.027139193043184e-05,
      "loss": 0.2418,
      "step": 2200
    },
    {
      "epoch": 0.09409405137833916,
      "grad_norm": 0.05847075954079628,
      "learning_rate": 6.0116058171648215e-05,
      "loss": 0.2601,
      "step": 2205
    },
    {
      "epoch": 0.09430741657420842,
      "grad_norm": 0.02777671068906784,
      "learning_rate": 5.9960622544271114e-05,
      "loss": 0.2332,
      "step": 2210
    },
    {
      "epoch": 0.09452078177007767,
      "grad_norm": 0.04333260655403137,
      "learning_rate": 5.9805086613535565e-05,
      "loss": 0.2381,
      "step": 2215
    },
    {
      "epoch": 0.09473414696594691,
      "grad_norm": 0.044327761977910995,
      "learning_rate": 5.964945194568668e-05,
      "loss": 0.244,
      "step": 2220
    },
    {
      "epoch": 0.09494751216181617,
      "grad_norm": 0.035913433879613876,
      "learning_rate": 5.949372010796383e-05,
      "loss": 0.2766,
      "step": 2225
    },
    {
      "epoch": 0.09516087735768541,
      "grad_norm": 0.07593889534473419,
      "learning_rate": 5.9337892668584896e-05,
      "loss": 0.2582,
      "step": 2230
    },
    {
      "epoch": 0.09537424255355466,
      "grad_norm": 0.0599554143846035,
      "learning_rate": 5.9181971196730454e-05,
      "loss": 0.3123,
      "step": 2235
    },
    {
      "epoch": 0.09558760774942392,
      "grad_norm": 0.039003703743219376,
      "learning_rate": 5.902595726252801e-05,
      "loss": 0.264,
      "step": 2240
    },
    {
      "epoch": 0.09580097294529316,
      "grad_norm": 0.06314410269260406,
      "learning_rate": 5.886985243703612e-05,
      "loss": 0.2965,
      "step": 2245
    },
    {
      "epoch": 0.09601433814116242,
      "grad_norm": 0.03709486126899719,
      "learning_rate": 5.871365829222869e-05,
      "loss": 0.2283,
      "step": 2250
    },
    {
      "epoch": 0.09622770333703166,
      "grad_norm": 0.030805354937911034,
      "learning_rate": 5.855737640097897e-05,
      "loss": 0.2542,
      "step": 2255
    },
    {
      "epoch": 0.09644106853290091,
      "grad_norm": 0.036497101187705994,
      "learning_rate": 5.840100833704392e-05,
      "loss": 0.2459,
      "step": 2260
    },
    {
      "epoch": 0.09665443372877017,
      "grad_norm": 0.031612712889909744,
      "learning_rate": 5.824455567504817e-05,
      "loss": 0.269,
      "step": 2265
    },
    {
      "epoch": 0.09686779892463941,
      "grad_norm": 0.05919693410396576,
      "learning_rate": 5.80880199904683e-05,
      "loss": 0.2703,
      "step": 2270
    },
    {
      "epoch": 0.09708116412050866,
      "grad_norm": 0.03870662301778793,
      "learning_rate": 5.793140285961692e-05,
      "loss": 0.2762,
      "step": 2275
    },
    {
      "epoch": 0.09729452931637791,
      "grad_norm": 0.0504191592335701,
      "learning_rate": 5.7774705859626824e-05,
      "loss": 0.2498,
      "step": 2280
    },
    {
      "epoch": 0.09750789451224716,
      "grad_norm": 0.057310234755277634,
      "learning_rate": 5.761793056843501e-05,
      "loss": 0.2439,
      "step": 2285
    },
    {
      "epoch": 0.09772125970811642,
      "grad_norm": 0.062385957688093185,
      "learning_rate": 5.746107856476695e-05,
      "loss": 0.2422,
      "step": 2290
    },
    {
      "epoch": 0.09793462490398566,
      "grad_norm": 0.032431695610284805,
      "learning_rate": 5.730415142812059e-05,
      "loss": 0.2709,
      "step": 2295
    },
    {
      "epoch": 0.0981479900998549,
      "grad_norm": 0.08663284778594971,
      "learning_rate": 5.7147150738750434e-05,
      "loss": 0.3159,
      "step": 2300
    },
    {
      "epoch": 0.09836135529572416,
      "grad_norm": 0.04084755480289459,
      "learning_rate": 5.6990078077651686e-05,
      "loss": 0.2674,
      "step": 2305
    },
    {
      "epoch": 0.09857472049159341,
      "grad_norm": 0.04680114984512329,
      "learning_rate": 5.683293502654429e-05,
      "loss": 0.2908,
      "step": 2310
    },
    {
      "epoch": 0.09878808568746267,
      "grad_norm": 0.0287613607943058,
      "learning_rate": 5.6675723167857054e-05,
      "loss": 0.2486,
      "step": 2315
    },
    {
      "epoch": 0.09900145088333191,
      "grad_norm": 0.05885633826255798,
      "learning_rate": 5.651844408471162e-05,
      "loss": 0.3344,
      "step": 2320
    },
    {
      "epoch": 0.09921481607920116,
      "grad_norm": 0.061988044530153275,
      "learning_rate": 5.636109936090661e-05,
      "loss": 0.2596,
      "step": 2325
    },
    {
      "epoch": 0.09942818127507042,
      "grad_norm": 0.03821874037384987,
      "learning_rate": 5.620369058090168e-05,
      "loss": 0.2385,
      "step": 2330
    },
    {
      "epoch": 0.09964154647093966,
      "grad_norm": 0.04039385914802551,
      "learning_rate": 5.604621932980148e-05,
      "loss": 0.2502,
      "step": 2335
    },
    {
      "epoch": 0.0998549116668089,
      "grad_norm": 0.034449685364961624,
      "learning_rate": 5.588868719333974e-05,
      "loss": 0.2453,
      "step": 2340
    },
    {
      "epoch": 0.10006827686267816,
      "grad_norm": 0.06667604297399521,
      "learning_rate": 5.573109575786334e-05,
      "loss": 0.3029,
      "step": 2345
    },
    {
      "epoch": 0.10028164205854741,
      "grad_norm": 0.04918724671006203,
      "learning_rate": 5.557344661031627e-05,
      "loss": 0.2788,
      "step": 2350
    },
    {
      "epoch": 0.10049500725441667,
      "grad_norm": 0.050029486417770386,
      "learning_rate": 5.5415741338223736e-05,
      "loss": 0.2573,
      "step": 2355
    },
    {
      "epoch": 0.10070837245028591,
      "grad_norm": 0.03130852058529854,
      "learning_rate": 5.525798152967605e-05,
      "loss": 0.2494,
      "step": 2360
    },
    {
      "epoch": 0.10092173764615515,
      "grad_norm": 0.0649510994553566,
      "learning_rate": 5.510016877331271e-05,
      "loss": 0.3011,
      "step": 2365
    },
    {
      "epoch": 0.10113510284202441,
      "grad_norm": 0.06331179291009903,
      "learning_rate": 5.494230465830647e-05,
      "loss": 0.2865,
      "step": 2370
    },
    {
      "epoch": 0.10134846803789366,
      "grad_norm": 0.047020912170410156,
      "learning_rate": 5.478439077434718e-05,
      "loss": 0.2557,
      "step": 2375
    },
    {
      "epoch": 0.1015618332337629,
      "grad_norm": 0.04574167728424072,
      "learning_rate": 5.462642871162592e-05,
      "loss": 0.232,
      "step": 2380
    },
    {
      "epoch": 0.10177519842963216,
      "grad_norm": 0.051083505153656006,
      "learning_rate": 5.446842006081889e-05,
      "loss": 0.2624,
      "step": 2385
    },
    {
      "epoch": 0.1019885636255014,
      "grad_norm": 0.0369320884346962,
      "learning_rate": 5.4310366413071454e-05,
      "loss": 0.2661,
      "step": 2390
    },
    {
      "epoch": 0.10220192882137066,
      "grad_norm": 0.04675738513469696,
      "learning_rate": 5.41522693599821e-05,
      "loss": 0.294,
      "step": 2395
    },
    {
      "epoch": 0.10241529401723991,
      "grad_norm": 0.026956388726830482,
      "learning_rate": 5.399413049358638e-05,
      "loss": 0.2762,
      "step": 2400
    },
    {
      "epoch": 0.10262865921310915,
      "grad_norm": 0.02909787930548191,
      "learning_rate": 5.383595140634093e-05,
      "loss": 0.2337,
      "step": 2405
    },
    {
      "epoch": 0.10284202440897841,
      "grad_norm": 0.03831162303686142,
      "learning_rate": 5.3677733691107415e-05,
      "loss": 0.2882,
      "step": 2410
    },
    {
      "epoch": 0.10305538960484766,
      "grad_norm": 0.03243284672498703,
      "learning_rate": 5.351947894113646e-05,
      "loss": 0.2759,
      "step": 2415
    },
    {
      "epoch": 0.10326875480071691,
      "grad_norm": 0.04824114590883255,
      "learning_rate": 5.3361188750051646e-05,
      "loss": 0.2979,
      "step": 2420
    },
    {
      "epoch": 0.10348211999658616,
      "grad_norm": 0.03624056652188301,
      "learning_rate": 5.320286471183343e-05,
      "loss": 0.2503,
      "step": 2425
    },
    {
      "epoch": 0.1036954851924554,
      "grad_norm": 0.032411981374025345,
      "learning_rate": 5.304450842080312e-05,
      "loss": 0.2427,
      "step": 2430
    },
    {
      "epoch": 0.10390885038832466,
      "grad_norm": 0.04932332783937454,
      "learning_rate": 5.288612147160681e-05,
      "loss": 0.2354,
      "step": 2435
    },
    {
      "epoch": 0.1041222155841939,
      "grad_norm": 0.044771142303943634,
      "learning_rate": 5.2727705459199336e-05,
      "loss": 0.2072,
      "step": 2440
    },
    {
      "epoch": 0.10433558078006315,
      "grad_norm": 0.058937136083841324,
      "learning_rate": 5.2569261978828155e-05,
      "loss": 0.2615,
      "step": 2445
    },
    {
      "epoch": 0.10454894597593241,
      "grad_norm": 0.09139160066843033,
      "learning_rate": 5.241079262601738e-05,
      "loss": 0.2613,
      "step": 2450
    },
    {
      "epoch": 0.10476231117180165,
      "grad_norm": 0.060784418135881424,
      "learning_rate": 5.225229899655163e-05,
      "loss": 0.2982,
      "step": 2455
    },
    {
      "epoch": 0.10497567636767091,
      "grad_norm": 0.05327871814370155,
      "learning_rate": 5.209378268645998e-05,
      "loss": 0.2496,
      "step": 2460
    },
    {
      "epoch": 0.10518904156354016,
      "grad_norm": 0.14507333934307098,
      "learning_rate": 5.1935245291999945e-05,
      "loss": 0.2963,
      "step": 2465
    },
    {
      "epoch": 0.1054024067594094,
      "grad_norm": 0.05370772257447243,
      "learning_rate": 5.177668840964127e-05,
      "loss": 0.2428,
      "step": 2470
    },
    {
      "epoch": 0.10561577195527866,
      "grad_norm": 0.05686064809560776,
      "learning_rate": 5.161811363605006e-05,
      "loss": 0.2831,
      "step": 2475
    },
    {
      "epoch": 0.1058291371511479,
      "grad_norm": 0.05286341533064842,
      "learning_rate": 5.1459522568072496e-05,
      "loss": 0.285,
      "step": 2480
    },
    {
      "epoch": 0.10604250234701715,
      "grad_norm": 0.03203525394201279,
      "learning_rate": 5.1300916802718866e-05,
      "loss": 0.2668,
      "step": 2485
    },
    {
      "epoch": 0.1062558675428864,
      "grad_norm": 0.03850114345550537,
      "learning_rate": 5.1142297937147487e-05,
      "loss": 0.2629,
      "step": 2490
    },
    {
      "epoch": 0.10646923273875565,
      "grad_norm": 0.031194498762488365,
      "learning_rate": 5.098366756864855e-05,
      "loss": 0.2832,
      "step": 2495
    },
    {
      "epoch": 0.10668259793462491,
      "grad_norm": 0.04863932728767395,
      "learning_rate": 5.082502729462813e-05,
      "loss": 0.2767,
      "step": 2500
    },
    {
      "epoch": 0.10689596313049415,
      "grad_norm": 0.03968985006213188,
      "learning_rate": 5.066637871259201e-05,
      "loss": 0.2448,
      "step": 2505
    },
    {
      "epoch": 0.1071093283263634,
      "grad_norm": 0.06314889341592789,
      "learning_rate": 5.050772342012966e-05,
      "loss": 0.2341,
      "step": 2510
    },
    {
      "epoch": 0.10732269352223266,
      "grad_norm": 0.05082229897379875,
      "learning_rate": 5.034906301489808e-05,
      "loss": 0.327,
      "step": 2515
    },
    {
      "epoch": 0.1075360587181019,
      "grad_norm": 0.052222758531570435,
      "learning_rate": 5.019039909460583e-05,
      "loss": 0.2951,
      "step": 2520
    },
    {
      "epoch": 0.10774942391397116,
      "grad_norm": 0.04903097823262215,
      "learning_rate": 5.003173325699682e-05,
      "loss": 0.2322,
      "step": 2525
    },
    {
      "epoch": 0.1079627891098404,
      "grad_norm": 0.0558171421289444,
      "learning_rate": 4.9873067099834256e-05,
      "loss": 0.2615,
      "step": 2530
    },
    {
      "epoch": 0.10817615430570965,
      "grad_norm": 0.029709627851843834,
      "learning_rate": 4.971440222088459e-05,
      "loss": 0.2311,
      "step": 2535
    },
    {
      "epoch": 0.10838951950157891,
      "grad_norm": 0.03654881939291954,
      "learning_rate": 4.9555740217901374e-05,
      "loss": 0.3172,
      "step": 2540
    },
    {
      "epoch": 0.10860288469744815,
      "grad_norm": 0.02956932783126831,
      "learning_rate": 4.939708268860925e-05,
      "loss": 0.2226,
      "step": 2545
    },
    {
      "epoch": 0.1088162498933174,
      "grad_norm": 0.03645358234643936,
      "learning_rate": 4.9238431230687754e-05,
      "loss": 0.29,
      "step": 2550
    },
    {
      "epoch": 0.10902961508918665,
      "grad_norm": 0.04032149165868759,
      "learning_rate": 4.90797874417553e-05,
      "loss": 0.2597,
      "step": 2555
    },
    {
      "epoch": 0.1092429802850559,
      "grad_norm": 0.03580070659518242,
      "learning_rate": 4.8921152919353105e-05,
      "loss": 0.2585,
      "step": 2560
    },
    {
      "epoch": 0.10945634548092516,
      "grad_norm": 0.06133759021759033,
      "learning_rate": 4.876252926092903e-05,
      "loss": 0.2644,
      "step": 2565
    },
    {
      "epoch": 0.1096697106767944,
      "grad_norm": 0.046570923179388046,
      "learning_rate": 4.860391806382157e-05,
      "loss": 0.2351,
      "step": 2570
    },
    {
      "epoch": 0.10988307587266365,
      "grad_norm": 0.05906417965888977,
      "learning_rate": 4.84453209252437e-05,
      "loss": 0.2514,
      "step": 2575
    },
    {
      "epoch": 0.1100964410685329,
      "grad_norm": 0.03712646663188934,
      "learning_rate": 4.8286739442266835e-05,
      "loss": 0.2268,
      "step": 2580
    },
    {
      "epoch": 0.11030980626440215,
      "grad_norm": 0.05033416301012039,
      "learning_rate": 4.8128175211804786e-05,
      "loss": 0.2337,
      "step": 2585
    },
    {
      "epoch": 0.1105231714602714,
      "grad_norm": 0.04265936464071274,
      "learning_rate": 4.7969629830597576e-05,
      "loss": 0.2853,
      "step": 2590
    },
    {
      "epoch": 0.11073653665614065,
      "grad_norm": 0.04118423908948898,
      "learning_rate": 4.781110489519541e-05,
      "loss": 0.2856,
      "step": 2595
    },
    {
      "epoch": 0.1109499018520099,
      "grad_norm": 0.04586204141378403,
      "learning_rate": 4.765260200194266e-05,
      "loss": 0.2586,
      "step": 2600
    },
    {
      "epoch": 0.11116326704787916,
      "grad_norm": 0.06333041936159134,
      "learning_rate": 4.7494122746961686e-05,
      "loss": 0.221,
      "step": 2605
    },
    {
      "epoch": 0.1113766322437484,
      "grad_norm": 0.04458615183830261,
      "learning_rate": 4.733566872613683e-05,
      "loss": 0.2415,
      "step": 2610
    },
    {
      "epoch": 0.11158999743961764,
      "grad_norm": 0.037213172763586044,
      "learning_rate": 4.7177241535098324e-05,
      "loss": 0.2441,
      "step": 2615
    },
    {
      "epoch": 0.1118033626354869,
      "grad_norm": 0.04331325367093086,
      "learning_rate": 4.701884276920622e-05,
      "loss": 0.2365,
      "step": 2620
    },
    {
      "epoch": 0.11201672783135615,
      "grad_norm": 0.06074150651693344,
      "learning_rate": 4.6860474023534335e-05,
      "loss": 0.2854,
      "step": 2625
    },
    {
      "epoch": 0.1122300930272254,
      "grad_norm": 0.05312689021229744,
      "learning_rate": 4.670213689285418e-05,
      "loss": 0.2524,
      "step": 2630
    },
    {
      "epoch": 0.11244345822309465,
      "grad_norm": 0.049623895436525345,
      "learning_rate": 4.654383297161889e-05,
      "loss": 0.2131,
      "step": 2635
    },
    {
      "epoch": 0.1126568234189639,
      "grad_norm": 0.07101915031671524,
      "learning_rate": 4.6385563853947213e-05,
      "loss": 0.2302,
      "step": 2640
    },
    {
      "epoch": 0.11287018861483315,
      "grad_norm": 0.030831437557935715,
      "learning_rate": 4.62273311336074e-05,
      "loss": 0.2362,
      "step": 2645
    },
    {
      "epoch": 0.1130835538107024,
      "grad_norm": 0.06696966290473938,
      "learning_rate": 4.606913640400118e-05,
      "loss": 0.3181,
      "step": 2650
    },
    {
      "epoch": 0.11329691900657164,
      "grad_norm": 0.026515573263168335,
      "learning_rate": 4.591098125814776e-05,
      "loss": 0.2149,
      "step": 2655
    },
    {
      "epoch": 0.1135102842024409,
      "grad_norm": 0.033425815403461456,
      "learning_rate": 4.5752867288667646e-05,
      "loss": 0.25,
      "step": 2660
    },
    {
      "epoch": 0.11372364939831014,
      "grad_norm": 0.026654472574591637,
      "learning_rate": 4.559479608776679e-05,
      "loss": 0.249,
      "step": 2665
    },
    {
      "epoch": 0.1139370145941794,
      "grad_norm": 0.027500402182340622,
      "learning_rate": 4.5436769247220423e-05,
      "loss": 0.2511,
      "step": 2670
    },
    {
      "epoch": 0.11415037979004865,
      "grad_norm": 0.041889481246471405,
      "learning_rate": 4.5278788358357066e-05,
      "loss": 0.2627,
      "step": 2675
    },
    {
      "epoch": 0.11436374498591789,
      "grad_norm": 0.03637152537703514,
      "learning_rate": 4.512085501204253e-05,
      "loss": 0.2635,
      "step": 2680
    },
    {
      "epoch": 0.11457711018178715,
      "grad_norm": 0.03357625752687454,
      "learning_rate": 4.496297079866387e-05,
      "loss": 0.2148,
      "step": 2685
    },
    {
      "epoch": 0.1147904753776564,
      "grad_norm": 0.04441482573747635,
      "learning_rate": 4.480513730811332e-05,
      "loss": 0.2686,
      "step": 2690
    },
    {
      "epoch": 0.11500384057352564,
      "grad_norm": 0.04678015410900116,
      "learning_rate": 4.464735612977242e-05,
      "loss": 0.2865,
      "step": 2695
    },
    {
      "epoch": 0.1152172057693949,
      "grad_norm": 0.05661318078637123,
      "learning_rate": 4.448962885249587e-05,
      "loss": 0.245,
      "step": 2700
    },
    {
      "epoch": 0.11543057096526414,
      "grad_norm": 0.0858657956123352,
      "learning_rate": 4.4331957064595584e-05,
      "loss": 0.3022,
      "step": 2705
    },
    {
      "epoch": 0.1156439361611334,
      "grad_norm": 0.041589103639125824,
      "learning_rate": 4.417434235382474e-05,
      "loss": 0.2804,
      "step": 2710
    },
    {
      "epoch": 0.11585730135700265,
      "grad_norm": 0.08438806235790253,
      "learning_rate": 4.401678630736172e-05,
      "loss": 0.269,
      "step": 2715
    },
    {
      "epoch": 0.11607066655287189,
      "grad_norm": 0.044863510876894,
      "learning_rate": 4.385929051179414e-05,
      "loss": 0.2487,
      "step": 2720
    },
    {
      "epoch": 0.11628403174874115,
      "grad_norm": 0.03649313002824783,
      "learning_rate": 4.370185655310295e-05,
      "loss": 0.2226,
      "step": 2725
    },
    {
      "epoch": 0.11649739694461039,
      "grad_norm": 0.0406070314347744,
      "learning_rate": 4.354448601664634e-05,
      "loss": 0.2346,
      "step": 2730
    },
    {
      "epoch": 0.11671076214047965,
      "grad_norm": 0.02676733396947384,
      "learning_rate": 4.3387180487143876e-05,
      "loss": 0.2191,
      "step": 2735
    },
    {
      "epoch": 0.1169241273363489,
      "grad_norm": 0.06558234989643097,
      "learning_rate": 4.32299415486605e-05,
      "loss": 0.3042,
      "step": 2740
    },
    {
      "epoch": 0.11713749253221814,
      "grad_norm": 0.03996054083108902,
      "learning_rate": 4.307277078459056e-05,
      "loss": 0.3291,
      "step": 2745
    },
    {
      "epoch": 0.1173508577280874,
      "grad_norm": 0.02801872417330742,
      "learning_rate": 4.2915669777641916e-05,
      "loss": 0.2573,
      "step": 2750
    },
    {
      "epoch": 0.11756422292395664,
      "grad_norm": 0.040861789137125015,
      "learning_rate": 4.2758640109819946e-05,
      "loss": 0.2992,
      "step": 2755
    },
    {
      "epoch": 0.11777758811982589,
      "grad_norm": 0.054297640919685364,
      "learning_rate": 4.260168336241169e-05,
      "loss": 0.2871,
      "step": 2760
    },
    {
      "epoch": 0.11799095331569515,
      "grad_norm": 0.02793304994702339,
      "learning_rate": 4.2444801115969835e-05,
      "loss": 0.2573,
      "step": 2765
    },
    {
      "epoch": 0.11820431851156439,
      "grad_norm": 0.031585920602083206,
      "learning_rate": 4.228799495029685e-05,
      "loss": 0.2489,
      "step": 2770
    },
    {
      "epoch": 0.11841768370743365,
      "grad_norm": 0.04898041486740112,
      "learning_rate": 4.213126644442911e-05,
      "loss": 0.2821,
      "step": 2775
    },
    {
      "epoch": 0.1186310489033029,
      "grad_norm": 0.046118322759866714,
      "learning_rate": 4.1974617176620914e-05,
      "loss": 0.2433,
      "step": 2780
    },
    {
      "epoch": 0.11884441409917214,
      "grad_norm": 0.03537612408399582,
      "learning_rate": 4.181804872432864e-05,
      "loss": 0.254,
      "step": 2785
    },
    {
      "epoch": 0.1190577792950414,
      "grad_norm": 0.05668311566114426,
      "learning_rate": 4.166156266419489e-05,
      "loss": 0.2945,
      "step": 2790
    },
    {
      "epoch": 0.11927114449091064,
      "grad_norm": 0.08627649396657944,
      "learning_rate": 4.1505160572032535e-05,
      "loss": 0.2446,
      "step": 2795
    },
    {
      "epoch": 0.11948450968677989,
      "grad_norm": 0.05237076058983803,
      "learning_rate": 4.1348844022808896e-05,
      "loss": 0.2057,
      "step": 2800
    },
    {
      "epoch": 0.11969787488264914,
      "grad_norm": 0.04535693675279617,
      "learning_rate": 4.1192614590629915e-05,
      "loss": 0.2478,
      "step": 2805
    },
    {
      "epoch": 0.11991124007851839,
      "grad_norm": 0.04677361249923706,
      "learning_rate": 4.1036473848724234e-05,
      "loss": 0.2527,
      "step": 2810
    },
    {
      "epoch": 0.12012460527438765,
      "grad_norm": 0.0905814841389656,
      "learning_rate": 4.0880423369427354e-05,
      "loss": 0.2903,
      "step": 2815
    },
    {
      "epoch": 0.12033797047025689,
      "grad_norm": 0.0332392118871212,
      "learning_rate": 4.072446472416592e-05,
      "loss": 0.2261,
      "step": 2820
    },
    {
      "epoch": 0.12055133566612614,
      "grad_norm": 0.02587384171783924,
      "learning_rate": 4.056859948344175e-05,
      "loss": 0.2705,
      "step": 2825
    },
    {
      "epoch": 0.1207647008619954,
      "grad_norm": 0.035545483231544495,
      "learning_rate": 4.041282921681605e-05,
      "loss": 0.2714,
      "step": 2830
    },
    {
      "epoch": 0.12097806605786464,
      "grad_norm": 0.03514299541711807,
      "learning_rate": 4.0257155492893705e-05,
      "loss": 0.2501,
      "step": 2835
    },
    {
      "epoch": 0.1211914312537339,
      "grad_norm": 0.0574767179787159,
      "learning_rate": 4.010157987930738e-05,
      "loss": 0.3075,
      "step": 2840
    },
    {
      "epoch": 0.12140479644960314,
      "grad_norm": 0.049769505858421326,
      "learning_rate": 3.9946103942701777e-05,
      "loss": 0.2528,
      "step": 2845
    },
    {
      "epoch": 0.12161816164547239,
      "grad_norm": 0.04318522661924362,
      "learning_rate": 3.9790729248717846e-05,
      "loss": 0.3193,
      "step": 2850
    },
    {
      "epoch": 0.12183152684134164,
      "grad_norm": 0.0307186096906662,
      "learning_rate": 3.963545736197705e-05,
      "loss": 0.228,
      "step": 2855
    },
    {
      "epoch": 0.12204489203721089,
      "grad_norm": 0.0428936704993248,
      "learning_rate": 3.9480289846065546e-05,
      "loss": 0.2662,
      "step": 2860
    },
    {
      "epoch": 0.12225825723308013,
      "grad_norm": 0.06488286703824997,
      "learning_rate": 3.9325228263518486e-05,
      "loss": 0.3167,
      "step": 2865
    },
    {
      "epoch": 0.12247162242894939,
      "grad_norm": 0.029549244791269302,
      "learning_rate": 3.917027417580432e-05,
      "loss": 0.2308,
      "step": 2870
    },
    {
      "epoch": 0.12268498762481864,
      "grad_norm": 0.032162122428417206,
      "learning_rate": 3.901542914330896e-05,
      "loss": 0.2055,
      "step": 2875
    },
    {
      "epoch": 0.1228983528206879,
      "grad_norm": 0.06762605160474777,
      "learning_rate": 3.886069472532018e-05,
      "loss": 0.2759,
      "step": 2880
    },
    {
      "epoch": 0.12311171801655714,
      "grad_norm": 0.033321306109428406,
      "learning_rate": 3.870607248001184e-05,
      "loss": 0.2513,
      "step": 2885
    },
    {
      "epoch": 0.12332508321242638,
      "grad_norm": 0.05399736762046814,
      "learning_rate": 3.855156396442825e-05,
      "loss": 0.2869,
      "step": 2890
    },
    {
      "epoch": 0.12353844840829564,
      "grad_norm": 0.0451161190867424,
      "learning_rate": 3.8397170734468425e-05,
      "loss": 0.2737,
      "step": 2895
    },
    {
      "epoch": 0.12375181360416489,
      "grad_norm": 0.033654969185590744,
      "learning_rate": 3.82428943448705e-05,
      "loss": 0.2391,
      "step": 2900
    },
    {
      "epoch": 0.12396517880003415,
      "grad_norm": 0.04707837104797363,
      "learning_rate": 3.808873634919599e-05,
      "loss": 0.2368,
      "step": 2905
    },
    {
      "epoch": 0.12417854399590339,
      "grad_norm": 0.032994143664836884,
      "learning_rate": 3.79346982998142e-05,
      "loss": 0.2187,
      "step": 2910
    },
    {
      "epoch": 0.12439190919177263,
      "grad_norm": 0.04009908437728882,
      "learning_rate": 3.778078174788659e-05,
      "loss": 0.2819,
      "step": 2915
    },
    {
      "epoch": 0.12460527438764189,
      "grad_norm": 0.06938085705041885,
      "learning_rate": 3.762698824335113e-05,
      "loss": 0.3021,
      "step": 2920
    },
    {
      "epoch": 0.12481863958351114,
      "grad_norm": 0.07776753604412079,
      "learning_rate": 3.7473319334906674e-05,
      "loss": 0.2557,
      "step": 2925
    },
    {
      "epoch": 0.1250320047793804,
      "grad_norm": 0.06620918959379196,
      "learning_rate": 3.731977656999744e-05,
      "loss": 0.2868,
      "step": 2930
    },
    {
      "epoch": 0.12524536997524963,
      "grad_norm": 0.04809044674038887,
      "learning_rate": 3.7166361494797376e-05,
      "loss": 0.2875,
      "step": 2935
    },
    {
      "epoch": 0.12545873517111888,
      "grad_norm": 0.06502178311347961,
      "learning_rate": 3.7013075654194585e-05,
      "loss": 0.2629,
      "step": 2940
    },
    {
      "epoch": 0.12567210036698814,
      "grad_norm": 0.03554438054561615,
      "learning_rate": 3.685992059177576e-05,
      "loss": 0.2955,
      "step": 2945
    },
    {
      "epoch": 0.12588546556285737,
      "grad_norm": 0.05960332974791527,
      "learning_rate": 3.6706897849810705e-05,
      "loss": 0.2419,
      "step": 2950
    },
    {
      "epoch": 0.12609883075872663,
      "grad_norm": 0.05557112395763397,
      "learning_rate": 3.655400896923672e-05,
      "loss": 0.234,
      "step": 2955
    },
    {
      "epoch": 0.1263121959545959,
      "grad_norm": 0.037429530173540115,
      "learning_rate": 3.6401255489643126e-05,
      "loss": 0.2709,
      "step": 2960
    },
    {
      "epoch": 0.12652556115046515,
      "grad_norm": 0.035069789737463,
      "learning_rate": 3.624863894925579e-05,
      "loss": 0.2597,
      "step": 2965
    },
    {
      "epoch": 0.12673892634633438,
      "grad_norm": 0.03909628838300705,
      "learning_rate": 3.609616088492157e-05,
      "loss": 0.2638,
      "step": 2970
    },
    {
      "epoch": 0.12695229154220364,
      "grad_norm": 0.055932916700839996,
      "learning_rate": 3.594382283209286e-05,
      "loss": 0.2716,
      "step": 2975
    },
    {
      "epoch": 0.1271656567380729,
      "grad_norm": 0.06635574996471405,
      "learning_rate": 3.579162632481219e-05,
      "loss": 0.2653,
      "step": 2980
    },
    {
      "epoch": 0.12737902193394213,
      "grad_norm": 0.047660503536462784,
      "learning_rate": 3.563957289569669e-05,
      "loss": 0.2886,
      "step": 2985
    },
    {
      "epoch": 0.12759238712981139,
      "grad_norm": 0.04716504365205765,
      "learning_rate": 3.548766407592269e-05,
      "loss": 0.2492,
      "step": 2990
    },
    {
      "epoch": 0.12780575232568064,
      "grad_norm": 0.0624786838889122,
      "learning_rate": 3.533590139521033e-05,
      "loss": 0.2869,
      "step": 2995
    },
    {
      "epoch": 0.12801911752154987,
      "grad_norm": 0.03306799754500389,
      "learning_rate": 3.5184286381808134e-05,
      "loss": 0.2452,
      "step": 3000
    },
    {
      "epoch": 0.12823248271741913,
      "grad_norm": 0.057195935398340225,
      "learning_rate": 3.503282056247758e-05,
      "loss": 0.2433,
      "step": 3005
    },
    {
      "epoch": 0.1284458479132884,
      "grad_norm": 0.048991717398166656,
      "learning_rate": 3.488150546247778e-05,
      "loss": 0.2873,
      "step": 3010
    },
    {
      "epoch": 0.12865921310915762,
      "grad_norm": 0.052679579704999924,
      "learning_rate": 3.473034260555014e-05,
      "loss": 0.2198,
      "step": 3015
    },
    {
      "epoch": 0.12887257830502688,
      "grad_norm": 0.049885161221027374,
      "learning_rate": 3.457933351390293e-05,
      "loss": 0.2432,
      "step": 3020
    },
    {
      "epoch": 0.12908594350089614,
      "grad_norm": 0.045226048678159714,
      "learning_rate": 3.4428479708196034e-05,
      "loss": 0.2796,
      "step": 3025
    },
    {
      "epoch": 0.1292993086967654,
      "grad_norm": 0.026101816445589066,
      "learning_rate": 3.427778270752561e-05,
      "loss": 0.2165,
      "step": 3030
    },
    {
      "epoch": 0.12951267389263463,
      "grad_norm": 0.05235889554023743,
      "learning_rate": 3.412724402940876e-05,
      "loss": 0.245,
      "step": 3035
    },
    {
      "epoch": 0.12972603908850389,
      "grad_norm": 0.04028499126434326,
      "learning_rate": 3.3976865189768314e-05,
      "loss": 0.2083,
      "step": 3040
    },
    {
      "epoch": 0.12993940428437314,
      "grad_norm": 0.04265929386019707,
      "learning_rate": 3.382664770291752e-05,
      "loss": 0.2614,
      "step": 3045
    },
    {
      "epoch": 0.13015276948024238,
      "grad_norm": 0.02367999777197838,
      "learning_rate": 3.367659308154481e-05,
      "loss": 0.2633,
      "step": 3050
    },
    {
      "epoch": 0.13036613467611163,
      "grad_norm": 0.03847155347466469,
      "learning_rate": 3.352670283669852e-05,
      "loss": 0.294,
      "step": 3055
    },
    {
      "epoch": 0.1305794998719809,
      "grad_norm": 0.025351345539093018,
      "learning_rate": 3.3376978477771796e-05,
      "loss": 0.1964,
      "step": 3060
    },
    {
      "epoch": 0.13079286506785012,
      "grad_norm": 0.04222143441438675,
      "learning_rate": 3.322742151248725e-05,
      "loss": 0.2012,
      "step": 3065
    },
    {
      "epoch": 0.13100623026371938,
      "grad_norm": 0.06947577744722366,
      "learning_rate": 3.307803344688185e-05,
      "loss": 0.2866,
      "step": 3070
    },
    {
      "epoch": 0.13121959545958864,
      "grad_norm": 0.055015839636325836,
      "learning_rate": 3.292881578529179e-05,
      "loss": 0.2389,
      "step": 3075
    },
    {
      "epoch": 0.13143296065545787,
      "grad_norm": 0.02586827240884304,
      "learning_rate": 3.2779770030337236e-05,
      "loss": 0.2425,
      "step": 3080
    },
    {
      "epoch": 0.13164632585132713,
      "grad_norm": 0.04067765176296234,
      "learning_rate": 3.2630897682907315e-05,
      "loss": 0.2478,
      "step": 3085
    },
    {
      "epoch": 0.1318596910471964,
      "grad_norm": 0.04412482678890228,
      "learning_rate": 3.248220024214488e-05,
      "loss": 0.3004,
      "step": 3090
    },
    {
      "epoch": 0.13207305624306562,
      "grad_norm": 0.0313575305044651,
      "learning_rate": 3.233367920543151e-05,
      "loss": 0.2777,
      "step": 3095
    },
    {
      "epoch": 0.13228642143893488,
      "grad_norm": 0.12363865971565247,
      "learning_rate": 3.2185336068372415e-05,
      "loss": 0.2819,
      "step": 3100
    },
    {
      "epoch": 0.13249978663480413,
      "grad_norm": 0.05080925300717354,
      "learning_rate": 3.203717232478133e-05,
      "loss": 0.2875,
      "step": 3105
    },
    {
      "epoch": 0.1327131518306734,
      "grad_norm": 0.06499867141246796,
      "learning_rate": 3.1889189466665514e-05,
      "loss": 0.2608,
      "step": 3110
    },
    {
      "epoch": 0.13292651702654262,
      "grad_norm": 0.03283000364899635,
      "learning_rate": 3.174138898421071e-05,
      "loss": 0.2418,
      "step": 3115
    },
    {
      "epoch": 0.13313988222241188,
      "grad_norm": 0.033234164118766785,
      "learning_rate": 3.1593772365766105e-05,
      "loss": 0.2675,
      "step": 3120
    },
    {
      "epoch": 0.13335324741828114,
      "grad_norm": 0.07482265681028366,
      "learning_rate": 3.144634109782945e-05,
      "loss": 0.3223,
      "step": 3125
    },
    {
      "epoch": 0.13356661261415037,
      "grad_norm": 0.03759711608290672,
      "learning_rate": 3.129909666503194e-05,
      "loss": 0.2491,
      "step": 3130
    },
    {
      "epoch": 0.13377997781001963,
      "grad_norm": 0.05213988572359085,
      "learning_rate": 3.1152040550123395e-05,
      "loss": 0.2965,
      "step": 3135
    },
    {
      "epoch": 0.1339933430058889,
      "grad_norm": 0.0370454341173172,
      "learning_rate": 3.100517423395727e-05,
      "loss": 0.2552,
      "step": 3140
    },
    {
      "epoch": 0.13420670820175812,
      "grad_norm": 0.07406094670295715,
      "learning_rate": 3.085849919547572e-05,
      "loss": 0.2764,
      "step": 3145
    },
    {
      "epoch": 0.13442007339762738,
      "grad_norm": 0.07789228111505508,
      "learning_rate": 3.0712016911694755e-05,
      "loss": 0.2782,
      "step": 3150
    },
    {
      "epoch": 0.13463343859349663,
      "grad_norm": 0.0676085501909256,
      "learning_rate": 3.056572885768937e-05,
      "loss": 0.2572,
      "step": 3155
    },
    {
      "epoch": 0.13484680378936587,
      "grad_norm": 0.027178052812814713,
      "learning_rate": 3.041963650657862e-05,
      "loss": 0.293,
      "step": 3160
    },
    {
      "epoch": 0.13506016898523512,
      "grad_norm": 0.044636454433202744,
      "learning_rate": 3.0273741329510853e-05,
      "loss": 0.302,
      "step": 3165
    },
    {
      "epoch": 0.13527353418110438,
      "grad_norm": 0.07038506120443344,
      "learning_rate": 3.0128044795648924e-05,
      "loss": 0.279,
      "step": 3170
    },
    {
      "epoch": 0.13548689937697364,
      "grad_norm": 0.04973322153091431,
      "learning_rate": 2.9982548372155263e-05,
      "loss": 0.2672,
      "step": 3175
    },
    {
      "epoch": 0.13570026457284287,
      "grad_norm": 0.03514574468135834,
      "learning_rate": 2.983725352417726e-05,
      "loss": 0.3061,
      "step": 3180
    },
    {
      "epoch": 0.13591362976871213,
      "grad_norm": 0.04318060725927353,
      "learning_rate": 2.9692161714832422e-05,
      "loss": 0.2904,
      "step": 3185
    },
    {
      "epoch": 0.1361269949645814,
      "grad_norm": 0.05169866606593132,
      "learning_rate": 2.9547274405193646e-05,
      "loss": 0.2631,
      "step": 3190
    },
    {
      "epoch": 0.13634036016045062,
      "grad_norm": 0.021512743085622787,
      "learning_rate": 2.9402593054274557e-05,
      "loss": 0.2473,
      "step": 3195
    },
    {
      "epoch": 0.13655372535631988,
      "grad_norm": 0.1515195518732071,
      "learning_rate": 2.9258119119014738e-05,
      "loss": 0.2587,
      "step": 3200
    },
    {
      "epoch": 0.13676709055218914,
      "grad_norm": 0.028010565787553787,
      "learning_rate": 2.911385405426511e-05,
      "loss": 0.2827,
      "step": 3205
    },
    {
      "epoch": 0.13698045574805837,
      "grad_norm": 0.049011435359716415,
      "learning_rate": 2.896979931277326e-05,
      "loss": 0.2245,
      "step": 3210
    },
    {
      "epoch": 0.13719382094392762,
      "grad_norm": 0.029440725222229958,
      "learning_rate": 2.8825956345168858e-05,
      "loss": 0.2631,
      "step": 3215
    },
    {
      "epoch": 0.13740718613979688,
      "grad_norm": 0.03892381489276886,
      "learning_rate": 2.8682326599949e-05,
      "loss": 0.2588,
      "step": 3220
    },
    {
      "epoch": 0.1376205513356661,
      "grad_norm": 0.03298211842775345,
      "learning_rate": 2.8538911523463596e-05,
      "loss": 0.2543,
      "step": 3225
    },
    {
      "epoch": 0.13783391653153537,
      "grad_norm": 0.03595763072371483,
      "learning_rate": 2.8395712559900877e-05,
      "loss": 0.2722,
      "step": 3230
    },
    {
      "epoch": 0.13804728172740463,
      "grad_norm": 0.02966315858066082,
      "learning_rate": 2.825273115127286e-05,
      "loss": 0.2568,
      "step": 3235
    },
    {
      "epoch": 0.1382606469232739,
      "grad_norm": 0.02747240848839283,
      "learning_rate": 2.8109968737400683e-05,
      "loss": 0.29,
      "step": 3240
    },
    {
      "epoch": 0.13847401211914312,
      "grad_norm": 0.033072371035814285,
      "learning_rate": 2.7967426755900293e-05,
      "loss": 0.2643,
      "step": 3245
    },
    {
      "epoch": 0.13868737731501238,
      "grad_norm": 0.06332861632108688,
      "learning_rate": 2.782510664216789e-05,
      "loss": 0.2442,
      "step": 3250
    },
    {
      "epoch": 0.13890074251088164,
      "grad_norm": 0.041870370507240295,
      "learning_rate": 2.7683009829365412e-05,
      "loss": 0.2759,
      "step": 3255
    },
    {
      "epoch": 0.13911410770675087,
      "grad_norm": 0.03412661328911781,
      "learning_rate": 2.7541137748406166e-05,
      "loss": 0.2813,
      "step": 3260
    },
    {
      "epoch": 0.13932747290262013,
      "grad_norm": 0.09390944242477417,
      "learning_rate": 2.7399491827940448e-05,
      "loss": 0.2588,
      "step": 3265
    },
    {
      "epoch": 0.13954083809848938,
      "grad_norm": 0.06064310669898987,
      "learning_rate": 2.7258073494341142e-05,
      "loss": 0.2636,
      "step": 3270
    },
    {
      "epoch": 0.13975420329435861,
      "grad_norm": 0.05415494367480278,
      "learning_rate": 2.711688417168924e-05,
      "loss": 0.2385,
      "step": 3275
    },
    {
      "epoch": 0.13996756849022787,
      "grad_norm": 0.042999934405088425,
      "learning_rate": 2.6975925281759674e-05,
      "loss": 0.2882,
      "step": 3280
    },
    {
      "epoch": 0.14018093368609713,
      "grad_norm": 0.0499967522919178,
      "learning_rate": 2.6835198244006927e-05,
      "loss": 0.2729,
      "step": 3285
    },
    {
      "epoch": 0.14039429888196636,
      "grad_norm": 0.05560830235481262,
      "learning_rate": 2.6694704475550668e-05,
      "loss": 0.248,
      "step": 3290
    },
    {
      "epoch": 0.14060766407783562,
      "grad_norm": 0.0683385506272316,
      "learning_rate": 2.65544453911616e-05,
      "loss": 0.2478,
      "step": 3295
    },
    {
      "epoch": 0.14082102927370488,
      "grad_norm": 0.045149531215429306,
      "learning_rate": 2.6414422403247174e-05,
      "loss": 0.2793,
      "step": 3300
    },
    {
      "epoch": 0.14103439446957414,
      "grad_norm": 0.05179640278220177,
      "learning_rate": 2.627463692183727e-05,
      "loss": 0.296,
      "step": 3305
    },
    {
      "epoch": 0.14124775966544337,
      "grad_norm": 0.06649018824100494,
      "learning_rate": 2.613509035457017e-05,
      "loss": 0.2379,
      "step": 3310
    },
    {
      "epoch": 0.14146112486131263,
      "grad_norm": 0.052240729331970215,
      "learning_rate": 2.5995784106678266e-05,
      "loss": 0.2535,
      "step": 3315
    },
    {
      "epoch": 0.14167449005718188,
      "grad_norm": 0.036249373108148575,
      "learning_rate": 2.5856719580973893e-05,
      "loss": 0.2191,
      "step": 3320
    },
    {
      "epoch": 0.14188785525305112,
      "grad_norm": 0.09789241850376129,
      "learning_rate": 2.5717898177835297e-05,
      "loss": 0.2965,
      "step": 3325
    },
    {
      "epoch": 0.14210122044892037,
      "grad_norm": 0.05446732044219971,
      "learning_rate": 2.557932129519249e-05,
      "loss": 0.3093,
      "step": 3330
    },
    {
      "epoch": 0.14231458564478963,
      "grad_norm": 0.03563051298260689,
      "learning_rate": 2.5440990328513097e-05,
      "loss": 0.235,
      "step": 3335
    },
    {
      "epoch": 0.14252795084065886,
      "grad_norm": 0.033343758434057236,
      "learning_rate": 2.5302906670788462e-05,
      "loss": 0.2338,
      "step": 3340
    },
    {
      "epoch": 0.14274131603652812,
      "grad_norm": 0.04656411334872246,
      "learning_rate": 2.5165071712519444e-05,
      "loss": 0.2647,
      "step": 3345
    },
    {
      "epoch": 0.14295468123239738,
      "grad_norm": 0.028808260336518288,
      "learning_rate": 2.502748684170258e-05,
      "loss": 0.2335,
      "step": 3350
    },
    {
      "epoch": 0.1431680464282666,
      "grad_norm": 0.06010651960968971,
      "learning_rate": 2.4890153443815956e-05,
      "loss": 0.242,
      "step": 3355
    },
    {
      "epoch": 0.14338141162413587,
      "grad_norm": 0.05745178833603859,
      "learning_rate": 2.475307290180538e-05,
      "loss": 0.2571,
      "step": 3360
    },
    {
      "epoch": 0.14359477682000513,
      "grad_norm": 0.05686336010694504,
      "learning_rate": 2.4616246596070403e-05,
      "loss": 0.2019,
      "step": 3365
    },
    {
      "epoch": 0.14380814201587436,
      "grad_norm": 0.040834225714206696,
      "learning_rate": 2.4479675904450377e-05,
      "loss": 0.2292,
      "step": 3370
    },
    {
      "epoch": 0.14402150721174362,
      "grad_norm": 0.0379675067961216,
      "learning_rate": 2.434336220221067e-05,
      "loss": 0.2739,
      "step": 3375
    },
    {
      "epoch": 0.14423487240761287,
      "grad_norm": 0.04807018116116524,
      "learning_rate": 2.4207306862028755e-05,
      "loss": 0.2592,
      "step": 3380
    },
    {
      "epoch": 0.14444823760348213,
      "grad_norm": 0.028774850070476532,
      "learning_rate": 2.4071511253980368e-05,
      "loss": 0.2678,
      "step": 3385
    },
    {
      "epoch": 0.14466160279935136,
      "grad_norm": 0.02962368167936802,
      "learning_rate": 2.3935976745525796e-05,
      "loss": 0.2055,
      "step": 3390
    },
    {
      "epoch": 0.14487496799522062,
      "grad_norm": 0.05338121950626373,
      "learning_rate": 2.3800704701496053e-05,
      "loss": 0.2622,
      "step": 3395
    },
    {
      "epoch": 0.14508833319108988,
      "grad_norm": 0.06764159351587296,
      "learning_rate": 2.3665696484079074e-05,
      "loss": 0.3009,
      "step": 3400
    },
    {
      "epoch": 0.1453016983869591,
      "grad_norm": 0.05051841586828232,
      "learning_rate": 2.353095345280614e-05,
      "loss": 0.2967,
      "step": 3405
    },
    {
      "epoch": 0.14551506358282837,
      "grad_norm": 0.06170937046408653,
      "learning_rate": 2.3396476964538094e-05,
      "loss": 0.2573,
      "step": 3410
    },
    {
      "epoch": 0.14572842877869763,
      "grad_norm": 0.08413007855415344,
      "learning_rate": 2.326226837345164e-05,
      "loss": 0.3393,
      "step": 3415
    },
    {
      "epoch": 0.14594179397456686,
      "grad_norm": 0.049033720046281815,
      "learning_rate": 2.312832903102582e-05,
      "loss": 0.254,
      "step": 3420
    },
    {
      "epoch": 0.14615515917043612,
      "grad_norm": 0.030561771243810654,
      "learning_rate": 2.2994660286028348e-05,
      "loss": 0.2464,
      "step": 3425
    },
    {
      "epoch": 0.14636852436630537,
      "grad_norm": 0.02829853631556034,
      "learning_rate": 2.2861263484501978e-05,
      "loss": 0.2805,
      "step": 3430
    },
    {
      "epoch": 0.1465818895621746,
      "grad_norm": 0.05904526263475418,
      "learning_rate": 2.2728139969751006e-05,
      "loss": 0.3079,
      "step": 3435
    },
    {
      "epoch": 0.14679525475804386,
      "grad_norm": 0.06681350618600845,
      "learning_rate": 2.2595291082327763e-05,
      "loss": 0.303,
      "step": 3440
    },
    {
      "epoch": 0.14700861995391312,
      "grad_norm": 0.05117553099989891,
      "learning_rate": 2.2462718160019086e-05,
      "loss": 0.2628,
      "step": 3445
    },
    {
      "epoch": 0.14722198514978238,
      "grad_norm": 0.050942253321409225,
      "learning_rate": 2.23304225378328e-05,
      "loss": 0.3037,
      "step": 3450
    },
    {
      "epoch": 0.1474353503456516,
      "grad_norm": 0.05341295525431633,
      "learning_rate": 2.2198405547984375e-05,
      "loss": 0.277,
      "step": 3455
    },
    {
      "epoch": 0.14764871554152087,
      "grad_norm": 0.06037607043981552,
      "learning_rate": 2.2066668519883438e-05,
      "loss": 0.3138,
      "step": 3460
    },
    {
      "epoch": 0.14786208073739013,
      "grad_norm": 0.029837803915143013,
      "learning_rate": 2.193521278012037e-05,
      "loss": 0.252,
      "step": 3465
    },
    {
      "epoch": 0.14807544593325936,
      "grad_norm": 0.0939725711941719,
      "learning_rate": 2.180403965245303e-05,
      "loss": 0.2961,
      "step": 3470
    },
    {
      "epoch": 0.14828881112912862,
      "grad_norm": 0.03857811540365219,
      "learning_rate": 2.1673150457793374e-05,
      "loss": 0.2966,
      "step": 3475
    },
    {
      "epoch": 0.14850217632499788,
      "grad_norm": 0.03278948366641998,
      "learning_rate": 2.15425465141941e-05,
      "loss": 0.2353,
      "step": 3480
    },
    {
      "epoch": 0.1487155415208671,
      "grad_norm": 0.034397102892398834,
      "learning_rate": 2.14122291368355e-05,
      "loss": 0.238,
      "step": 3485
    },
    {
      "epoch": 0.14892890671673636,
      "grad_norm": 0.04874144494533539,
      "learning_rate": 2.128219963801212e-05,
      "loss": 0.2602,
      "step": 3490
    },
    {
      "epoch": 0.14914227191260562,
      "grad_norm": 0.08462044596672058,
      "learning_rate": 2.115245932711954e-05,
      "loss": 0.286,
      "step": 3495
    },
    {
      "epoch": 0.14935563710847485,
      "grad_norm": 0.034470949321985245,
      "learning_rate": 2.1023009510641266e-05,
      "loss": 0.2643,
      "step": 3500
    },
    {
      "epoch": 0.1495690023043441,
      "grad_norm": 0.02920464612543583,
      "learning_rate": 2.0893851492135537e-05,
      "loss": 0.2355,
      "step": 3505
    },
    {
      "epoch": 0.14978236750021337,
      "grad_norm": 0.03835563361644745,
      "learning_rate": 2.076498657222214e-05,
      "loss": 0.3198,
      "step": 3510
    },
    {
      "epoch": 0.14999573269608263,
      "grad_norm": 0.03874047473073006,
      "learning_rate": 2.0636416048569372e-05,
      "loss": 0.2699,
      "step": 3515
    },
    {
      "epoch": 0.15020909789195186,
      "grad_norm": 0.04331187531352043,
      "learning_rate": 2.0508141215881004e-05,
      "loss": 0.2135,
      "step": 3520
    },
    {
      "epoch": 0.15042246308782112,
      "grad_norm": 0.029747920110821724,
      "learning_rate": 2.0380163365883187e-05,
      "loss": 0.2189,
      "step": 3525
    },
    {
      "epoch": 0.15063582828369038,
      "grad_norm": 0.046003468334674835,
      "learning_rate": 2.0252483787311412e-05,
      "loss": 0.2647,
      "step": 3530
    },
    {
      "epoch": 0.1508491934795596,
      "grad_norm": 0.09097316861152649,
      "learning_rate": 2.012510376589764e-05,
      "loss": 0.2428,
      "step": 3535
    },
    {
      "epoch": 0.15106255867542887,
      "grad_norm": 0.0513770654797554,
      "learning_rate": 1.9998024584357293e-05,
      "loss": 0.2524,
      "step": 3540
    },
    {
      "epoch": 0.15127592387129812,
      "grad_norm": 0.06401456147432327,
      "learning_rate": 1.987124752237628e-05,
      "loss": 0.2751,
      "step": 3545
    },
    {
      "epoch": 0.15148928906716735,
      "grad_norm": 0.03902352601289749,
      "learning_rate": 1.9744773856598227e-05,
      "loss": 0.2258,
      "step": 3550
    },
    {
      "epoch": 0.1517026542630366,
      "grad_norm": 0.05232783779501915,
      "learning_rate": 1.9618604860611556e-05,
      "loss": 0.2988,
      "step": 3555
    },
    {
      "epoch": 0.15191601945890587,
      "grad_norm": 0.05214405432343483,
      "learning_rate": 1.9492741804936622e-05,
      "loss": 0.288,
      "step": 3560
    },
    {
      "epoch": 0.1521293846547751,
      "grad_norm": 0.02670934610068798,
      "learning_rate": 1.9367185957013022e-05,
      "loss": 0.2771,
      "step": 3565
    },
    {
      "epoch": 0.15234274985064436,
      "grad_norm": 0.03555550426244736,
      "learning_rate": 1.9241938581186764e-05,
      "loss": 0.2624,
      "step": 3570
    },
    {
      "epoch": 0.15255611504651362,
      "grad_norm": 0.045630622655153275,
      "learning_rate": 1.9117000938697494e-05,
      "loss": 0.2764,
      "step": 3575
    },
    {
      "epoch": 0.15276948024238285,
      "grad_norm": 0.046486835926771164,
      "learning_rate": 1.899237428766591e-05,
      "loss": 0.2938,
      "step": 3580
    },
    {
      "epoch": 0.1529828454382521,
      "grad_norm": 0.03299181908369064,
      "learning_rate": 1.8868059883081014e-05,
      "loss": 0.3069,
      "step": 3585
    },
    {
      "epoch": 0.15319621063412137,
      "grad_norm": 0.07283072173595428,
      "learning_rate": 1.8744058976787455e-05,
      "loss": 0.282,
      "step": 3590
    },
    {
      "epoch": 0.15340957582999062,
      "grad_norm": 0.023736000061035156,
      "learning_rate": 1.8620372817473004e-05,
      "loss": 0.2616,
      "step": 3595
    },
    {
      "epoch": 0.15362294102585985,
      "grad_norm": 0.05454801768064499,
      "learning_rate": 1.8497002650655888e-05,
      "loss": 0.3055,
      "step": 3600
    },
    {
      "epoch": 0.1538363062217291,
      "grad_norm": 0.04869690164923668,
      "learning_rate": 1.8373949718672346e-05,
      "loss": 0.2739,
      "step": 3605
    },
    {
      "epoch": 0.15404967141759837,
      "grad_norm": 0.04065186157822609,
      "learning_rate": 1.8251215260664005e-05,
      "loss": 0.2722,
      "step": 3610
    },
    {
      "epoch": 0.1542630366134676,
      "grad_norm": 0.04591168090701103,
      "learning_rate": 1.8128800512565513e-05,
      "loss": 0.2419,
      "step": 3615
    },
    {
      "epoch": 0.15447640180933686,
      "grad_norm": 0.024122687056660652,
      "learning_rate": 1.800670670709204e-05,
      "loss": 0.2416,
      "step": 3620
    },
    {
      "epoch": 0.15468976700520612,
      "grad_norm": 0.029880404472351074,
      "learning_rate": 1.7884935073726823e-05,
      "loss": 0.2682,
      "step": 3625
    },
    {
      "epoch": 0.15490313220107535,
      "grad_norm": 0.04852145537734032,
      "learning_rate": 1.776348683870886e-05,
      "loss": 0.3288,
      "step": 3630
    },
    {
      "epoch": 0.1551164973969446,
      "grad_norm": 0.043220989406108856,
      "learning_rate": 1.7642363225020558e-05,
      "loss": 0.2962,
      "step": 3635
    },
    {
      "epoch": 0.15532986259281387,
      "grad_norm": 0.04529421776533127,
      "learning_rate": 1.7521565452375333e-05,
      "loss": 0.2895,
      "step": 3640
    },
    {
      "epoch": 0.1555432277886831,
      "grad_norm": 0.03261356055736542,
      "learning_rate": 1.7401094737205414e-05,
      "loss": 0.278,
      "step": 3645
    },
    {
      "epoch": 0.15575659298455236,
      "grad_norm": 0.06764718145132065,
      "learning_rate": 1.72809522926496e-05,
      "loss": 0.3019,
      "step": 3650
    },
    {
      "epoch": 0.15596995818042161,
      "grad_norm": 0.05066860094666481,
      "learning_rate": 1.7161139328540933e-05,
      "loss": 0.2713,
      "step": 3655
    },
    {
      "epoch": 0.15618332337629087,
      "grad_norm": 0.03307951241731644,
      "learning_rate": 1.7041657051394644e-05,
      "loss": 0.2489,
      "step": 3660
    },
    {
      "epoch": 0.1563966885721601,
      "grad_norm": 0.037781812250614166,
      "learning_rate": 1.692250666439596e-05,
      "loss": 0.2697,
      "step": 3665
    },
    {
      "epoch": 0.15661005376802936,
      "grad_norm": 0.046853724867105484,
      "learning_rate": 1.680368936738792e-05,
      "loss": 0.3015,
      "step": 3670
    },
    {
      "epoch": 0.15682341896389862,
      "grad_norm": 0.07891824096441269,
      "learning_rate": 1.66852063568594e-05,
      "loss": 0.2406,
      "step": 3675
    },
    {
      "epoch": 0.15703678415976785,
      "grad_norm": 0.041396141052246094,
      "learning_rate": 1.6567058825933026e-05,
      "loss": 0.2713,
      "step": 3680
    },
    {
      "epoch": 0.1572501493556371,
      "grad_norm": 0.029394563287496567,
      "learning_rate": 1.6449247964353092e-05,
      "loss": 0.2241,
      "step": 3685
    },
    {
      "epoch": 0.15746351455150637,
      "grad_norm": 0.050384823232889175,
      "learning_rate": 1.633177495847366e-05,
      "loss": 0.2352,
      "step": 3690
    },
    {
      "epoch": 0.1576768797473756,
      "grad_norm": 0.043050263077020645,
      "learning_rate": 1.621464099124661e-05,
      "loss": 0.2375,
      "step": 3695
    },
    {
      "epoch": 0.15789024494324486,
      "grad_norm": 0.039797719568014145,
      "learning_rate": 1.60978472422097e-05,
      "loss": 0.248,
      "step": 3700
    },
    {
      "epoch": 0.15810361013911411,
      "grad_norm": 0.055135563015937805,
      "learning_rate": 1.598139488747467e-05,
      "loss": 0.3028,
      "step": 3705
    },
    {
      "epoch": 0.15831697533498335,
      "grad_norm": 0.07093951106071472,
      "learning_rate": 1.5865285099715444e-05,
      "loss": 0.2676,
      "step": 3710
    },
    {
      "epoch": 0.1585303405308526,
      "grad_norm": 0.03311896696686745,
      "learning_rate": 1.5749519048156307e-05,
      "loss": 0.2231,
      "step": 3715
    },
    {
      "epoch": 0.15874370572672186,
      "grad_norm": 0.05148845165967941,
      "learning_rate": 1.5634097898560098e-05,
      "loss": 0.2972,
      "step": 3720
    },
    {
      "epoch": 0.15895707092259112,
      "grad_norm": 0.06406794488430023,
      "learning_rate": 1.551902281321651e-05,
      "loss": 0.3017,
      "step": 3725
    },
    {
      "epoch": 0.15917043611846035,
      "grad_norm": 0.060651905834674835,
      "learning_rate": 1.54042949509304e-05,
      "loss": 0.2557,
      "step": 3730
    },
    {
      "epoch": 0.1593838013143296,
      "grad_norm": 0.03541293367743492,
      "learning_rate": 1.5289915467010028e-05,
      "loss": 0.2649,
      "step": 3735
    },
    {
      "epoch": 0.15959716651019887,
      "grad_norm": 0.04953879490494728,
      "learning_rate": 1.5175885513255561e-05,
      "loss": 0.267,
      "step": 3740
    },
    {
      "epoch": 0.1598105317060681,
      "grad_norm": 0.06979471445083618,
      "learning_rate": 1.5062206237947363e-05,
      "loss": 0.2711,
      "step": 3745
    },
    {
      "epoch": 0.16002389690193736,
      "grad_norm": 0.059081923216581345,
      "learning_rate": 1.4948878785834453e-05,
      "loss": 0.2836,
      "step": 3750
    },
    {
      "epoch": 0.16023726209780662,
      "grad_norm": 0.04884744808077812,
      "learning_rate": 1.4835904298123026e-05,
      "loss": 0.2878,
      "step": 3755
    },
    {
      "epoch": 0.16045062729367585,
      "grad_norm": 0.026843862608075142,
      "learning_rate": 1.4723283912464942e-05,
      "loss": 0.2754,
      "step": 3760
    },
    {
      "epoch": 0.1606639924895451,
      "grad_norm": 0.03532971814274788,
      "learning_rate": 1.4611018762946215e-05,
      "loss": 0.2328,
      "step": 3765
    },
    {
      "epoch": 0.16087735768541436,
      "grad_norm": 0.04297260940074921,
      "learning_rate": 1.4499109980075638e-05,
      "loss": 0.2857,
      "step": 3770
    },
    {
      "epoch": 0.1610907228812836,
      "grad_norm": 0.08891765773296356,
      "learning_rate": 1.4387558690773428e-05,
      "loss": 0.2763,
      "step": 3775
    },
    {
      "epoch": 0.16130408807715285,
      "grad_norm": 0.028797414153814316,
      "learning_rate": 1.4276366018359844e-05,
      "loss": 0.2753,
      "step": 3780
    },
    {
      "epoch": 0.1615174532730221,
      "grad_norm": 0.05980689451098442,
      "learning_rate": 1.416553308254383e-05,
      "loss": 0.3081,
      "step": 3785
    },
    {
      "epoch": 0.16173081846889134,
      "grad_norm": 0.061136480420827866,
      "learning_rate": 1.405506099941184e-05,
      "loss": 0.2777,
      "step": 3790
    },
    {
      "epoch": 0.1619441836647606,
      "grad_norm": 0.03178182616829872,
      "learning_rate": 1.3944950881416541e-05,
      "loss": 0.2473,
      "step": 3795
    },
    {
      "epoch": 0.16215754886062986,
      "grad_norm": 0.03303143382072449,
      "learning_rate": 1.3835203837365563e-05,
      "loss": 0.2205,
      "step": 3800
    },
    {
      "epoch": 0.16237091405649912,
      "grad_norm": 0.05323231965303421,
      "learning_rate": 1.3725820972410435e-05,
      "loss": 0.2898,
      "step": 3805
    },
    {
      "epoch": 0.16258427925236835,
      "grad_norm": 0.048013921827077866,
      "learning_rate": 1.3616803388035415e-05,
      "loss": 0.269,
      "step": 3810
    },
    {
      "epoch": 0.1627976444482376,
      "grad_norm": 0.07717172056436539,
      "learning_rate": 1.3508152182046334e-05,
      "loss": 0.303,
      "step": 3815
    },
    {
      "epoch": 0.16301100964410686,
      "grad_norm": 0.0423373281955719,
      "learning_rate": 1.3399868448559639e-05,
      "loss": 0.2712,
      "step": 3820
    },
    {
      "epoch": 0.1632243748399761,
      "grad_norm": 0.05492858961224556,
      "learning_rate": 1.3291953277991349e-05,
      "loss": 0.2296,
      "step": 3825
    },
    {
      "epoch": 0.16343774003584535,
      "grad_norm": 0.02808844856917858,
      "learning_rate": 1.3184407757045996e-05,
      "loss": 0.2771,
      "step": 3830
    },
    {
      "epoch": 0.1636511052317146,
      "grad_norm": 0.05110626667737961,
      "learning_rate": 1.3077232968705805e-05,
      "loss": 0.2564,
      "step": 3835
    },
    {
      "epoch": 0.16386447042758384,
      "grad_norm": 0.07465339452028275,
      "learning_rate": 1.2970429992219712e-05,
      "loss": 0.2312,
      "step": 3840
    },
    {
      "epoch": 0.1640778356234531,
      "grad_norm": 0.0487658828496933,
      "learning_rate": 1.2863999903092472e-05,
      "loss": 0.2618,
      "step": 3845
    },
    {
      "epoch": 0.16429120081932236,
      "grad_norm": 0.04845481738448143,
      "learning_rate": 1.2757943773073943e-05,
      "loss": 0.2725,
      "step": 3850
    },
    {
      "epoch": 0.1645045660151916,
      "grad_norm": 0.07366489619016647,
      "learning_rate": 1.2652262670148134e-05,
      "loss": 0.2596,
      "step": 3855
    },
    {
      "epoch": 0.16471793121106085,
      "grad_norm": 0.09205091744661331,
      "learning_rate": 1.2546957658522618e-05,
      "loss": 0.3198,
      "step": 3860
    },
    {
      "epoch": 0.1649312964069301,
      "grad_norm": 0.046175114810466766,
      "learning_rate": 1.244202979861766e-05,
      "loss": 0.2479,
      "step": 3865
    },
    {
      "epoch": 0.16514466160279936,
      "grad_norm": 0.03580921143293381,
      "learning_rate": 1.2337480147055657e-05,
      "loss": 0.2827,
      "step": 3870
    },
    {
      "epoch": 0.1653580267986686,
      "grad_norm": 0.037516091018915176,
      "learning_rate": 1.2233309756650457e-05,
      "loss": 0.2365,
      "step": 3875
    },
    {
      "epoch": 0.16557139199453785,
      "grad_norm": 0.05925428867340088,
      "learning_rate": 1.21295196763967e-05,
      "loss": 0.25,
      "step": 3880
    },
    {
      "epoch": 0.1657847571904071,
      "grad_norm": 0.030986029654741287,
      "learning_rate": 1.2026110951459362e-05,
      "loss": 0.2874,
      "step": 3885
    },
    {
      "epoch": 0.16599812238627634,
      "grad_norm": 0.029863039031624794,
      "learning_rate": 1.1923084623163172e-05,
      "loss": 0.2782,
      "step": 3890
    },
    {
      "epoch": 0.1662114875821456,
      "grad_norm": 0.0324256606400013,
      "learning_rate": 1.1820441728982074e-05,
      "loss": 0.2241,
      "step": 3895
    },
    {
      "epoch": 0.16642485277801486,
      "grad_norm": 0.051585614681243896,
      "learning_rate": 1.1718183302528896e-05,
      "loss": 0.2761,
      "step": 3900
    },
    {
      "epoch": 0.1666382179738841,
      "grad_norm": 0.0472947433590889,
      "learning_rate": 1.1616310373544864e-05,
      "loss": 0.2314,
      "step": 3905
    },
    {
      "epoch": 0.16685158316975335,
      "grad_norm": 0.06849602609872818,
      "learning_rate": 1.151482396788922e-05,
      "loss": 0.2484,
      "step": 3910
    },
    {
      "epoch": 0.1670649483656226,
      "grad_norm": 0.03979794681072235,
      "learning_rate": 1.1413725107528955e-05,
      "loss": 0.2176,
      "step": 3915
    },
    {
      "epoch": 0.16727831356149184,
      "grad_norm": 0.03490182384848595,
      "learning_rate": 1.1313014810528483e-05,
      "loss": 0.2175,
      "step": 3920
    },
    {
      "epoch": 0.1674916787573611,
      "grad_norm": 0.03408092260360718,
      "learning_rate": 1.1212694091039349e-05,
      "loss": 0.2307,
      "step": 3925
    },
    {
      "epoch": 0.16770504395323035,
      "grad_norm": 0.03784136846661568,
      "learning_rate": 1.1112763959290102e-05,
      "loss": 0.2551,
      "step": 3930
    },
    {
      "epoch": 0.1679184091490996,
      "grad_norm": 0.052538204938173294,
      "learning_rate": 1.1013225421576079e-05,
      "loss": 0.3082,
      "step": 3935
    },
    {
      "epoch": 0.16813177434496884,
      "grad_norm": 0.04591459408402443,
      "learning_rate": 1.0914079480249196e-05,
      "loss": 0.2306,
      "step": 3940
    },
    {
      "epoch": 0.1683451395408381,
      "grad_norm": 0.04322687163949013,
      "learning_rate": 1.0815327133708015e-05,
      "loss": 0.2645,
      "step": 3945
    },
    {
      "epoch": 0.16855850473670736,
      "grad_norm": 0.054449405521154404,
      "learning_rate": 1.0716969376387565e-05,
      "loss": 0.2564,
      "step": 3950
    },
    {
      "epoch": 0.1687718699325766,
      "grad_norm": 0.02442888915538788,
      "learning_rate": 1.0619007198749387e-05,
      "loss": 0.2628,
      "step": 3955
    },
    {
      "epoch": 0.16898523512844585,
      "grad_norm": 0.05107388645410538,
      "learning_rate": 1.0521441587271496e-05,
      "loss": 0.2522,
      "step": 3960
    },
    {
      "epoch": 0.1691986003243151,
      "grad_norm": 0.035718612372875214,
      "learning_rate": 1.0424273524438522e-05,
      "loss": 0.2545,
      "step": 3965
    },
    {
      "epoch": 0.16941196552018434,
      "grad_norm": 0.03340170159935951,
      "learning_rate": 1.0327503988731795e-05,
      "loss": 0.2778,
      "step": 3970
    },
    {
      "epoch": 0.1696253307160536,
      "grad_norm": 0.05660717561841011,
      "learning_rate": 1.0231133954619448e-05,
      "loss": 0.3236,
      "step": 3975
    },
    {
      "epoch": 0.16983869591192285,
      "grad_norm": 0.06612809747457504,
      "learning_rate": 1.013516439254666e-05,
      "loss": 0.3194,
      "step": 3980
    },
    {
      "epoch": 0.17005206110779209,
      "grad_norm": 0.03767440840601921,
      "learning_rate": 1.0039596268925866e-05,
      "loss": 0.2737,
      "step": 3985
    },
    {
      "epoch": 0.17026542630366134,
      "grad_norm": 0.0460498183965683,
      "learning_rate": 9.944430546126988e-06,
      "loss": 0.2828,
      "step": 3990
    },
    {
      "epoch": 0.1704787914995306,
      "grad_norm": 0.05466720461845398,
      "learning_rate": 9.849668182467808e-06,
      "loss": 0.3208,
      "step": 3995
    },
    {
      "epoch": 0.17069215669539983,
      "grad_norm": 0.04989245906472206,
      "learning_rate": 9.755310132204298e-06,
      "loss": 0.272,
      "step": 4000
    },
    {
      "epoch": 0.1709055218912691,
      "grad_norm": 0.0718965083360672,
      "learning_rate": 9.661357345520939e-06,
      "loss": 0.2798,
      "step": 4005
    },
    {
      "epoch": 0.17111888708713835,
      "grad_norm": 0.09650619328022003,
      "learning_rate": 9.567810768521268e-06,
      "loss": 0.2697,
      "step": 4010
    },
    {
      "epoch": 0.1713322522830076,
      "grad_norm": 0.04506387934088707,
      "learning_rate": 9.474671343218294e-06,
      "loss": 0.2867,
      "step": 4015
    },
    {
      "epoch": 0.17154561747887684,
      "grad_norm": 0.0567018948495388,
      "learning_rate": 9.381940007524975e-06,
      "loss": 0.2662,
      "step": 4020
    },
    {
      "epoch": 0.1717589826747461,
      "grad_norm": 0.05038357898592949,
      "learning_rate": 9.289617695244817e-06,
      "loss": 0.2226,
      "step": 4025
    },
    {
      "epoch": 0.17197234787061536,
      "grad_norm": 0.06428422033786774,
      "learning_rate": 9.197705336062518e-06,
      "loss": 0.276,
      "step": 4030
    },
    {
      "epoch": 0.17218571306648459,
      "grad_norm": 0.04753938317298889,
      "learning_rate": 9.106203855534479e-06,
      "loss": 0.2598,
      "step": 4035
    },
    {
      "epoch": 0.17239907826235384,
      "grad_norm": 0.03603370115160942,
      "learning_rate": 9.015114175079614e-06,
      "loss": 0.2558,
      "step": 4040
    },
    {
      "epoch": 0.1726124434582231,
      "grad_norm": 0.05583081766963005,
      "learning_rate": 8.924437211969983e-06,
      "loss": 0.2984,
      "step": 4045
    },
    {
      "epoch": 0.17282580865409233,
      "grad_norm": 0.07349082082509995,
      "learning_rate": 8.834173879321617e-06,
      "loss": 0.275,
      "step": 4050
    },
    {
      "epoch": 0.1730391738499616,
      "grad_norm": 0.045763324946165085,
      "learning_rate": 8.744325086085248e-06,
      "loss": 0.2824,
      "step": 4055
    },
    {
      "epoch": 0.17325253904583085,
      "grad_norm": 0.032165709882974625,
      "learning_rate": 8.654891737037235e-06,
      "loss": 0.2466,
      "step": 4060
    },
    {
      "epoch": 0.17346590424170008,
      "grad_norm": 0.0373283326625824,
      "learning_rate": 8.56587473277043e-06,
      "loss": 0.2746,
      "step": 4065
    },
    {
      "epoch": 0.17367926943756934,
      "grad_norm": 0.04542847350239754,
      "learning_rate": 8.477274969685046e-06,
      "loss": 0.259,
      "step": 4070
    },
    {
      "epoch": 0.1738926346334386,
      "grad_norm": 0.03387686237692833,
      "learning_rate": 8.389093339979726e-06,
      "loss": 0.2775,
      "step": 4075
    },
    {
      "epoch": 0.17410599982930786,
      "grad_norm": 0.04495028406381607,
      "learning_rate": 8.30133073164252e-06,
      "loss": 0.2481,
      "step": 4080
    },
    {
      "epoch": 0.1743193650251771,
      "grad_norm": 0.0575721301138401,
      "learning_rate": 8.213988028441894e-06,
      "loss": 0.2553,
      "step": 4085
    },
    {
      "epoch": 0.17453273022104634,
      "grad_norm": 0.039610959589481354,
      "learning_rate": 8.127066109917908e-06,
      "loss": 0.2531,
      "step": 4090
    },
    {
      "epoch": 0.1747460954169156,
      "grad_norm": 0.03821743652224541,
      "learning_rate": 8.040565851373334e-06,
      "loss": 0.2787,
      "step": 4095
    },
    {
      "epoch": 0.17495946061278483,
      "grad_norm": 0.031287215650081635,
      "learning_rate": 7.954488123864784e-06,
      "loss": 0.2923,
      "step": 4100
    },
    {
      "epoch": 0.1751728258086541,
      "grad_norm": 0.027765121310949326,
      "learning_rate": 7.868833794194046e-06,
      "loss": 0.2225,
      "step": 4105
    },
    {
      "epoch": 0.17538619100452335,
      "grad_norm": 0.042792439460754395,
      "learning_rate": 7.783603724899257e-06,
      "loss": 0.3016,
      "step": 4110
    },
    {
      "epoch": 0.17559955620039258,
      "grad_norm": 0.09766152501106262,
      "learning_rate": 7.698798774246257e-06,
      "loss": 0.3008,
      "step": 4115
    },
    {
      "epoch": 0.17581292139626184,
      "grad_norm": 0.04561256244778633,
      "learning_rate": 7.614419796219973e-06,
      "loss": 0.261,
      "step": 4120
    },
    {
      "epoch": 0.1760262865921311,
      "grad_norm": 0.05500500276684761,
      "learning_rate": 7.530467640515782e-06,
      "loss": 0.2533,
      "step": 4125
    },
    {
      "epoch": 0.17623965178800033,
      "grad_norm": 0.03867582231760025,
      "learning_rate": 7.446943152530933e-06,
      "loss": 0.2558,
      "step": 4130
    },
    {
      "epoch": 0.1764530169838696,
      "grad_norm": 0.08846193552017212,
      "learning_rate": 7.36384717335612e-06,
      "loss": 0.2689,
      "step": 4135
    },
    {
      "epoch": 0.17666638217973885,
      "grad_norm": 0.05647452175617218,
      "learning_rate": 7.2811805397669245e-06,
      "loss": 0.3316,
      "step": 4140
    },
    {
      "epoch": 0.1768797473756081,
      "grad_norm": 0.03561975061893463,
      "learning_rate": 7.19894408421542e-06,
      "loss": 0.2247,
      "step": 4145
    },
    {
      "epoch": 0.17709311257147733,
      "grad_norm": 0.03941909596323967,
      "learning_rate": 7.117138634821807e-06,
      "loss": 0.309,
      "step": 4150
    },
    {
      "epoch": 0.1773064777673466,
      "grad_norm": 0.04588200896978378,
      "learning_rate": 7.035765015366047e-06,
      "loss": 0.2892,
      "step": 4155
    },
    {
      "epoch": 0.17751984296321585,
      "grad_norm": 0.11102508008480072,
      "learning_rate": 6.954824045279606e-06,
      "loss": 0.2518,
      "step": 4160
    },
    {
      "epoch": 0.17773320815908508,
      "grad_norm": 0.049080025404691696,
      "learning_rate": 6.874316539637127e-06,
      "loss": 0.322,
      "step": 4165
    },
    {
      "epoch": 0.17794657335495434,
      "grad_norm": 0.030083278194069862,
      "learning_rate": 6.794243309148307e-06,
      "loss": 0.2633,
      "step": 4170
    },
    {
      "epoch": 0.1781599385508236,
      "grad_norm": 0.0422041192650795,
      "learning_rate": 6.7146051601497005e-06,
      "loss": 0.282,
      "step": 4175
    },
    {
      "epoch": 0.17837330374669283,
      "grad_norm": 0.05504720285534859,
      "learning_rate": 6.635402894596565e-06,
      "loss": 0.2778,
      "step": 4180
    },
    {
      "epoch": 0.1785866689425621,
      "grad_norm": 0.05727815628051758,
      "learning_rate": 6.556637310054842e-06,
      "loss": 0.2828,
      "step": 4185
    },
    {
      "epoch": 0.17880003413843135,
      "grad_norm": 0.054251860827207565,
      "learning_rate": 6.478309199693105e-06,
      "loss": 0.2397,
      "step": 4190
    },
    {
      "epoch": 0.17901339933430058,
      "grad_norm": 0.03679342195391655,
      "learning_rate": 6.40041935227455e-06,
      "loss": 0.252,
      "step": 4195
    },
    {
      "epoch": 0.17922676453016984,
      "grad_norm": 0.07020217925310135,
      "learning_rate": 6.3229685521490555e-06,
      "loss": 0.312,
      "step": 4200
    },
    {
      "epoch": 0.1794401297260391,
      "grad_norm": 0.04006445035338402,
      "learning_rate": 6.2459575792453486e-06,
      "loss": 0.2458,
      "step": 4205
    },
    {
      "epoch": 0.17965349492190835,
      "grad_norm": 0.04442313686013222,
      "learning_rate": 6.169387209063049e-06,
      "loss": 0.2841,
      "step": 4210
    },
    {
      "epoch": 0.17986686011777758,
      "grad_norm": 0.046564552932977676,
      "learning_rate": 6.093258212664937e-06,
      "loss": 0.2801,
      "step": 4215
    },
    {
      "epoch": 0.18008022531364684,
      "grad_norm": 0.04995394125580788,
      "learning_rate": 6.017571356669183e-06,
      "loss": 0.2497,
      "step": 4220
    },
    {
      "epoch": 0.1802935905095161,
      "grad_norm": 0.052206698805093765,
      "learning_rate": 5.94232740324156e-06,
      "loss": 0.3269,
      "step": 4225
    },
    {
      "epoch": 0.18050695570538533,
      "grad_norm": 0.06572721898555756,
      "learning_rate": 5.8675271100878556e-06,
      "loss": 0.2373,
      "step": 4230
    },
    {
      "epoch": 0.1807203209012546,
      "grad_norm": 0.048980046063661575,
      "learning_rate": 5.793171230446198e-06,
      "loss": 0.2399,
      "step": 4235
    },
    {
      "epoch": 0.18093368609712385,
      "grad_norm": 0.06297014653682709,
      "learning_rate": 5.71926051307945e-06,
      "loss": 0.2497,
      "step": 4240
    },
    {
      "epoch": 0.18114705129299308,
      "grad_norm": 0.03860311210155487,
      "learning_rate": 5.645795702267731e-06,
      "loss": 0.2419,
      "step": 4245
    },
    {
      "epoch": 0.18136041648886234,
      "grad_norm": 0.0591987669467926,
      "learning_rate": 5.572777537800872e-06,
      "loss": 0.2679,
      "step": 4250
    },
    {
      "epoch": 0.1815737816847316,
      "grad_norm": 0.05120760574936867,
      "learning_rate": 5.500206754970966e-06,
      "loss": 0.3403,
      "step": 4255
    },
    {
      "epoch": 0.18178714688060083,
      "grad_norm": 0.03889409825205803,
      "learning_rate": 5.428084084565e-06,
      "loss": 0.2716,
      "step": 4260
    },
    {
      "epoch": 0.18200051207647008,
      "grad_norm": 0.059393636882305145,
      "learning_rate": 5.356410252857458e-06,
      "loss": 0.2735,
      "step": 4265
    },
    {
      "epoch": 0.18221387727233934,
      "grad_norm": 0.04208177700638771,
      "learning_rate": 5.285185981603041e-06,
      "loss": 0.2584,
      "step": 4270
    },
    {
      "epoch": 0.18242724246820857,
      "grad_norm": 0.04951794818043709,
      "learning_rate": 5.214411988029355e-06,
      "loss": 0.2985,
      "step": 4275
    },
    {
      "epoch": 0.18264060766407783,
      "grad_norm": 0.06069893389940262,
      "learning_rate": 5.144088984829743e-06,
      "loss": 0.2758,
      "step": 4280
    },
    {
      "epoch": 0.1828539728599471,
      "grad_norm": 0.06895998120307922,
      "learning_rate": 5.074217680156063e-06,
      "loss": 0.2655,
      "step": 4285
    },
    {
      "epoch": 0.18306733805581635,
      "grad_norm": 0.05610162392258644,
      "learning_rate": 5.004798777611564e-06,
      "loss": 0.34,
      "step": 4290
    },
    {
      "epoch": 0.18328070325168558,
      "grad_norm": 0.0802537202835083,
      "learning_rate": 4.9358329762438316e-06,
      "loss": 0.2579,
      "step": 4295
    },
    {
      "epoch": 0.18349406844755484,
      "grad_norm": 0.054699163883924484,
      "learning_rate": 4.867320970537737e-06,
      "loss": 0.2659,
      "step": 4300
    },
    {
      "epoch": 0.1837074336434241,
      "grad_norm": 0.06850281357765198,
      "learning_rate": 4.799263450408387e-06,
      "loss": 0.2678,
      "step": 4305
    },
    {
      "epoch": 0.18392079883929333,
      "grad_norm": 0.06609869748353958,
      "learning_rate": 4.731661101194273e-06,
      "loss": 0.2532,
      "step": 4310
    },
    {
      "epoch": 0.18413416403516258,
      "grad_norm": 0.05899686738848686,
      "learning_rate": 4.664514603650305e-06,
      "loss": 0.2902,
      "step": 4315
    },
    {
      "epoch": 0.18434752923103184,
      "grad_norm": 0.04501541331410408,
      "learning_rate": 4.5978246339409555e-06,
      "loss": 0.2578,
      "step": 4320
    },
    {
      "epoch": 0.18456089442690107,
      "grad_norm": 0.05530253052711487,
      "learning_rate": 4.531591863633478e-06,
      "loss": 0.2797,
      "step": 4325
    },
    {
      "epoch": 0.18477425962277033,
      "grad_norm": 0.053202658891677856,
      "learning_rate": 4.465816959691149e-06,
      "loss": 0.256,
      "step": 4330
    },
    {
      "epoch": 0.1849876248186396,
      "grad_norm": 0.052529629319906235,
      "learning_rate": 4.400500584466505e-06,
      "loss": 0.2876,
      "step": 4335
    },
    {
      "epoch": 0.18520099001450882,
      "grad_norm": 0.04725325107574463,
      "learning_rate": 4.3356433956947275e-06,
      "loss": 0.2398,
      "step": 4340
    },
    {
      "epoch": 0.18541435521037808,
      "grad_norm": 0.028557373210787773,
      "learning_rate": 4.271246046486993e-06,
      "loss": 0.2781,
      "step": 4345
    },
    {
      "epoch": 0.18562772040624734,
      "grad_norm": 0.06626544147729874,
      "learning_rate": 4.207309185323877e-06,
      "loss": 0.2308,
      "step": 4350
    },
    {
      "epoch": 0.1858410856021166,
      "grad_norm": 0.03005518764257431,
      "learning_rate": 4.143833456048868e-06,
      "loss": 0.3422,
      "step": 4355
    },
    {
      "epoch": 0.18605445079798583,
      "grad_norm": 0.03854590281844139,
      "learning_rate": 4.080819497861871e-06,
      "loss": 0.3097,
      "step": 4360
    },
    {
      "epoch": 0.18626781599385508,
      "grad_norm": 0.04129241779446602,
      "learning_rate": 4.0182679453127316e-06,
      "loss": 0.2121,
      "step": 4365
    },
    {
      "epoch": 0.18648118118972434,
      "grad_norm": 0.0667153000831604,
      "learning_rate": 3.956179428294876e-06,
      "loss": 0.2723,
      "step": 4370
    },
    {
      "epoch": 0.18669454638559357,
      "grad_norm": 0.039827339351177216,
      "learning_rate": 3.894554572039e-06,
      "loss": 0.2933,
      "step": 4375
    },
    {
      "epoch": 0.18690791158146283,
      "grad_norm": 0.03958721086382866,
      "learning_rate": 3.833393997106727e-06,
      "loss": 0.2721,
      "step": 4380
    },
    {
      "epoch": 0.1871212767773321,
      "grad_norm": 0.03742252290248871,
      "learning_rate": 3.772698319384349e-06,
      "loss": 0.2944,
      "step": 4385
    },
    {
      "epoch": 0.18733464197320132,
      "grad_norm": 0.04507017135620117,
      "learning_rate": 3.71246815007667e-06,
      "loss": 0.2439,
      "step": 4390
    },
    {
      "epoch": 0.18754800716907058,
      "grad_norm": 0.03195054456591606,
      "learning_rate": 3.6527040957008485e-06,
      "loss": 0.2816,
      "step": 4395
    },
    {
      "epoch": 0.18776137236493984,
      "grad_norm": 0.0383896678686142,
      "learning_rate": 3.59340675808022e-06,
      "loss": 0.2238,
      "step": 4400
    },
    {
      "epoch": 0.18797473756080907,
      "grad_norm": 0.06188017874956131,
      "learning_rate": 3.534576734338324e-06,
      "loss": 0.2423,
      "step": 4405
    },
    {
      "epoch": 0.18818810275667833,
      "grad_norm": 0.04827018827199936,
      "learning_rate": 3.4762146168928646e-06,
      "loss": 0.3519,
      "step": 4410
    },
    {
      "epoch": 0.18840146795254759,
      "grad_norm": 0.04148463159799576,
      "learning_rate": 3.4183209934496917e-06,
      "loss": 0.2779,
      "step": 4415
    },
    {
      "epoch": 0.18861483314841684,
      "grad_norm": 0.04182235896587372,
      "learning_rate": 3.3608964469969585e-06,
      "loss": 0.2621,
      "step": 4420
    },
    {
      "epoch": 0.18882819834428607,
      "grad_norm": 0.061836447566747665,
      "learning_rate": 3.3039415557992225e-06,
      "loss": 0.281,
      "step": 4425
    },
    {
      "epoch": 0.18904156354015533,
      "grad_norm": 0.0508822500705719,
      "learning_rate": 3.2474568933915927e-06,
      "loss": 0.2732,
      "step": 4430
    },
    {
      "epoch": 0.1892549287360246,
      "grad_norm": 0.03378046303987503,
      "learning_rate": 3.1914430285739926e-06,
      "loss": 0.2187,
      "step": 4435
    },
    {
      "epoch": 0.18946829393189382,
      "grad_norm": 0.03305033966898918,
      "learning_rate": 3.1359005254054273e-06,
      "loss": 0.3338,
      "step": 4440
    },
    {
      "epoch": 0.18968165912776308,
      "grad_norm": 0.031235400587320328,
      "learning_rate": 3.080829943198277e-06,
      "loss": 0.2749,
      "step": 4445
    },
    {
      "epoch": 0.18989502432363234,
      "grad_norm": 0.03703257068991661,
      "learning_rate": 3.026231836512705e-06,
      "loss": 0.288,
      "step": 4450
    },
    {
      "epoch": 0.19010838951950157,
      "grad_norm": 0.05204526707530022,
      "learning_rate": 2.972106755151027e-06,
      "loss": 0.2638,
      "step": 4455
    },
    {
      "epoch": 0.19032175471537083,
      "grad_norm": 0.04831521585583687,
      "learning_rate": 2.918455244152224e-06,
      "loss": 0.2297,
      "step": 4460
    },
    {
      "epoch": 0.1905351199112401,
      "grad_norm": 0.046774059534072876,
      "learning_rate": 2.8652778437864016e-06,
      "loss": 0.2617,
      "step": 4465
    },
    {
      "epoch": 0.19074848510710932,
      "grad_norm": 0.05099419876933098,
      "learning_rate": 2.812575089549402e-06,
      "loss": 0.3439,
      "step": 4470
    },
    {
      "epoch": 0.19096185030297858,
      "grad_norm": 0.03984484449028969,
      "learning_rate": 2.760347512157374e-06,
      "loss": 0.2474,
      "step": 4475
    },
    {
      "epoch": 0.19117521549884783,
      "grad_norm": 0.04184257239103317,
      "learning_rate": 2.708595637541439e-06,
      "loss": 0.3228,
      "step": 4480
    },
    {
      "epoch": 0.19138858069471706,
      "grad_norm": 0.07454527914524078,
      "learning_rate": 2.6573199868423936e-06,
      "loss": 0.3034,
      "step": 4485
    },
    {
      "epoch": 0.19160194589058632,
      "grad_norm": 0.06637032330036163,
      "learning_rate": 2.606521076405494e-06,
      "loss": 0.2589,
      "step": 4490
    },
    {
      "epoch": 0.19181531108645558,
      "grad_norm": 0.07311289757490158,
      "learning_rate": 2.5561994177751737e-06,
      "loss": 0.2706,
      "step": 4495
    },
    {
      "epoch": 0.19202867628232484,
      "grad_norm": 0.05886521935462952,
      "learning_rate": 2.5063555176899957e-06,
      "loss": 0.2374,
      "step": 4500
    },
    {
      "epoch": 0.19224204147819407,
      "grad_norm": 0.047253381460905075,
      "learning_rate": 2.4569898780774813e-06,
      "loss": 0.2399,
      "step": 4505
    },
    {
      "epoch": 0.19245540667406333,
      "grad_norm": 0.06049156188964844,
      "learning_rate": 2.4081029960490662e-06,
      "loss": 0.2784,
      "step": 4510
    },
    {
      "epoch": 0.1926687718699326,
      "grad_norm": 0.04458348825573921,
      "learning_rate": 2.359695363895109e-06,
      "loss": 0.2586,
      "step": 4515
    },
    {
      "epoch": 0.19288213706580182,
      "grad_norm": 0.027349358424544334,
      "learning_rate": 2.311767469079934e-06,
      "loss": 0.231,
      "step": 4520
    },
    {
      "epoch": 0.19309550226167108,
      "grad_norm": 0.03573762997984886,
      "learning_rate": 2.264319794236902e-06,
      "loss": 0.2416,
      "step": 4525
    },
    {
      "epoch": 0.19330886745754033,
      "grad_norm": 0.06514992564916611,
      "learning_rate": 2.2173528171635815e-06,
      "loss": 0.2695,
      "step": 4530
    },
    {
      "epoch": 0.19352223265340956,
      "grad_norm": 0.03785952553153038,
      "learning_rate": 2.170867010816907e-06,
      "loss": 0.2851,
      "step": 4535
    },
    {
      "epoch": 0.19373559784927882,
      "grad_norm": 0.0737953782081604,
      "learning_rate": 2.1248628433084337e-06,
      "loss": 0.2876,
      "step": 4540
    },
    {
      "epoch": 0.19394896304514808,
      "grad_norm": 0.06700155138969421,
      "learning_rate": 2.079340777899602e-06,
      "loss": 0.2414,
      "step": 4545
    },
    {
      "epoch": 0.1941623282410173,
      "grad_norm": 0.05878114327788353,
      "learning_rate": 2.0343012729971243e-06,
      "loss": 0.2906,
      "step": 4550
    },
    {
      "epoch": 0.19437569343688657,
      "grad_norm": 0.07281042635440826,
      "learning_rate": 1.989744782148312e-06,
      "loss": 0.258,
      "step": 4555
    },
    {
      "epoch": 0.19458905863275583,
      "grad_norm": 0.06878158450126648,
      "learning_rate": 1.9456717540365267e-06,
      "loss": 0.2916,
      "step": 4560
    },
    {
      "epoch": 0.1948024238286251,
      "grad_norm": 0.04501020163297653,
      "learning_rate": 1.9020826324766706e-06,
      "loss": 0.2516,
      "step": 4565
    },
    {
      "epoch": 0.19501578902449432,
      "grad_norm": 0.042321186512708664,
      "learning_rate": 1.8589778564107263e-06,
      "loss": 0.292,
      "step": 4570
    },
    {
      "epoch": 0.19522915422036358,
      "grad_norm": 0.055975645780563354,
      "learning_rate": 1.8163578599033005e-06,
      "loss": 0.2677,
      "step": 4575
    },
    {
      "epoch": 0.19544251941623283,
      "grad_norm": 0.04721767455339432,
      "learning_rate": 1.7742230721372822e-06,
      "loss": 0.2302,
      "step": 4580
    },
    {
      "epoch": 0.19565588461210207,
      "grad_norm": 0.045917026698589325,
      "learning_rate": 1.7325739174095301e-06,
      "loss": 0.2692,
      "step": 4585
    },
    {
      "epoch": 0.19586924980797132,
      "grad_norm": 0.03773931786417961,
      "learning_rate": 1.6914108151265539e-06,
      "loss": 0.2534,
      "step": 4590
    },
    {
      "epoch": 0.19608261500384058,
      "grad_norm": 0.05688842013478279,
      "learning_rate": 1.6507341798003395e-06,
      "loss": 0.2923,
      "step": 4595
    },
    {
      "epoch": 0.1962959801997098,
      "grad_norm": 0.034526243805885315,
      "learning_rate": 1.610544421044169e-06,
      "loss": 0.2478,
      "step": 4600
    },
    {
      "epoch": 0.19650934539557907,
      "grad_norm": 0.04009445384144783,
      "learning_rate": 1.5708419435684462e-06,
      "loss": 0.2199,
      "step": 4605
    },
    {
      "epoch": 0.19672271059144833,
      "grad_norm": 0.0707956850528717,
      "learning_rate": 1.531627147176684e-06,
      "loss": 0.2609,
      "step": 4610
    },
    {
      "epoch": 0.19693607578731756,
      "grad_norm": 0.06028107926249504,
      "learning_rate": 1.492900426761462e-06,
      "loss": 0.2417,
      "step": 4615
    },
    {
      "epoch": 0.19714944098318682,
      "grad_norm": 0.04308047890663147,
      "learning_rate": 1.4546621723004083e-06,
      "loss": 0.2825,
      "step": 4620
    },
    {
      "epoch": 0.19736280617905608,
      "grad_norm": 0.059893909841775894,
      "learning_rate": 1.4169127688523187e-06,
      "loss": 0.263,
      "step": 4625
    },
    {
      "epoch": 0.19757617137492534,
      "grad_norm": 0.03032476082444191,
      "learning_rate": 1.379652596553277e-06,
      "loss": 0.3042,
      "step": 4630
    },
    {
      "epoch": 0.19778953657079457,
      "grad_norm": 0.03792242705821991,
      "learning_rate": 1.3428820306128075e-06,
      "loss": 0.2654,
      "step": 4635
    },
    {
      "epoch": 0.19800290176666382,
      "grad_norm": 0.03666025027632713,
      "learning_rate": 1.3066014413100847e-06,
      "loss": 0.1969,
      "step": 4640
    },
    {
      "epoch": 0.19821626696253308,
      "grad_norm": 0.03577778860926628,
      "learning_rate": 1.2708111939902567e-06,
      "loss": 0.2172,
      "step": 4645
    },
    {
      "epoch": 0.1984296321584023,
      "grad_norm": 0.07881481200456619,
      "learning_rate": 1.235511649060711e-06,
      "loss": 0.2408,
      "step": 4650
    },
    {
      "epoch": 0.19864299735427157,
      "grad_norm": 0.03811100125312805,
      "learning_rate": 1.2007031619874654e-06,
      "loss": 0.2256,
      "step": 4655
    },
    {
      "epoch": 0.19885636255014083,
      "grad_norm": 0.03567060828208923,
      "learning_rate": 1.166386083291604e-06,
      "loss": 0.2737,
      "step": 4660
    },
    {
      "epoch": 0.19906972774601006,
      "grad_norm": 0.06434053182601929,
      "learning_rate": 1.1325607585457365e-06,
      "loss": 0.3119,
      "step": 4665
    },
    {
      "epoch": 0.19928309294187932,
      "grad_norm": 0.03487309440970421,
      "learning_rate": 1.0992275283704944e-06,
      "loss": 0.24,
      "step": 4670
    },
    {
      "epoch": 0.19949645813774858,
      "grad_norm": 0.05383623391389847,
      "learning_rate": 1.0663867284311457e-06,
      "loss": 0.2926,
      "step": 4675
    },
    {
      "epoch": 0.1997098233336178,
      "grad_norm": 0.03324466571211815,
      "learning_rate": 1.0340386894341747e-06,
      "loss": 0.2214,
      "step": 4680
    },
    {
      "epoch": 0.19992318852948707,
      "grad_norm": 0.06584849208593369,
      "learning_rate": 1.002183737123974e-06,
      "loss": 0.3149,
      "step": 4685
    },
    {
      "epoch": 0.20013655372535633,
      "grad_norm": 0.07605189830064774,
      "learning_rate": 9.70822192279569e-07,
      "loss": 0.2332,
      "step": 4690
    },
    {
      "epoch": 0.20034991892122556,
      "grad_norm": 0.03976590931415558,
      "learning_rate": 9.3995437071136e-07,
      "loss": 0.2735,
      "step": 4695
    },
    {
      "epoch": 0.20056328411709481,
      "grad_norm": 0.039675548672676086,
      "learning_rate": 9.095805832579685e-07,
      "loss": 0.2692,
      "step": 4700
    },
    {
      "epoch": 0.20077664931296407,
      "grad_norm": 0.04239419102668762,
      "learning_rate": 8.797011357830953e-07,
      "loss": 0.25,
      "step": 4705
    },
    {
      "epoch": 0.20099001450883333,
      "grad_norm": 0.059025608003139496,
      "learning_rate": 8.503163291724514e-07,
      "loss": 0.3041,
      "step": 4710
    },
    {
      "epoch": 0.20120337970470256,
      "grad_norm": 0.09818308800458908,
      "learning_rate": 8.214264593307098e-07,
      "loss": 0.258,
      "step": 4715
    },
    {
      "epoch": 0.20141674490057182,
      "grad_norm": 0.06851904839277267,
      "learning_rate": 7.930318171785356e-07,
      "loss": 0.3186,
      "step": 4720
    },
    {
      "epoch": 0.20163011009644108,
      "grad_norm": 0.038040272891521454,
      "learning_rate": 7.651326886496612e-07,
      "loss": 0.2489,
      "step": 4725
    },
    {
      "epoch": 0.2018434752923103,
      "grad_norm": 0.07185639441013336,
      "learning_rate": 7.377293546880049e-07,
      "loss": 0.2486,
      "step": 4730
    },
    {
      "epoch": 0.20205684048817957,
      "grad_norm": 0.06898926198482513,
      "learning_rate": 7.108220912448282e-07,
      "loss": 0.2973,
      "step": 4735
    },
    {
      "epoch": 0.20227020568404883,
      "grad_norm": 0.038696639239788055,
      "learning_rate": 6.844111692759836e-07,
      "loss": 0.2576,
      "step": 4740
    },
    {
      "epoch": 0.20248357087991806,
      "grad_norm": 0.048795949667692184,
      "learning_rate": 6.584968547391657e-07,
      "loss": 0.262,
      "step": 4745
    },
    {
      "epoch": 0.20269693607578732,
      "grad_norm": 0.034041162580251694,
      "learning_rate": 6.330794085912195e-07,
      "loss": 0.2419,
      "step": 4750
    },
    {
      "epoch": 0.20291030127165657,
      "grad_norm": 0.06364594399929047,
      "learning_rate": 6.081590867855536e-07,
      "loss": 0.2257,
      "step": 4755
    },
    {
      "epoch": 0.2031236664675258,
      "grad_norm": 0.04523025453090668,
      "learning_rate": 5.837361402695363e-07,
      "loss": 0.2193,
      "step": 4760
    },
    {
      "epoch": 0.20333703166339506,
      "grad_norm": 0.09638120234012604,
      "learning_rate": 5.598108149819536e-07,
      "loss": 0.2519,
      "step": 4765
    },
    {
      "epoch": 0.20355039685926432,
      "grad_norm": 0.04276850447058678,
      "learning_rate": 5.363833518505834e-07,
      "loss": 0.2528,
      "step": 4770
    },
    {
      "epoch": 0.20376376205513358,
      "grad_norm": 0.03698282316327095,
      "learning_rate": 5.134539867897082e-07,
      "loss": 0.2085,
      "step": 4775
    },
    {
      "epoch": 0.2039771272510028,
      "grad_norm": 0.08047995716333389,
      "learning_rate": 4.910229506977837e-07,
      "loss": 0.2853,
      "step": 4780
    },
    {
      "epoch": 0.20419049244687207,
      "grad_norm": 0.04353812336921692,
      "learning_rate": 4.6909046945509125e-07,
      "loss": 0.2429,
      "step": 4785
    },
    {
      "epoch": 0.20440385764274133,
      "grad_norm": 0.04936252906918526,
      "learning_rate": 4.476567639214779e-07,
      "loss": 0.2453,
      "step": 4790
    },
    {
      "epoch": 0.20461722283861056,
      "grad_norm": 0.060226939618587494,
      "learning_rate": 4.2672204993411955e-07,
      "loss": 0.2457,
      "step": 4795
    },
    {
      "epoch": 0.20483058803447982,
      "grad_norm": 0.04342520236968994,
      "learning_rate": 4.0628653830535046e-07,
      "loss": 0.2667,
      "step": 4800
    },
    {
      "epoch": 0.20504395323034907,
      "grad_norm": 0.06255505979061127,
      "learning_rate": 3.863504348205427e-07,
      "loss": 0.2885,
      "step": 4805
    },
    {
      "epoch": 0.2052573184262183,
      "grad_norm": 0.07537965476512909,
      "learning_rate": 3.6691394023604664e-07,
      "loss": 0.3184,
      "step": 4810
    },
    {
      "epoch": 0.20547068362208756,
      "grad_norm": 0.03243553638458252,
      "learning_rate": 3.479772502771372e-07,
      "loss": 0.2775,
      "step": 4815
    },
    {
      "epoch": 0.20568404881795682,
      "grad_norm": 0.049653906375169754,
      "learning_rate": 3.29540555636082e-07,
      "loss": 0.2788,
      "step": 4820
    },
    {
      "epoch": 0.20589741401382605,
      "grad_norm": 0.04777057468891144,
      "learning_rate": 3.1160404197018154e-07,
      "loss": 0.2185,
      "step": 4825
    },
    {
      "epoch": 0.2061107792096953,
      "grad_norm": 0.04216861352324486,
      "learning_rate": 2.9416788989993784e-07,
      "loss": 0.2884,
      "step": 4830
    },
    {
      "epoch": 0.20632414440556457,
      "grad_norm": 0.061070866882801056,
      "learning_rate": 2.7723227500719983e-07,
      "loss": 0.249,
      "step": 4835
    },
    {
      "epoch": 0.20653750960143383,
      "grad_norm": 0.05538971349596977,
      "learning_rate": 2.607973678334319e-07,
      "loss": 0.268,
      "step": 4840
    },
    {
      "epoch": 0.20675087479730306,
      "grad_norm": 0.033091139048337936,
      "learning_rate": 2.4486333387795934e-07,
      "loss": 0.244,
      "step": 4845
    },
    {
      "epoch": 0.20696423999317232,
      "grad_norm": 0.031875718384981155,
      "learning_rate": 2.294303335963255e-07,
      "loss": 0.3072,
      "step": 4850
    },
    {
      "epoch": 0.20717760518904157,
      "grad_norm": 0.04376211017370224,
      "learning_rate": 2.1449852239868174e-07,
      "loss": 0.2225,
      "step": 4855
    },
    {
      "epoch": 0.2073909703849108,
      "grad_norm": 0.03457999974489212,
      "learning_rate": 2.000680506481889e-07,
      "loss": 0.2811,
      "step": 4860
    },
    {
      "epoch": 0.20760433558078006,
      "grad_norm": 0.03150720149278641,
      "learning_rate": 1.8613906365954614e-07,
      "loss": 0.2548,
      "step": 4865
    },
    {
      "epoch": 0.20781770077664932,
      "grad_norm": 0.05654549598693848,
      "learning_rate": 1.7271170169749218e-07,
      "loss": 0.2853,
      "step": 4870
    },
    {
      "epoch": 0.20803106597251855,
      "grad_norm": 0.043127015233039856,
      "learning_rate": 1.5978609997542304e-07,
      "loss": 0.243,
      "step": 4875
    },
    {
      "epoch": 0.2082444311683878,
      "grad_norm": 0.03365889564156532,
      "learning_rate": 1.4736238865398765e-07,
      "loss": 0.2161,
      "step": 4880
    },
    {
      "epoch": 0.20845779636425707,
      "grad_norm": 0.043637823313474655,
      "learning_rate": 1.354406928398333e-07,
      "loss": 0.2684,
      "step": 4885
    },
    {
      "epoch": 0.2086711615601263,
      "grad_norm": 0.03281090408563614,
      "learning_rate": 1.240211325843066e-07,
      "loss": 0.2643,
      "step": 4890
    },
    {
      "epoch": 0.20888452675599556,
      "grad_norm": 0.033972080796957016,
      "learning_rate": 1.1310382288224341e-07,
      "loss": 0.243,
      "step": 4895
    },
    {
      "epoch": 0.20909789195186482,
      "grad_norm": 0.05067916959524155,
      "learning_rate": 1.0268887367083647e-07,
      "loss": 0.259,
      "step": 4900
    },
    {
      "epoch": 0.20931125714773405,
      "grad_norm": 0.040933504700660706,
      "learning_rate": 9.277638982850834e-08,
      "loss": 0.2556,
      "step": 4905
    },
    {
      "epoch": 0.2095246223436033,
      "grad_norm": 0.03402777761220932,
      "learning_rate": 8.336647117385687e-08,
      "loss": 0.3101,
      "step": 4910
    },
    {
      "epoch": 0.20973798753947256,
      "grad_norm": 0.03424748033285141,
      "learning_rate": 7.445921246466702e-08,
      "loss": 0.2685,
      "step": 4915
    },
    {
      "epoch": 0.20995135273534182,
      "grad_norm": 0.03480102866888046,
      "learning_rate": 6.605470339692832e-08,
      "loss": 0.217,
      "step": 4920
    },
    {
      "epoch": 0.21016471793121105,
      "grad_norm": 0.04535042122006416,
      "learning_rate": 5.815302860395777e-08,
      "loss": 0.3211,
      "step": 4925
    },
    {
      "epoch": 0.2103780831270803,
      "grad_norm": 0.0580628328025341,
      "learning_rate": 5.0754267655528375e-08,
      "loss": 0.2581,
      "step": 4930
    },
    {
      "epoch": 0.21059144832294957,
      "grad_norm": 0.057852450758218765,
      "learning_rate": 4.385849505708084e-08,
      "loss": 0.2818,
      "step": 4935
    },
    {
      "epoch": 0.2108048135188188,
      "grad_norm": 0.027065880596637726,
      "learning_rate": 3.746578024897418e-08,
      "loss": 0.2199,
      "step": 4940
    },
    {
      "epoch": 0.21101817871468806,
      "grad_norm": 0.033928047865629196,
      "learning_rate": 3.157618760577519e-08,
      "loss": 0.2695,
      "step": 4945
    },
    {
      "epoch": 0.21123154391055732,
      "grad_norm": 0.056048568338155746,
      "learning_rate": 2.6189776435608937e-08,
      "loss": 0.2182,
      "step": 4950
    },
    {
      "epoch": 0.21144490910642655,
      "grad_norm": 0.034584637731313705,
      "learning_rate": 2.1306600979581482e-08,
      "loss": 0.2571,
      "step": 4955
    },
    {
      "epoch": 0.2116582743022958,
      "grad_norm": 0.07665237039327621,
      "learning_rate": 1.6926710411219183e-08,
      "loss": 0.2775,
      "step": 4960
    },
    {
      "epoch": 0.21187163949816507,
      "grad_norm": 0.044214677065610886,
      "learning_rate": 1.305014883595801e-08,
      "loss": 0.2691,
      "step": 4965
    },
    {
      "epoch": 0.2120850046940343,
      "grad_norm": 0.06713976711034775,
      "learning_rate": 9.676955290749413e-09,
      "loss": 0.233,
      "step": 4970
    },
    {
      "epoch": 0.21229836988990355,
      "grad_norm": 0.05482616648077965,
      "learning_rate": 6.807163743594025e-09,
      "loss": 0.2888,
      "step": 4975
    },
    {
      "epoch": 0.2125117350857728,
      "grad_norm": 0.03590961545705795,
      "learning_rate": 4.4408030932807655e-09,
      "loss": 0.2928,
      "step": 4980
    },
    {
      "epoch": 0.21272510028164207,
      "grad_norm": 0.0413973294198513,
      "learning_rate": 2.57789716902046e-09,
      "loss": 0.2559,
      "step": 4985
    },
    {
      "epoch": 0.2129384654775113,
      "grad_norm": 0.06160064786672592,
      "learning_rate": 1.2184647302626583e-09,
      "loss": 0.2996,
      "step": 4990
    },
    {
      "epoch": 0.21315183067338056,
      "grad_norm": 0.03526068478822708,
      "learning_rate": 3.6251946647358757e-10,
      "loss": 0.2562,
      "step": 4995
    },
    {
      "epoch": 0.21336519586924982,
      "grad_norm": 0.07224000990390778,
      "learning_rate": 1.0069997008477217e-11,
      "loss": 0.3306,
      "step": 5000
    }
  ],
  "logging_steps": 5,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.3568245551444787e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
